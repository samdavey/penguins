{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Temp and Humidity Data Preparation\n",
    "The following need to be done:\n",
    "1. Set up the environment\n",
    "2. Load the relevant data sets from file\n",
    " * `NestCharacteristic-Static.csv   -> df_nest_static`\n",
    " * `NestCharacteristic-Seasonal.csv -> df_nest_seasonal`\n",
    " * `BreedingDataCombined.csv        -> df_breeding`\n",
    " * `TempData_2_10_2016.txt          -> df_temp`\n",
    " * `HumidData_2_10_2016.txt         -> df_humd`\n",
    "3. Join them into a single data set\n",
    "4. Add additional computed features to the data\n",
    "5. Write the prepared data to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the environment\n",
    "### 1.1 Import the required libraries\n",
    "We need a certain set of common libraries for the tasks to be performed. These are imported below. If an import statement errors, you will need to install the library in your environment using the command line command `pip install <library>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up environment and variables.\n"
     ]
    }
   ],
   "source": [
    "print('Setting up environment and variables.', flush=True)\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set up the variables\n",
    "You will need to change the values of the variables below to suit the names and directory location of your files to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# update these with your file paths\n",
    "nest_static_file = os.path.normpath('../0_data/NestCharacteristic-Static.csv')\n",
    "nest_seasonal_file = os.path.normpath('../0_data/NestCharacteristic-Seasonal.csv')\n",
    "breeding_data_file = os.path.normpath('../0_data/BreedingDataCombined.csv')\n",
    "temperature_file = os.path.normpath('../0_data/TempData_2_10_2016.txt')\n",
    "humidity_file = os.path.normpath('../0_data/HumidData_2_10_2016.txt')\n",
    "joined_data_file = os.path.normpath('TempHumdCombined.csv')\n",
    "\n",
    "# write intermediate tables to disk for debugging purposes\n",
    "write_temps = True\n",
    "df_sensor_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Define helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_file_handler_start(file_path, file_description):\n",
    "    '''\n",
    "    Prints the user-friendly messages at the start of reading a data file to csv:\n",
    "        '<timestamp> Loading the <file_description> data file.'\n",
    "        '<timestamp> <file_description> file is <file size> MB.'\n",
    "        '<timestamp> Loading into memory. Please be patient.'\n",
    "    Variables:\n",
    "        file_path: the location of the file to be read. Requires an os.path.normpath object.\n",
    "        file_description: String description of what the file is / name of the file.\n",
    "    '''\n",
    "    print('{0} - Loading the {1} data file.'.format(str(time.ctime()), file_description), flush=True)\n",
    "\n",
    "    file_size = os.path.getsize(file_path)\n",
    "    print('{0} - {1} file is {2:.3f} MB.'.format(str(time.ctime()), file_description, (file_size/1000000)))\n",
    "\n",
    "    if file_size > 5000000: # over 5mb\n",
    "        print('{0} - Loading into memory. Please be patient.'.format(str(time.ctime())), flush=True)\n",
    "    else:\n",
    "        print('{0} - Loading into memory.'.format(str(time.ctime())), flush=True)\n",
    "\n",
    "def read_file_handler_end(file_path, file_description, df, df_var_name):\n",
    "    '''\n",
    "    Prints the user-friendly messages at the end of reading a data file to csv:\n",
    "        '<timestamp> Success: loaded <number of records> records.'\n",
    "        On fail: \n",
    "            '<timestamp> ### FAILED! ###'\n",
    "            '<timestamp> <df_var_name> was not created. Exiting.'\n",
    "            Exits the script.\n",
    "    Variables:\n",
    "        file_path: the location of the file to be read. Requires an os.path.normpath object.\n",
    "        file_description: String description of what the file is / name of the file.\n",
    "        df: a Pandas dataframe that should have resulted from the read_csv() call.\n",
    "        df_var_name: the variable name for the dataframe as a string.\n",
    "    '''\n",
    "    if df is not None:\n",
    "        print('{0} - Success: loaded {1:,} records.'.format(str(time.ctime()), len(df)))\n",
    "    else:\n",
    "        print('{0} - ### FAILED! ###'.format(str(time.ctime())))\n",
    "        print('{0} - {1} was not created. Exiting.'.format(str(time.ctime())), df_var_name)\n",
    "        sys.exit(0)\n",
    "\n",
    "def write_temp_file(df, filepath, df_name):\n",
    "    '''\n",
    "    If write_temps is true, this function will write the specified Pandas dataframe (df) to csv at the specified location (filepath).\n",
    "    Variables:\n",
    "        df: a Pandas dataframe to be written to csv.\n",
    "        filepath: a string in Unix path format (using / not \\) for the csv destination.\n",
    "        df_name: human readable name or description of the dataframe for logging purposes.\n",
    "    '''\n",
    "    if write_temps:\n",
    "        print('{0} - Writing intermediate table {1} to disk.'.format(str(time.ctime()), df_name, filepath), flush=True)\n",
    "        df.to_csv(os.path.normpath(filepath))\n",
    "        if os.path.getsize(filepath) > 0:\n",
    "            print('{0} - Written {1}: {2:.3f} MB'.format(str(time.ctime()), filepath, os.path.getsize(filepath)/1000000), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Load the data from file\n",
    "### 2.1.1 Read in the NestCharacteristic-Static data (df_nest_static)\n",
    "This is the real nest master data to which everything else is joined. Refer to the GitHub Wiki for descriptions of the data fields."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 24 10:39:04 2017 - Loading the Nest Characteristic (Static) data file.\n",
      "Tue Jan 24 10:39:04 2017 - Nest Characteristic (Static) file is 0.032 MB.\n",
      "Tue Jan 24 10:39:04 2017 - Loading into memory.\n",
      "Tue Jan 24 10:39:04 2017 - Success: loaded 241 records.\n"
     ]
    }
   ],
   "source": [
    "read_file_handler_start(nest_static_file, 'Nest Characteristic (Static)')\n",
    "data_types = {'nest_id': str,\n",
    "              'nest_type': str,\n",
    "              'distance_to_boardwalk_m': np.float32,\n",
    "              'distance_to_vegetation_m': np.float32,\n",
    "              'distance_to_landfall': np.float32,\n",
    "              'entrance_bearing': np.float32,\n",
    "              'box_height_mm': np.float32,\n",
    "              'box_length_mm': np.float32,\n",
    "              'box_width_mm': np.float32,\n",
    "              'box_wall_width_mm': np.float32,\n",
    "              'box_lid_depth': np.float32,\n",
    "              'internal_height_mm': np.float32,\n",
    "              'internal_width_mm': np.float32,\n",
    "              'internal_length_mm': np.float32,\n",
    "              'entrance_height': np.float32,\n",
    "              'entrance_width': np.float32,\n",
    "              'entrance_length': np.float32,\n",
    "              'vents': np.float32,\n",
    "              'box_has_tunnel': np.float32,\n",
    "              'shape': str,\n",
    "              'elevation': np.float32,\n",
    "              'easting': np.float32,\n",
    "              'northing': np.float32,\n",
    "              'aspect': np.float32,\n",
    "              'slope': np.float32,\n",
    "              'duration_of_insolation': np.float32,\n",
    "              'comment': str}\n",
    "df_nest_static = pd.read_csv(nest_static_file, \n",
    "                             header=0,\n",
    "                             dtype=data_types,\n",
    "                             encoding='utf-8',\n",
    "                             error_bad_lines=True,\n",
    "                             warn_bad_lines=True)\n",
    "read_file_handler_end(nest_static_file, 'Nest Characteristic (Static)', df_nest_static, 'df_nest_static')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1.1 Update and cleanse fields in NestCharacteristic-Static data (df_nest_static)\n",
    "* Make sure all the nest IDs are uppercase and trimmed\n",
    "* Create field `box_vol_L`\n",
    "* Create field `box_area_cm2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 24 09:34:38 2017 df_nest_static prepared successfully.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# make sure the nest IDs are all caps\n",
    "df_nest_static['nest_id'] = df_nest_static['nest_id'].apply(lambda x: x.strip()).apply(lambda x: x.upper())\n",
    "\n",
    "# calc the volume\n",
    "# some boxes have only external measurements, not internal (which we are trying to calc). If it has external\n",
    "# but not internal, then use external measurements\n",
    "def box_vol_L(row):\n",
    "    if not (np.isnan(row['internal_length_mm']) or \n",
    "            np.isnan(row['internal_width_mm']) or \n",
    "            np.isnan(row['internal_height_mm'])\n",
    "           ):\n",
    "        # has all internal measurements\n",
    "        result = row['internal_length_mm'] * row['internal_width_mm'] * row['internal_height_mm'] / 1000000\n",
    "    else:\n",
    "        # has >0 missing internal measurements, so we'll use the external measurements.\n",
    "        # if we don't have all of those we'll get a NaN anyway.\n",
    "        result = row['box_length_mm'] * row['box_width_mm'] * row['box_height_mm'] / 1000000\n",
    "    return result\n",
    "\n",
    "df_nest_static['box_vol_L'] = df_nest_static.apply(box_vol_L, axis=1)\n",
    "        \n",
    "# calc the floor area\n",
    "def box_area_cm2(row):\n",
    "    if not (np.isnan(row['internal_length_mm']) or np.isnan(row['internal_width_mm'])):\n",
    "        # have all internal measurements, so use them\n",
    "        result = row['internal_length_mm'] * row['internal_width_mm'] / 100\n",
    "    else:\n",
    "        # hope we have all external measurements, else we're getting a Nan anyway\n",
    "        result = row['box_length_mm'] * row['box_width_mm'] / 100\n",
    "    return result\n",
    "\n",
    "df_nest_static['box_area_cm2'] = df_nest_static.apply(box_area_cm2, axis=1)\n",
    "\n",
    "print(str(time.ctime()), 'df_nest_static prepared successfully.\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.1 Read in the NestCharacteristic-Seasonal data (as df_nest_seasonal)\n",
    "Recorded for old boxes and natural nests. Contains seasonal observations of nest vegetation and cover.\n",
    "New boxes (not recorded) were an experiment in different building methods and their effect on box temperature. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 24 10:40:32 2017 - Loading the Nest Characteristic (Seasonal) data file.\n",
      "Tue Jan 24 10:40:32 2017 - Nest Characteristic (Seasonal) file is 0.108 MB.\n",
      "Tue Jan 24 10:40:32 2017 - Loading into memory.\n",
      "Tue Jan 24 10:40:32 2017 - Success: loaded 1,711 records.\n"
     ]
    }
   ],
   "source": [
    "read_file_handler_start(nest_seasonal_file, 'Nest Characteristic (Seasonal)')\n",
    "\n",
    "data_types = {'type': str,\n",
    "              'nest_id': str,\n",
    "              'BoxSeasYear': str,\n",
    "              'date': str,\n",
    "              'year': str,\n",
    "              'season': str,\n",
    "              'BoxCoverTotal': np.float32,\n",
    "              'BoxCoverDead': np.float32,\n",
    "              'BoxWood': np.float32,\n",
    "              'BoxWoodDead': np.float32,\n",
    "              'BoxVeg': np.float32,\n",
    "              'BoxVegDead': np.float32,\n",
    "              'QuadCoverTotal': np.float32,\n",
    "              'QuadCoverDead': np.float32,\n",
    "              'QuadWood': np.float32,\n",
    "              'QuadWoodDead': np.float32,\n",
    "              'QuadVeg': np.float32,\n",
    "              'QuadVegDead': np.float32,\n",
    "              # placeholder for the NestDomeCover field that is meant to exist but currently does not\n",
    "              'comments': str\n",
    "             }\n",
    "df_nest_seasonal = pd.read_csv(nest_seasonal_file,\n",
    "                               header=0,\n",
    "                               dtype=data_types,\n",
    "                               encoding='utf-8',\n",
    "                               parse_dates=['date'],\n",
    "                               dayfirst=True,\n",
    "                               error_bad_lines=True,\n",
    "                               warn_bad_lines=True)\n",
    "\n",
    "read_file_handler_end(nest_seasonal_file, 'Nest Characteristic (Seasonal)', df_nest_seasonal, 'df_nest_seasonal')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.2.2 Update and cleanse fields in the NestCharacteristic-Seasonal data (df_nest_seasonal)\n",
    "* Nest IDs to be all uppercase and trimmed\n",
    "* recalculate the `year` and `season`\n",
    "* create the unique ID `BoxSeasYear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure the nest IDs are all caps\n",
    "df_nest_seasonal['nest_id'] = df_nest_seasonal['nest_id'].apply(lambda x: x.strip()).apply(lambda x: x.upper())\n",
    "\n",
    "# recalculate year (because was manually created)\n",
    "df_nest_seasonal['year'] = df_nest_seasonal['date'].apply(lambda x: x.year)\n",
    "\n",
    "# recalculate season (because was manually created)\n",
    "def season(date):\n",
    "    if date.month >= 3 and date.month <= 5:\n",
    "        return 'AUTUMN'\n",
    "    elif date.month >= 6 and date.month <= 8:\n",
    "        return 'WINTER'\n",
    "    elif date.month >= 9 and date.month <= 11:\n",
    "        return 'SPRING'\n",
    "    elif (date.month >= 1 and date.month <= 2) or date.month == 12:\n",
    "        return 'SUMMER'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "df_nest_seasonal['season'] = df_nest_seasonal['date'].apply(lambda x: season(x))\n",
    "\n",
    "# calc the unique ID\n",
    "df_nest_seasonal['BoxSeasYear'] = df_nest_seasonal['nest_id'] + df_nest_seasonal['season'] + df_nest_seasonal['year'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.1 Read in the BreedingDataCombined file (as df_breeding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 25 13:27:45 2017 - Loading the Breeding data file.\n",
      "Wed Jan 25 13:27:45 2017 - Breeding file is 0.137 MB.\n",
      "Wed Jan 25 13:27:45 2017 - Loading into memory.\n",
      "Wed Jan 25 13:27:45 2017 - Success: loaded 3,575 records.\n"
     ]
    }
   ],
   "source": [
    "read_file_handler_start(breeding_data_file, 'Breeding')\n",
    "data_types = {'nest_id': str,\n",
    "              'observation_date': str,\n",
    "              'ActivityStatus': np.float32,\n",
    "              'adult': np.float32,\n",
    "              'clutch': np.float32,\n",
    "              'eggs': np.float32,\n",
    "              'ChicksAlive': np.float32,\n",
    "              'ChicksDead': np.float32,\n",
    "              'ChicksAge': np.float32,\n",
    "              'ChicksFledge': np.float32,\n",
    "              'ChicksMissing': np.float32,\n",
    "              'ContentsNotVisible': np.float32,\n",
    "              'EggLayDate': str,\n",
    "              'IDChick1': np.float32,\n",
    "              'MassChick1': np.float32,\n",
    "              'IDChick2': np.float32,\n",
    "              'MassChick2': np.float32,\n",
    "              'comments': str\n",
    "             }\n",
    "df_breeding = pd.read_csv(breeding_data_file,\n",
    "                          header=0, \n",
    "                          dtype=data_types,\n",
    "                          encoding='utf-8',\n",
    "                          parse_dates=['observation_date', 'EggLayDate'],\n",
    "                          dayfirst=True,\n",
    "                          error_bad_lines=True,\n",
    "                          warn_bad_lines=True)\n",
    "read_file_handler_end(breeding_data_file, 'Breeding', df_breeding, 'df_breeding')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.2 Update and cleanse fields in the Breeding data (df_breeding)\n",
    "* Nest IDs to be all uppercase and trimmed\n",
    "* `year` is year of `observation_date`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure the nest IDs are all caps\n",
    "df_breeding['nest_id'] = df_breeding['nest_id'].apply(lambda x: x.strip()).apply(lambda x: x.upper())\n",
    "\n",
    "# create year field\n",
    "df_breeding['year'] = df_breeding['observation_date'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.3.3 Aggregate the Breeding data to get annual stats\n",
    "* **nest_id**\n",
    "* **year**\n",
    "* **clutch**\n",
    "* clutch_count\n",
    "* egg_count\n",
    "* chick_count\n",
    "* fletch_count\n",
    "* lay_date\n",
    "* age_at_fletching\n",
    "* mass_at_fletching_chick1\n",
    "* mass_at_fletching_chick2\n",
    "* chick_id1\n",
    "* chick_id2\n",
    "\n",
    "Add field:\n",
    "* `flag_activity_status`: True iff max(ActivityStatus) in year > 0. Note that ActivityStatus was not recorded for the numeric nest_ids, so this field should not be used for 'usage'."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 25 13:28:01 2017 - Aggregating breeding data to get annual stats.\n",
      "Wed Jan 25 13:28:01 2017 - Writing intermediate table df_clutch_count to disk.\n",
      "Wed Jan 25 13:28:01 2017 - Written df_clutch_count.csv: 0.005 MB\n",
      "Wed Jan 25 13:28:01 2017 - Writing intermediate table df_breeding_gb to disk.\n",
      "Wed Jan 25 13:28:01 2017 - Written df_breeding_gb.csv: 0.015 MB\n"
     ]
    }
   ],
   "source": [
    "print('{0} - Aggregating breeding data to get annual stats.'.format(str(time.ctime())), flush=True)\n",
    "\n",
    "# get the clutches per nest and year\n",
    "# [[chosen columns]] -> groupby -> apply max -> add suffix -> remove multi-index\n",
    "df_clutch_count = df_breeding[['nest_id', 'year', 'clutch']\n",
    "                             ].groupby(['nest_id', 'year']).max().add_suffix('_count').reset_index()\n",
    "\n",
    "# get the annual stats per nest, year and clutch\n",
    "temp = df_breeding[['nest_id', 'year', 'ActivityStatus', 'clutch', 'eggs', 'ChicksAlive', 'ChicksFledge', 'EggLayDate', 'ChicksAge', 'MassChick1', 'MassChick2', 'IDChick1', 'IDChick2']].copy()\n",
    "df_breeding_gb = temp.groupby(['nest_id', 'year', 'clutch']).max().reset_index()\n",
    "df_breeding_gb.rename(columns = {'eggs': 'egg_count', 'ChicksAlive': 'chick_count', 'ChicksFledge': 'fledge_count', \n",
    "                     'EggLayDate': 'lay_date', 'ChicksAge': 'age_at_fledging', 'MassChick1': 'mass_at_fletching_chick1', \n",
    "                     'MassChick2': 'mass_at_fletching_chick1', 'ActivityStatus': 'flag_activity_satus'}\n",
    "          , inplace=True)\n",
    "df_breeding_gb['flag_activity_satus'] = df_breeding_gb['flag_activity_satus'].apply(lambda x: x > 0)\n",
    "\n",
    "write_temp_file(df_clutch_count, 'df_clutch_count.csv', 'df_clutch_count')\n",
    "write_temp_file(df_breeding_gb, 'df_breeding_gb.csv', 'df_breeding_gb')\n",
    "del temp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Load the temperature data\n",
    "Read the temperature data file into memory and report on success/failure.\n",
    "We maintain a shortcut: if the joined temp-humidity output file (csv) already exists then skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 24 13:19:58 2017 - Loading the Temperature data file.\n",
      "Tue Jan 24 13:19:58 2017 - Temperature file is 88.172 MB.\n",
      "Tue Jan 24 13:19:58 2017 - Loading into memory. Please be patient.\n",
      "Tue Jan 24 13:20:11 2017 - Success: loaded 2,169,903 records.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), '- Combined temp and humidity file found. Skipping the temp data load.', flush=True)\n",
    "else:\n",
    "    read_file_handler_start(temperature_file, 'Temperature')\n",
    "    column_names = ['recnum', 'datetime', 'temp_c', 'nest_id']\n",
    "    data_types = {'recnum': np.int32, \n",
    "                  'datetime': str, \n",
    "                  'temp_c': np.float32, \n",
    "                  'nest_id': str}\n",
    "    df_temp = pd.read_csv(temperature_file,\n",
    "                          names=column_names,\n",
    "                          usecols=[0,1,2,3],\n",
    "                          dtype=data_types,\n",
    "#                           nrows=10000,\n",
    "                          parse_dates=['datetime'],\n",
    "                          infer_datetime_format=True,\n",
    "                          dayfirst=True,\n",
    "                          encoding='utf-8',\n",
    "                          error_bad_lines=True,\n",
    "                          warn_bad_lines=True\n",
    "                         )\n",
    "    read_file_handler_end(temperature_file, 'Temperature', df_temp, 'df_temp')\n",
    "    \n",
    "    # make sure the nest IDs are all caps\n",
    "    df_temp['nest_id'] = df_temp['nest_id'].apply(lambda x: x.strip()).apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.4.1 Load the humidity data\n",
    "Read the humidity data file into memory and report on success/failure.\n",
    "We maintain a shortcut: if the joined temp-humidity output file (csv) already exists then skip this step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tue Jan 24 13:33:22 2017 - Loading the Humidity data file.\n",
      "Tue Jan 24 13:33:22 2017 - Humidity file is 93.235 MB.\n",
      "Tue Jan 24 13:33:22 2017 - Loading into memory. Please be patient.\n",
      "Tue Jan 24 13:33:35 2017 - Success: loaded 2,173,732 records.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), '- Combined temp and humidity file found. Skipping the humidity data load.', flush=True)\n",
    "else:\n",
    "    read_file_handler_start(humidity_file, 'Humidity')\n",
    "    column_names = ['recnum', 'datetime', 'humidity', 'nest_id']\n",
    "    data_types = {'recnum': np.int32, \n",
    "                  'datetime': str, \n",
    "                  'humidity': np.float32, \n",
    "                  'nest_id': str}\n",
    "    df_humd = pd.read_csv(humidity_file,\n",
    "                          names=column_names,\n",
    "                          usecols=[0,1,2,3],\n",
    "                          dtype=data_types,\n",
    "#                          nrows=10000,               # for testing only\n",
    "                          parse_dates=['datetime'],\n",
    "                          infer_datetime_format=True,\n",
    "                          dayfirst=True,\n",
    "                          encoding='utf-8',\n",
    "                          error_bad_lines=False,\n",
    "                          warn_bad_lines=True\n",
    "                         )\n",
    "\n",
    "    read_file_handler_end(humidity_file, 'Humidity', df_humd, 'df_humd')\n",
    "    \n",
    "    # make sure the nest IDs are all caps\n",
    "    df_humd['nest_id'] = df_humd['nest_id'].apply(lambda x: x.strip()).apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3 Join the loaded data\n",
    "### 3.1 Join the temperature and humidity data (creates df_sensor data)\n",
    "We maintain a shortcut: if the joined temp-humidity output file (csv) already exists then skip this step.\n",
    "Note that the same sensor records temp and humidity simultaneously, so the datetime stamps align and can be used in the join."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wed Jan 25 14:48:54 2017 - Joining the temperature and humidity data sets.\n",
      "Wed Jan 25 14:48:55 2017 - Join complete. Here are the stats:\n",
      "Records in temperature data:            2,169,903\n",
      "Records in humidity data:               2,173,732\n",
      "                              -------------------\n",
      "Records in joined data:                 2,173,738\n",
      "\n",
      "Overview:\n",
      "Number of nest_ids:                           138\n",
      "\n",
      "Wed Jan 25 14:48:56 2017 - Writing intermediate table df_sensor_data to disk.\n",
      "Wed Jan 25 14:49:20 2017 - Written TempHumdCombined.csv: 148.404 MB\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), '- Combined temp and humidity file found. Skipping the temp and humidity data join.', flush=True)\n",
    "else:\n",
    "    print('\\n{0} - Joining the temperature and humidity data sets.'.format(str(time.ctime())), flush=True)\n",
    "    df_sensor_data = pd.merge(left=df_temp,\n",
    "                            right=df_humd,\n",
    "                            how='outer',\n",
    "                            on=['nest_id', 'datetime'], # both have same keys\n",
    "                            left_on=None, # same key names: don't need to specify R and L\n",
    "                            right_on=None, # same key names: don't need to specify R and L\n",
    "                            left_index=False, # dont' use left df index as key\n",
    "                            right_index=False, # dont' use right df index as key\n",
    "                            sort=True, # for efficiency do/not sort the df first\n",
    "                            suffixes=['_temp', '_humd']\n",
    "                            )[['nest_id', 'datetime', 'temp_c', 'humidity']] # take only these cols\n",
    "\n",
    "    print('{0} - Join complete. Here are the stats:'.format(str(time.ctime())))\n",
    "    print('Records in temperature data: {0:>20,}'.format(len(df_temp)))\n",
    "    print('Records in humidity data:    {0:>20,}'.format(len(df_humd)))\n",
    "    print('                              -------------------')\n",
    "    print('Records in joined data:      {0:>20,}'.format(len(df_sensor_data)))\n",
    "    print('\\nOverview:')\n",
    "    gb = df_sensor_data.groupby(['nest_id'])\n",
    "    print('Number of nest_ids:          {0:>20,}\\n'.format(len(gb)))\n",
    "    del gb\n",
    "    write_temp_file(df_sensor_data, joined_data_file, 'df_sensor_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.1 Shortcut: Load the joined temp and humidity csv\n",
    "Do this if the dataframe (df_sensor_data) does not exist but the csv of it (created in a previous run of the script) does. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# if we don't have a df_sensor_data but we do have the output already on disk, then load it. Else do nothing.\n",
    "if df_sensor_data is None and os.path.isfile(joined_data_file):\n",
    "    read_file_handler_start(joined_data_file, 'Combined temp and humidity')\n",
    "    data_types = {'nest_id': str,\n",
    "    #               'recnum': np.int32, \n",
    "                  'datetime': str, \n",
    "                  'temp_c': np.float32,\n",
    "                  'humidity': np.float32, \n",
    "                  'breeding_year': np.float32}\n",
    "    df_sensor_data = pd.read_csv(joined_data_file,\n",
    "                                 dtype=data_types,\n",
    "#                                  nrows=2048,               # for testing only\n",
    "                                 parse_dates=['datetime'],\n",
    "                                 dayfirst=True,\n",
    "                                 encoding='utf-8',\n",
    "                                 error_bad_lines=False,\n",
    "                                 warn_bad_lines=True\n",
    "                                )\n",
    "    read_file_handler_end(joined_data_file, 'Combined temp and humidity', df_sensor_data, joined_data_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1.2 Calculations per-sensor reading\n",
    "The following calculations are added per sensor reading:\n",
    "* The `breeding_year`: same as the calendar year\n",
    "* `temp_bucket` is a category for each 5C temperature range: <0, 0-5, .., 60+\n",
    "* `humidity_bucket`: is a category for roughly 20% humidity ranges, based on human comfort zones\n",
    "* `average_activity_phase`: the average activity conducted at the time of the observation\n",
    "\n",
    "Note: An `actual_activity_phase` (the current phase of breeding based on per-nest observations) is added later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def temp_bucket(temp_c):\n",
    "    result = None\n",
    "    if temp_c < 0:\n",
    "        result = 'temp_<0'\n",
    "    elif temp_c >= 100:\n",
    "        result = 'temp_100+'\n",
    "    else:\n",
    "        floor = (temp_c // 10) * 10\n",
    "        ceiling = floor + 10\n",
    "        result = 'temp_{0:.0f}-{1:.0f}'.format(floor, ceiling)\n",
    "    return result\n",
    "\n",
    "def humidity_bucket(humidity):\n",
    "    '''\n",
    "    Returns buckets every 20% from 0 to 160+\n",
    "    '''\n",
    "    result = None\n",
    "    if humidity < 20: # lung & eye irritation in humans\n",
    "        result = 'RH%_<20'\n",
    "    elif humidity >= 160: # dripping; probably underwater\n",
    "        result = 'RH%_160+'\n",
    "    else:\n",
    "        floor = (humidity // 20) * 20\n",
    "        ceiling = floor + 20\n",
    "        result = 'RH%_{0:.0f}-{1:.0f}'.format(floor, ceiling)\n",
    "    return result\n",
    "\n",
    "def average_activity_phase(sensor_datetime):\n",
    "    '''\n",
    "    Returns the current phase of breeding based on per-nest observations. Phases are generally:\n",
    "    1 Jan - 31 Mar: moulting\n",
    "    1 Apr - 31 May: nest building\n",
    "    1 Jun - 30 Jun: laying\n",
    "    1 Jul - 7 Aug: incubating\n",
    "    8 Aug - 30 Sep: rearing\n",
    "    1 Oct - 30 Oct: fledging\n",
    "    1 Nov - 31 Dec: post-fledging\n",
    "    There can be two lays per season. The second lay is not considered in the average timeframes \n",
    "    above.\n",
    "    '''\n",
    "    if sensor_datetime is None:\n",
    "        return None\n",
    "    elif sensor_datetime.month >= 1 and sensor_datetime.month <= 3:\n",
    "        return 'moulting'\n",
    "    elif sensor_datetime.month >= 4 and sensor_datetime.month >= 5:\n",
    "        return 'nest building'\n",
    "    elif sensor_datetime.month == 6:\n",
    "        return 'laying'\n",
    "    elif sensor_datetime.month == 7:\n",
    "        return 'incubating'\n",
    "    elif sensor_datetime.month == 8 and date(sensor_datetime.year, sensor_datetime.month, sensor_datetime.day) <= date(sensor_datetime.year, 8, 7):\n",
    "        return 'incubating'\n",
    "    elif sensor_datetime.month == 8 and date(sensor_datetime.year, sensor_datetime.month, sensor_datetime.day) > date(sensor_datetime.year, 8, 7):\n",
    "        return 'rearing'\n",
    "    elif sensor_datetime.month >= 9:\n",
    "        return 'rearing'\n",
    "    elif sensor_datetime.month >= 10:\n",
    "        return 'fledging'\n",
    "    elif sensor_datetime.month in [11, 12]:\n",
    "        return 'post-fledging'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 25 14:28:41 2017 - Calculating breeding year. Done.\n",
      "Wed Jan 25 14:28:52 2017 - Calculating average activity periods. Done.\n",
      "Wed Jan 25 14:29:02 2017 - Calculating temperature buckets. Done.\n",
      "Wed Jan 25 14:29:08 2017 - Calculating humidity buckets. Done.\n"
     ]
    }
   ],
   "source": [
    "# Maintain a shortcut: the output is saved to csv, so if it exists from a previous run, then skip this step and load that instead.\n",
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), '- Combined temp and humidity file found. Skipping calculated fields.', flush=True)\n",
    "else:\n",
    "    # add the breeding_year (same as calendar year): \n",
    "    print(str(time.ctime()), '- Calculating breeding year.', end='', flush=True)\n",
    "    df_sensor_data['breeding_year'] = df_sensor_data['datetime'].apply(lambda x: x.year)\n",
    "    print(' Done.', flush=True)\n",
    "\n",
    "    # add the average breeding phases \n",
    "    print(str(time.ctime()), '- Calculating average activity periods.', end='', flush=True)\n",
    "    df_sensor_data['average_activity_period'] = df_sensor_data['datetime'].apply(average_activity_phase)\n",
    "    print(' Done.', flush=True)\n",
    "\n",
    "    # Add flags for various temperature ranges. \n",
    "    # These are summed to give the amount of time in the temp band\n",
    "    print(str(time.ctime()), '- Calculating temperature buckets.', end='', flush=True)\n",
    "    df_sensor_data['temp_bucket'] = df_sensor_data['temp_c'].apply(temp_bucket)\n",
    "    print(' Done.', flush=True)\n",
    "\n",
    "    # # Add flags for various humidity ranges. \n",
    "    # # These are summed to give the amount of time in the humidity band\n",
    "    print(str(time.ctime()), '- Calculating humidity buckets.', end='', flush=True)\n",
    "    df_sensor_data['humidity_bucket'] = df_sensor_data['humidity'].apply(humidity_bucket)\n",
    "    print(' Done.', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 25 14:29:37 2017 Combined temp and humidity file found. Skipping writing the combined data to file.\n"
     ]
    }
   ],
   "source": [
    "# write the new joined-and-augmented sendor dataframe to csv as a shortcut for next time.\n",
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), 'Combined temp and humidity file found. Skipping writing the combined data to file.', flush=True)\n",
    "else:\n",
    "    print('\\n{0} - Writing the joined dataset to csv.'.format(str(time.ctime())), flush=True)\n",
    "    df_sensor_data.to_csv(path_or_buf=joined_data_file,\n",
    "                     sep=',',\n",
    "                     na_rep='',\n",
    "                     float_format='%.3f',\n",
    "                     header=True,\n",
    "                     index=False,\n",
    "                     mode='w',\n",
    "                     encoding='utf-8')\n",
    "    print('{0} - File written: {1} ({2:.1f}MB)'.format(str(time.ctime()), str(joined_data_file), os.path.getsize(joined_data_file)/1000000), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.2 Join the NestCharacteristic Static and Seasonal data\n",
    "`df_nest_seasonal` + `df_nest_static` -> `df_nest_joined`\n",
    "\n",
    "Seasonal is `left` and Static is `right`, such that the Seasonal data is augmented with the nests static metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 25 13:28:38 2017 Joining the Nest Characteristic (Seasonal and Static) data sets .\n",
      "Wed Jan 25 13:28:38 2017 - Join complete. Here are the stats:\n",
      "Records in seasonal data:                   1,711\n",
      "Records in static data:                       241\n",
      "                              -------------------\n",
      "Records in joined data:                     1,711\n",
      "\n",
      "Overview:\n",
      "Number of nest_ids:                           193\n",
      "Wed Jan 25 13:28:38 2017 - Writing intermediate table df_nest_joined to disk.\n",
      "Wed Jan 25 13:28:38 2017 - Written df_nest_joined.csv: 0.455 MB\n"
     ]
    }
   ],
   "source": [
    "print('{0} Joining the Nest Characteristic (Seasonal and Static) data sets .'.format(str(time.ctime())), flush=True)\n",
    "df_nest_joined = pd.merge(left=df_nest_seasonal,\n",
    "                            right=df_nest_static,\n",
    "                            how='left',\n",
    "                            on=['nest_id'], # both have same keys\n",
    "                            left_on=None, # same key names: don't need to specify R and L\n",
    "                            right_on=None, # same key names: don't need to specify R and L\n",
    "                            left_index=False, # dont' use left df index as key\n",
    "                            right_index=False, # dont' use right df index as key\n",
    "                            sort=True, # for efficiency do/not sort the df first\n",
    "                            suffixes=['_seasonal', '_static']\n",
    "                            )\n",
    "if df_nest_joined is not None:\n",
    "    print('{0} - Join complete. Here are the stats:'.format(str(time.ctime())))\n",
    "    print('Records in seasonal data:    {0:>20,}'.format(len(df_nest_seasonal)))\n",
    "    print('Records in static data:      {0:>20,}'.format(len(df_nest_static)))\n",
    "    print('                              -------------------')\n",
    "    print('Records in joined data:      {0:>20,}'.format(len(df_nest_joined)))\n",
    "    print('\\nOverview:')\n",
    "    gb = df_nest_joined.groupby(['nest_id'])\n",
    "    print('Number of nest_ids:          {0:>20,}'.format(len(gb)))\n",
    "    write_temp_file(df_nest_joined, 'df_nest_joined.csv', 'df_nest_joined')\n",
    "    del gb\n",
    "else:\n",
    "    print('{0} - JOIN FAILED!!!.'.format(str(time.ctime())), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.3 Join the breeding stats together\n",
    "`df_breeding_gb + df_clutch_count -> df_breeding_annual_stats`\n",
    "\n",
    "Clutch counts per year and annual clutch survival stats.\n",
    "Note that the reduced record count in `df_breeding_annual_stats` compared to `df_clutch_count` is due to a number of nest-years having blank/zero clutches. These are excluded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wed Jan 25 13:28:44 2017 - Merging the aggregated breeding stats.\n",
      "Wed Jan 25 13:28:44 2017 - Join complete. Here are the stats:\n",
      "Records in annual stats data:                  267\n",
      "Records in clutch count data:                  302\n",
      "                              -------------------\n",
      "Records in joined data:                        267\n",
      "\n",
      "Overview:\n",
      "Number of nest_ids in clutch count:            129\n",
      "Number of nest_ids in breeding stats:          121\n",
      "Number of nest_ids in joined:                  121\n",
      "Wed Jan 25 13:28:44 2017 - Writing intermediate table df_breeding_annual_stats to disk.\n",
      "Wed Jan 25 13:28:44 2017 - Written df_breeding_annual_stats.csv: 0.016 MB\n"
     ]
    }
   ],
   "source": [
    "# join the clutch count on to the annual stats\n",
    "print('\\n{0} - Merging the aggregated breeding stats.'.format(str(time.ctime())), flush=True)\n",
    "df_breeding_annual_stats = pd.merge(left=df_breeding_gb,\n",
    "                                    right=df_clutch_count,\n",
    "                                    how='left',\n",
    "                                    on=['nest_id', 'year'], # both have same keys\n",
    "                                    sort=True # for efficiency do/not sort the df first\n",
    "                                   )\n",
    "\n",
    "print('{0} - Join complete. Here are the stats:'.format(str(time.ctime())))\n",
    "print('Records in annual stats data: {0:>20,}'.format(len(df_breeding_gb)))\n",
    "print('Records in clutch count data: {0:>20,}'.format(len(df_clutch_count)))\n",
    "print('                              -------------------')\n",
    "print('Records in joined data:       {0:>20,}'.format(len(df_breeding_annual_stats)))\n",
    "print('\\nOverview:')\n",
    "gb = df_breeding_annual_stats.groupby(['nest_id'])\n",
    "print('Number of nest_ids in clutch count:   {0:>12,}'.format(len(df_clutch_count.groupby(['nest_id']))))\n",
    "print('Number of nest_ids in breeding stats: {0:>12,}'.format(len(df_breeding_gb.groupby(['nest_id']))))\n",
    "print('Number of nest_ids in joined:         {0:>12,}'.format(len(df_breeding_annual_stats.groupby(['nest_id']))))\n",
    "write_temp_file(df_breeding_annual_stats, 'df_breeding_annual_stats.csv', 'df_breeding_annual_stats')\n",
    "del gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.4 Join the Nest data (seasonal and static) to the Breeding stats\n",
    "`df_nest_joined + df_breeding_annual_stats -> df_nest_and_breeding`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wed Jan 25 13:28:52 2017 - Merging the aggregated breeding stats to the static and seasonal nest data.\n",
      "Wed Jan 25 13:28:52 2017 - Join complete. Here are the stats:\n",
      "Records in nest data:                        1,711\n",
      "Records in breeding stats data:                267\n",
      "                                      ------------\n",
      "Records in joined data:                      1,829\n",
      "\n",
      "Overview:\n",
      "Number of nest_ids in nest data:               193\n",
      "Number of nest_ids in breeding stats:          121\n",
      "Number of nest_ids in joined:                  193\n",
      "Wed Jan 25 13:28:52 2017 - Writing intermediate table df_nest_and_breeding to disk.\n",
      "Wed Jan 25 13:28:52 2017 - Written df_nest_and_breeding.csv: 0.528 MB\n"
     ]
    }
   ],
   "source": [
    "# join the annual clutch and breeding stats onto the full seasonal and static nest data\n",
    "print('\\n{0} - Merging the aggregated breeding stats to the static and seasonal nest data.'.format(str(time.ctime())), flush=True)\n",
    "df_nest_and_breeding = pd.merge(left=df_nest_joined,\n",
    "                                right=df_breeding_annual_stats,\n",
    "                                how='left',\n",
    "                                on=['nest_id','year'], # both have same keys\n",
    "                                sort=True \n",
    "                               )\n",
    "\n",
    "print('{0} - Join complete. Here are the stats:'.format(str(time.ctime())))\n",
    "print('Records in nest data:                 {0:>12,}'.format(len(df_nest_joined)))\n",
    "print('Records in breeding stats data:       {0:>12,}'.format(len(df_breeding_annual_stats)))\n",
    "print('                                      ------------')\n",
    "print('Records in joined data:               {0:>12,}'.format(len(df_nest_and_breeding)))\n",
    "print('\\nOverview:')\n",
    "gb = df_breeding_annual_stats.groupby(['nest_id'])\n",
    "print('Number of nest_ids in nest data:      {0:>12,}'.format(len(df_nest_joined.groupby(['nest_id']))))\n",
    "print('Number of nest_ids in breeding stats: {0:>12,}'.format(len(df_breeding_annual_stats.groupby(['nest_id']))))\n",
    "print('Number of nest_ids in joined:         {0:>12,}'.format(len(df_nest_and_breeding.groupby(['nest_id']))))\n",
    "write_temp_file(df_nest_and_breeding, 'NestDataWithBreedingStats.csv', 'df_nest_and_breeding')\n",
    "del gb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5 Aggregate the sensor data into stats per breeding phase\n",
    "To understand the effect of nest conditions (from sensor data) in the choice of nest and breeding success of the nest, we need to break up the stats into:\n",
    "* *annual stats* which represent the averages, spikes etc for the entire year. These give an understanding of the nest itself.\n",
    "* *phase stats* which represent the conditions during specific phases of the breeding cycle. E.g. during nesting, during incubation, during rearing. To get these phase stats, we need to get the phase boundary dates from the breeding observation data.\n",
    "\n",
    "The nest sensor readings are aggregated to summarise the nest conditions by `nest`, `breeding_year` and `activity_phase`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### 3.5.1 Get the actual breeding phase dates\n",
    "Summarise the breeding data to obtain the following:\n",
    "* list of all nests (regardless of breeding activity)\n",
    "* the `nesting_date` for each nest in each year\n",
    "* the `egg_lay_date` for each nest, year and clutch\n",
    "* the `hatch_date` for each nest, year and clutch\n",
    "* the `fledge_date` for each nest, year and clutch\n",
    "\n",
    "Join these all back together to get the phase dates all in one place, then join the combined result on to the sensor data table and calculate the phase in which each sensor reading occurred.\n",
    "This will take a while.\n",
    "\n",
    "**Issue: Nesting dates dont work: the second clutch will have first nesting date and the first obs for many nests is after the lay date, so nesting_date > lay_date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 25 13:44:04 2017 - Calculating the breeding phase dates for each nest and year.\n",
      "Wed Jan 25 13:44:04 2017 - Writing intermediate table df_all_nests to disk.\n",
      "Wed Jan 25 13:44:04 2017 - Written df_all_nests.csv: 0.002 MB\n",
      "Wed Jan 25 13:44:04 2017 - Writing intermediate table gb_lay_date to disk.\n",
      "Wed Jan 25 13:44:04 2017 - Written gb_lay_date.csv: 0.010 MB\n",
      "Wed Jan 25 13:44:04 2017 - Writing intermediate table gb_hatch_date to disk.\n",
      "Wed Jan 25 13:44:04 2017 - Written gb_hatch_date.csv: 0.006 MB\n",
      "Wed Jan 25 13:44:04 2017 - Writing intermediate table gb_fledge_date to disk.\n",
      "Wed Jan 25 13:44:04 2017 - Written gb_fledge_date.csv: 0.003 MB\n",
      "Wed Jan 25 13:44:04 2017 Merging the phase date tables.\n",
      "Wed Jan 25 13:44:04 2017 - Writing intermediate table df_phase_dates to disk.\n",
      "Wed Jan 25 13:44:04 2017 - Written df_phase_dates.csv: 0.016 MB\n"
     ]
    }
   ],
   "source": [
    "# for each nest, year and clutch, get the following:\n",
    "# first activity_status date (nesting_date), EggLayDate, hatch_date, fledge_date\n",
    "# nesting_date, hatch_date, fledge_date are the min observation_date per nest, year, clutch where the value is not NaN\n",
    "\n",
    "print('{0} - Calculating the breeding phase dates for each nest and year.'.format(str(time.ctime())), flush=True)\n",
    "# all observed nests\n",
    "df_all_nests = df_nest_static[['nest_id']].drop_duplicates()\n",
    "write_temp_file(df_all_nests, 'df_all_nests.csv', 'df_all_nests')\n",
    "\n",
    "# egg_lay_date\n",
    "gb_lay_date = df_breeding[['nest_id', 'year', 'clutch', 'EggLayDate']\n",
    "                         ].groupby(['nest_id', 'year', 'clutch']).min().reset_index()\n",
    "gb_lay_date.rename(columns={'EggLayDate': 'egg_lay_date'}, inplace=True)\n",
    "# nesting date: 31 days before egg_lay_date\n",
    "gb_lay_date['courting_date'] = gb_lay_date['egg_lay_date'] - datetime.timedelta(days=31)\n",
    "write_temp_file(gb_lay_date, 'gb_lay_date.csv', 'gb_lay_date')\n",
    "\n",
    "# hatch_date\n",
    "def hatch_date(row):\n",
    "    return row['observation_date'] - datetime.timedelta(days=row['ChicksAge'])\n",
    "# get the observation date (select columns)                                                 where age is not blank (i.e. they're there)\n",
    "gb_hatch_date = df_breeding[['nest_id', 'year', 'clutch', 'observation_date', 'ChicksAge']].loc[df_breeding['ChicksAge'].notnull()]\n",
    "gb_hatch_date['hatch_date'] = gb_hatch_date.apply(hatch_date, axis=1)\n",
    "# get the min hatch_date \n",
    "gb_hatch_date = gb_hatch_date[['nest_id', 'year', 'clutch', 'hatch_date']].groupby(['nest_id', 'year', 'clutch']).min().reset_index()\n",
    "write_temp_file(gb_hatch_date, 'gb_hatch_date.csv', 'gb_hatch_date')\n",
    "\n",
    "# fledge_date\n",
    "# is either the date that the chicks were of age and no longer observed in the nest, or were observed dead\n",
    "# get the observation date (select columns) where there is a fledge flag\n",
    "gb_fledge_date = df_breeding[['nest_id', 'year', 'clutch', 'observation_date', 'ChicksAlive', 'ChicksDead', 'ChicksFledge']].fillna(0)\n",
    "gb_fledge_date['dead_or_fledged'] = gb_fledge_date.apply(lambda row: row['ChicksFledge'] > 0 or (row['ChicksDead'] > 0 and row['ChicksAlive'] == 0), axis=1)\n",
    "gb_fledge_date = gb_fledge_date.query('dead_or_fledged')\n",
    "# get the min obs date, which is the earliest fledge recording (per clutch)\n",
    "gb_fledge_date = gb_fledge_date[['nest_id', 'year', 'clutch', 'observation_date']].groupby(['nest_id', 'year', 'clutch']).min().reset_index()\n",
    "# rename the obs date \n",
    "gb_fledge_date.rename(columns={'observation_date': 'dead_or_fledge_date'}, inplace=True)\n",
    "write_temp_file(gb_fledge_date, 'gb_fledge_date.csv', 'gb_fledge_date')\n",
    "\n",
    "# join the key date tables together\n",
    "print('{0} - Merging the phase date tables.'.format(str(time.ctime())), flush=True)\n",
    "df_phase_dates = pd.merge(left=df_all_nests, right=gb_lay_date, how='left', on=['nest_id'], sort=True)\n",
    "df_phase_dates = pd.merge(left=df_phase_dates, right=gb_hatch_date, how='left', on=['nest_id', 'year', 'clutch'], sort=True)\n",
    "df_phase_dates = pd.merge(left=df_phase_dates, right=gb_fledge_date, how='left', on=['nest_id', 'year', 'clutch'], sort=True)\n",
    "write_temp_file(df_phase_dates, 'df_phase_dates.csv', 'df_phase_dates')\n",
    "\n",
    "print('{0} - Pivot breeding data to get the clutch dates.'.format(str(time.ctime())), flush=True)\n",
    "# get the required cols\n",
    "df_clutch_pivot = gb_lay_date[['nest_id', 'year', 'clutch', 'egg_lay_date']].copy()\n",
    "# we have to combine the index because pivot() does not like a multi-index\n",
    "df_clutch_pivot['nestyear'] = df_clutch_pivot['nest_id'] + '-' + df_clutch_pivot['year'].apply(lambda x: str(x))\n",
    "# drop the old index fields\n",
    "df_clutch_pivot = df_clutch_pivot[['nestyear', 'clutch', 'egg_lay_date']]\n",
    "# do the pivot to get the (up to three) clutch dates per nest and year\n",
    "df_clutch_pivot = df_clutch_pivot.pivot(index='nestyear', columns='clutch')['egg_lay_date'].reset_index()\n",
    "# rename and restore the indexes\n",
    "df_clutch_pivot.rename(columns={1.0: 'clutch_1', 2.0: 'clutch_2', 3.0: 'clutch_3'}, inplace=True)\n",
    "df_clutch_pivot['nest_id'] = df_clutch_pivot['nestyear'].apply(lambda x: x.split('-')[0])\n",
    "df_clutch_pivot['breeding_year'] = df_clutch_pivot['nestyear'].apply(lambda x: int(x.split('-')[1]))\n",
    "df_clutch_pivot = df_clutch_pivot[['nest_id', 'breeding_year', 'clutch_1', 'clutch_2', 'clutch_3']]\n",
    "write_temp_file(df_clutch_pivot, 'df_clutch_pivot.csv', 'df_clutch_pivot')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Add clutch dates to the sensor data** \n",
    "\n",
    "The `sensor_data` are lacking a `clutch` number, which will create duplicates if we attempt to join on the phase dates. Get the clutch dates and join them into the `sensor_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 25 14:30:31 2017 - Join the clutch dates to the sensor data.\n",
      "Wed Jan 25 14:30:31 2017 - Done. Rows: 2,173,738\n",
      "Wed Jan 25 14:30:31 2017 - Assigning a clutch number to each sensor record. Be patient.\n",
      "Wed Jan 25 14:34:38 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "# to avoid making epic dupes, we need to first add the clutch number on to the sensor data table\n",
    "\n",
    "print('{0} - Join the clutch dates to the sensor data.'.format(str(time.ctime())), flush=True)\n",
    "# join on to the sensor data\n",
    "df_sensor_clutch = pd.merge(left=df_sensor_data, \n",
    "                            right=df_clutch_pivot, \n",
    "                            how='left', \n",
    "                            on=['nest_id', 'breeding_year'],\n",
    "                            sort=True\n",
    "                           )\n",
    "print('{0} - Done. Rows: {1:,}'.format(str(time.ctime()), len(df_sensor_clutch)), flush=True)\n",
    "\n",
    "print('{0} - Assigning a clutch number to each sensor record. Be patient.'.format(str(time.ctime())), flush=True)\n",
    "# flag each reading with a clutch number\n",
    "def clutch_number(row):\n",
    "    if pd.isnull(row['clutch_1']):\n",
    "        # there are no breeding observations for this nest and year\n",
    "        return 0\n",
    "    else:\n",
    "        # there is at least 1 clutch\n",
    "        if pd.isnull(row['clutch_2']) or row['datetime'] < row['clutch_2']:\n",
    "            # there was only a single clutch, or there were >1 but this reading was before the 2nd clutch\n",
    "            return 1\n",
    "        elif pd.isnull(row['clutch_3']) or (not pd.isnull(row['clutch_3']) and row['datetime'] < row['clutch_3']):\n",
    "            # there is a 2nd clutch if we got this far. if there is no 3rd, or the reading is before the 3rd, then this is 2nd\n",
    "            return 2\n",
    "        else:\n",
    "            # there is a 3rd clutch and the sensor reading is after the 3rd\n",
    "            return 3\n",
    "\n",
    "df_sensor_clutch['clutch_number'] = df_sensor_clutch.apply(lambda row: clutch_number(row), axis=1)\n",
    "print('{0} - Done.'.format(str(time.ctime())), flush=True)\n",
    "write_temp_file(df_sensor_clutch, 'df_sensor_clutch.csv', 'df_sensor_clutch')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.5.2 Get the breeding phase against each sensor reading\n",
    "1. Join the phase dates on to the sensor data\n",
    "2. Use the phase date to calculate the breeding_phase for each sensor reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 25 14:51:52 2017 - Join the phase dates on to the sensor data.\n",
      "Wed Jan 25 14:51:53 2017 - Done. Rows: 2,173,738\n",
      "Wed Jan 25 14:51:53 2017 - Writing intermediate table df_sensor_phase to disk.\n",
      "Wed Jan 25 14:52:54 2017 - Written df_sensor_phase.csv: 307.077 MB\n"
     ]
    }
   ],
   "source": [
    "print('{0} - Join the phase dates on to the sensor data.'.format(str(time.ctime())), flush=True)\n",
    "df_sensor_phase = pd.merge(left=df_sensor_clutch,\n",
    "                        right=df_phase_dates,\n",
    "                        how='left',\n",
    "                        left_on=['nest_id', 'breeding_year', 'clutch_number'], # same key names: don't need to specify R and L\n",
    "                        right_on=['nest_id', 'year', 'clutch'], # same key names: don't need to specify R and L\n",
    "                        sort=True # for efficiency do/not sort the df first\n",
    "#                             suffixes=['_temp', '_humd']\n",
    "                        )\n",
    "print('{0} - Done. Rows: {1:,}'.format(str(time.ctime()), len(df_sensor_phase)), flush=True)\n",
    "\n",
    "if os.path.isfile(os.path.normpath('df_sensor_phase.pkl')):\n",
    "    print(str(time.ctime()), '- Combined breeding_phase for sensor readings file found. Skipping this calc and loading that file.', flush=True)\n",
    "    df_sensor_phase = pd.read_pickle(os.path.normpath('df_sensor_phase.pkl'))\n",
    "    print('{0} - Done.'.format(str(time.ctime())), flush=True)\n",
    "else:\n",
    "    print('{0} - Calculating the breeding_phase for each sensor reading. Be patient.'.format(str(time.ctime())), flush=True)\n",
    "    # for each sensor reading, determine the breeding_phase:\n",
    "    # 'courting' iff date between nesting_date and egg_lay_date\n",
    "    # 'incubating' iff date between egg_lay_date and hatch_date\n",
    "    # 'rearing' iff date between hatch_date adn fledge_date\n",
    "    # 'courting' iff clutch < clutch_count and date between fledge_date and egg_lay_date\n",
    "    # else 'unoccupied' \n",
    "\n",
    "    def breeding_phase(row):\n",
    "        if pd.isnull(row['egg_lay_date']) or row['clutch_number'] == 0: \n",
    "            # no activity this year\n",
    "            return 'unoccupied'\n",
    "\n",
    "        elif pd.isnull(row['hatch_date']):\n",
    "            # laid but never hatched\n",
    "            if row['datetime'] <= row['egg_lay_date'] + datetime.timedelta(days=35):\n",
    "                # this egg never hatches, but the current sensor period is incubation\n",
    "                return 'incubating'\n",
    "            else:\n",
    "                # this egg never hatches, and the current sensor period is past the 35 day incubation period\n",
    "                return 'unoccupied'\n",
    "\n",
    "        elif pd.isnull(row['dead_or_fledge_date']): \n",
    "            # hatched but never fledged\n",
    "            if row['datetime'] <= row['hatch_date'] + datetime.timedelta(days=80):\n",
    "                # oldest chick at fledge was 77 days, so assume up to 80\n",
    "                return 'rearing'\n",
    "            else:\n",
    "                # the chicks must be missing\n",
    "                return 'unoccupied' \n",
    "\n",
    "        elif row['datetime'] < row['courting_date']:\n",
    "            # no one has moved in yet\n",
    "            return 'unoccupied'\n",
    "\n",
    "        elif row['clutch_number'] == 1 and row['courting_date'] <= row['datetime'] <= row['egg_lay_date']:\n",
    "            # for the first clutch, courting is 31 days prior to lay\n",
    "            return 'courting'\n",
    "\n",
    "        elif row['clutch_number'] > 1 and row['datetime'] <= row['egg_lay_date']:\n",
    "            # consider it courting again between fledging and second clutch\n",
    "            return 'courting'\n",
    "\n",
    "        elif row['egg_lay_date'] <= row['datetime'] <= row['hatch_date']:\n",
    "            return 'incubating'\n",
    "\n",
    "        elif row['hatch_date'] <= row['datetime'] <= row['dead_or_fledge_date']:\n",
    "            return 'rearing'\n",
    "\n",
    "        elif row['datetime'] > row['dead_or_fledge_date']:\n",
    "            return 'unoccupied'\n",
    "\n",
    "        else:\n",
    "            return 'undefined'\n",
    "\n",
    "    df_sensor_phase['breeding_phase'] = df_sensor_phase.apply(lambda row: breeding_phase(row), axis=1)\n",
    "    df_sensor_phase['nest_year'] = df_sensor_phase.apply(lambda row: '{0}-{1:.0f}'.format(row['nest_id'], row['year']), axis=1)\n",
    "    print('{0} - Done.'.format(str(time.ctime())), flush=True)\n",
    "    print('{0} - Writing to pickle for later.'.format(str(time.ctime())), flush=True)\n",
    "    df_sensor_phase.to_pickle(os.path.normpath('df_sensor_phase.pkl'))\n",
    "    print('{0} - Done.'.format(str(time.ctime())), flush=True)\n",
    "    write_temp_file(df_sensor_phase, 'SensorDataWithBreedingPhase.csv', 'df_sensor_phase')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Do a clean up of dataframes that we'll no longer need.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wed Jan 25 15:45:50 2017 - Cleaning up intermediate data tables...\n",
      "Wed Jan 25 15:45:50 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "print('{0} - Cleaning up intermediate data tables...'.format(str(time.ctime())), flush=True)\n",
    "del df_sensor_clutch\n",
    "del gb_lay_date\n",
    "del gb_hatch_date\n",
    "del gb_fledge_date\n",
    "del df_nest_joined\n",
    "del df_breeding_annual_stats\n",
    "del df_clutch_count\n",
    "del df_breeding_gb\n",
    "print('{0} - Done.'.format(str(time.ctime())), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------\n",
    "# Dev and Test\n",
    "### ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Release memory by deleting DFs that are no longer required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# do it here"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the annual microclimate stats for each nest\n",
    "This is used to understand the annual nest output absed on it's characteristics in the breeding year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_sensor_phase = pd.read_pickle(os.path.normpath('..\\\\0_data\\\\df_sensor_phase.pkl'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# get the YEARLY temp and humidity mean, min, max, stddev for each nest and year\n",
    "temp_annual = df_sensor_phase[['nest_id', 'year', 'temp_c']].dropna().groupby(['nest_id', 'year']).agg([np.min, np.max, np.mean, np.std]).reset_index()\n",
    "temp_annual.rename(columns={'temp_c': 'temp_annual_'}, inplace=True)\n",
    "temp_annual.columns = list(map(''.join, temp_annual.columns.values))\n",
    "\n",
    "humidity_annual = df_sensor_phase[['nest_id', 'year', 'humidity']].dropna().groupby(['nest_id', 'year']).agg([np.min, np.max, np.mean, np.std]).reset_index()\n",
    "humidity_annual.rename(columns={'humidity': 'humidity_annual_'}, inplace=True)\n",
    "humidity_annual.columns = list(map(''.join, humidity_annual.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 163,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nest_id</th>\n",
       "      <th>year</th>\n",
       "      <th>temp_annual_amin</th>\n",
       "      <th>temp_annual_amax</th>\n",
       "      <th>temp_annual_mean</th>\n",
       "      <th>temp_annual_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>37.599998</td>\n",
       "      <td>18.406204</td>\n",
       "      <td>4.666923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>43.580002</td>\n",
       "      <td>21.536072</td>\n",
       "      <td>5.532999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nest_id    year  temp_annual_amin  temp_annual_amax  temp_annual_mean  \\\n",
       "0     101  2013.0              8.59         37.599998         18.406204   \n",
       "1     101  2014.0              8.59         43.580002         21.536072   \n",
       "\n",
       "   temp_annual_std  \n",
       "0         4.666923  \n",
       "1         5.532999  "
      ]
     },
     "execution_count": 163,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_annual.head(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nest_id</th>\n",
       "      <th>year</th>\n",
       "      <th>humidity_annual_amin</th>\n",
       "      <th>humidity_annual_amax</th>\n",
       "      <th>humidity_annual_mean</th>\n",
       "      <th>humidity_annual_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>85.430153</td>\n",
       "      <td>15.742786</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>26.030001</td>\n",
       "      <td>109.050003</td>\n",
       "      <td>75.252083</td>\n",
       "      <td>16.728451</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10A</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>26.070000</td>\n",
       "      <td>126.050003</td>\n",
       "      <td>101.895477</td>\n",
       "      <td>25.549717</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nest_id    year  humidity_annual_amin  humidity_annual_amax  \\\n",
       "0     101  2013.0             28.790001            107.029999   \n",
       "1     101  2014.0             26.030001            109.050003   \n",
       "2     10A  2014.0             26.070000            126.050003   \n",
       "\n",
       "   humidity_annual_mean  humidity_annual_std  \n",
       "0             85.430153            15.742786  \n",
       "1             75.252083            16.728451  \n",
       "2            101.895477            25.549717  "
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humidity_annual.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the microclimate stats for each nest, year and clutch as well as per-phase \n",
    "This is used to understand how the microclimate affects the outcome of each clutch and nest selection during courting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the PHASE temp and humidity mean, min, max, stddev for each nest, year, clutch and phase\n",
    "temp_phase = df_sensor_phase[['nest_id', 'year', 'clutch', 'breeding_phase', 'temp_c']].groupby(['nest_id', 'year', 'clutch', 'breeding_phase']).agg([np.min, np.max, np.mean, np.std]).reset_index()\n",
    "temp_phase.rename(columns={'temp_c': 'temp_phase_'}, inplace=True)\n",
    "temp_phase.columns = list(map(''.join, temp_phase.columns.values))\n",
    "\n",
    "humidity_phase = df_sensor_phase[['nest_id', 'year', 'clutch', 'breeding_phase', 'humidity']].groupby(['nest_id', 'year', 'clutch', 'breeding_phase']).agg([np.min, np.max, np.mean, np.std]).reset_index()\n",
    "humidity_phase.rename(columns={'humidity': 'humidity_phase_'}, inplace=True)\n",
    "humidity_phase.columns = list(map(''.join, humidity_phase.columns.values))\n",
    "\n",
    "# Make a dummy variable that we can sum to get the count of time at each bucket temp/humidity.\n",
    "# Note that the sensor readings are taken every 15 mins, so a dummy value of 0.25 means the sum of bucket records\n",
    "#   equals the total hours in that bucket.\n",
    "temp = df_sensor_phase.copy()\n",
    "temp['counter'] = 0.25\n",
    "\n",
    "# get the temp and humidity buckets for each nest, year, clutch, phase\n",
    "temp_phase_bucket = temp.pivot_table(values='counter', index=['nest_id', 'year', 'clutch', 'breeding_phase'], columns='temp_bucket', aggfunc=np.sum).reset_index()\n",
    "temp_phase_bucket.rename(columns={'humidity': 'temp_phase_bucket_'}, inplace=True)\n",
    "temp_phase_bucket.columns = list(map(''.join, temp_phase_bucket.columns.values))\n",
    "\n",
    "humidity_phase_bucket = temp.pivot_table(values='counter', index=['nest_id', 'year', 'clutch', 'breeding_phase'], columns='humidity_bucket', aggfunc=np.sum).reset_index()\n",
    "humidity_phase_bucket.rename(columns={'humidity': ' humidity_phase_bucket_'}, inplace=True)\n",
    "humidity_phase_bucket.columns = list(map(''.join, humidity_phase_bucket.columns.values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nest_id</th>\n",
       "      <th>year</th>\n",
       "      <th>clutch</th>\n",
       "      <th>breeding_phase</th>\n",
       "      <th>temp_phase_amin</th>\n",
       "      <th>temp_phase_amax</th>\n",
       "      <th>temp_phase_mean</th>\n",
       "      <th>temp_phase_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>incubating</td>\n",
       "      <td>8.59</td>\n",
       "      <td>24.610001</td>\n",
       "      <td>16.033649</td>\n",
       "      <td>2.331077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unoccupied</td>\n",
       "      <td>10.09</td>\n",
       "      <td>37.599998</td>\n",
       "      <td>20.032824</td>\n",
       "      <td>5.146225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rearing</td>\n",
       "      <td>8.59</td>\n",
       "      <td>43.580002</td>\n",
       "      <td>21.536072</td>\n",
       "      <td>5.532999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nest_id    year  clutch breeding_phase  temp_phase_amin  temp_phase_amax  \\\n",
       "0     101  2013.0     1.0     incubating             8.59        24.610001   \n",
       "1     101  2013.0     1.0     unoccupied            10.09        37.599998   \n",
       "2     101  2014.0     1.0        rearing             8.59        43.580002   \n",
       "\n",
       "   temp_phase_mean  temp_phase_std  \n",
       "0        16.033649        2.331077  \n",
       "1        20.032824        5.146225  \n",
       "2        21.536072        5.532999  "
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_phase.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 171,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nest_id</th>\n",
       "      <th>year</th>\n",
       "      <th>clutch</th>\n",
       "      <th>breeding_phase</th>\n",
       "      <th>humidity_phase_amin</th>\n",
       "      <th>humidity_phase_amax</th>\n",
       "      <th>humidity_phase_mean</th>\n",
       "      <th>humidity_phase_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>incubating</td>\n",
       "      <td>57.990002</td>\n",
       "      <td>103.489998</td>\n",
       "      <td>92.353508</td>\n",
       "      <td>6.944231</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unoccupied</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>80.683510</td>\n",
       "      <td>18.147106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rearing</td>\n",
       "      <td>26.030001</td>\n",
       "      <td>109.050003</td>\n",
       "      <td>75.252083</td>\n",
       "      <td>16.728451</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nest_id    year  clutch breeding_phase  humidity_phase_amin  \\\n",
       "0     101  2013.0     1.0     incubating            57.990002   \n",
       "1     101  2013.0     1.0     unoccupied            28.790001   \n",
       "2     101  2014.0     1.0        rearing            26.030001   \n",
       "\n",
       "   humidity_phase_amax  humidity_phase_mean  humidity_phase_std  \n",
       "0           103.489998            92.353508            6.944231  \n",
       "1           107.029999            80.683510           18.147106  \n",
       "2           109.050003            75.252083           16.728451  "
      ]
     },
     "execution_count": 171,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humidity_phase.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nest_id</th>\n",
       "      <th>year</th>\n",
       "      <th>clutch</th>\n",
       "      <th>breeding_phase</th>\n",
       "      <th>temp_0-5</th>\n",
       "      <th>temp_10-15</th>\n",
       "      <th>temp_15-20</th>\n",
       "      <th>temp_20-25</th>\n",
       "      <th>temp_25-30</th>\n",
       "      <th>temp_30-35</th>\n",
       "      <th>temp_35-40</th>\n",
       "      <th>temp_40-45</th>\n",
       "      <th>temp_45-50</th>\n",
       "      <th>temp_5-10</th>\n",
       "      <th>temp_50-55</th>\n",
       "      <th>temp_55-60</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>incubating</td>\n",
       "      <td>NaN</td>\n",
       "      <td>317.75</td>\n",
       "      <td>675.25</td>\n",
       "      <td>53.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7.00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unoccupied</td>\n",
       "      <td>NaN</td>\n",
       "      <td>236.25</td>\n",
       "      <td>616.00</td>\n",
       "      <td>429.50</td>\n",
       "      <td>169.00</td>\n",
       "      <td>75.25</td>\n",
       "      <td>10.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rearing</td>\n",
       "      <td>NaN</td>\n",
       "      <td>180.75</td>\n",
       "      <td>639.25</td>\n",
       "      <td>719.00</td>\n",
       "      <td>320.25</td>\n",
       "      <td>123.25</td>\n",
       "      <td>43.25</td>\n",
       "      <td>2.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11.25</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nest_id    year  clutch breeding_phase  temp_0-5  temp_10-15  temp_15-20  \\\n",
       "0     101  2013.0     1.0     incubating       NaN      317.75      675.25   \n",
       "1     101  2013.0     1.0     unoccupied       NaN      236.25      616.00   \n",
       "2     101  2014.0     1.0        rearing       NaN      180.75      639.25   \n",
       "\n",
       "   temp_20-25  temp_25-30  temp_30-35  temp_35-40  temp_40-45  temp_45-50  \\\n",
       "0       53.25         NaN         NaN         NaN         NaN         NaN   \n",
       "1      429.50      169.00       75.25       10.25         NaN         NaN   \n",
       "2      719.00      320.25      123.25       43.25        2.25         NaN   \n",
       "\n",
       "   temp_5-10  temp_50-55  temp_55-60  \n",
       "0       7.00         NaN         NaN  \n",
       "1        NaN         NaN         NaN  \n",
       "2      11.25         NaN         NaN  "
      ]
     },
     "execution_count": 175,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_phase_bucket.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nest_id</th>\n",
       "      <th>year</th>\n",
       "      <th>clutch</th>\n",
       "      <th>breeding_phase</th>\n",
       "      <th>RH%_100+</th>\n",
       "      <th>RH%_20-30</th>\n",
       "      <th>RH%_30-50</th>\n",
       "      <th>RH%_50-60</th>\n",
       "      <th>RH%_60-80</th>\n",
       "      <th>RH%_80-100</th>\n",
       "      <th>RH%_&lt;20</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>incubating</td>\n",
       "      <td>74.50</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>3.00</td>\n",
       "      <td>65.25</td>\n",
       "      <td>910.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>unoccupied</td>\n",
       "      <td>293.75</td>\n",
       "      <td>0.25</td>\n",
       "      <td>91.25</td>\n",
       "      <td>143.25</td>\n",
       "      <td>498.25</td>\n",
       "      <td>509.5</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>rearing</td>\n",
       "      <td>134.25</td>\n",
       "      <td>5.75</td>\n",
       "      <td>160.75</td>\n",
       "      <td>202.00</td>\n",
       "      <td>890.50</td>\n",
       "      <td>646.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nest_id    year  clutch breeding_phase  RH%_100+  RH%_20-30  RH%_30-50  \\\n",
       "0     101  2013.0     1.0     incubating     74.50        NaN        NaN   \n",
       "1     101  2013.0     1.0     unoccupied    293.75       0.25      91.25   \n",
       "2     101  2014.0     1.0        rearing    134.25       5.75     160.75   \n",
       "\n",
       "   RH%_50-60  RH%_60-80  RH%_80-100  RH%_<20  \n",
       "0       3.00      65.25       910.5      NaN  \n",
       "1     143.25     498.25       509.5      NaN  \n",
       "2     202.00     890.50       646.0      NaN  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "humidity_phase_bucket.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['type', 'nest_id', 'BoxSeasYear', 'date', 'year', 'season',\n",
       "       'BoxCoverTotal', 'BoxCoverDead', 'BoxWood', 'BoxWoodDead', 'BoxVeg',\n",
       "       'BoxVegDead', 'QuadCoverTotal', 'QuadCoverDead', 'QuadWood',\n",
       "       'QuadWoodDead', 'QuadVeg', 'QuadVegDead', 'comments', 'nest_type',\n",
       "       'distance_to_boardwalk_m', 'distance_to_vegetation_m',\n",
       "       'distance_to_landfall', 'entrance_bearing', 'box_height_mm',\n",
       "       'box_length_mm', 'box_width_mm', 'box_wall_width_mm', 'box_lid_depth',\n",
       "       'internal_height_mm', 'internal_width_mm', 'internal_length_mm',\n",
       "       'entrance_height', 'entrance_width', 'entrance_length', 'vents',\n",
       "       'box_vol_L', 'box_area_cm2', 'box_has_tunnel', 'shape', 'elevation',\n",
       "       'easting', 'northing', 'aspect', 'slope', 'duration_of_insolation',\n",
       "       'comment', 'clutch', 'egg_count', 'chick_count', 'fledge_count',\n",
       "       'lay_date', 'age_at_fledging', 'mass_at_fletching_chick1',\n",
       "       'mass_at_fletching_chick1', 'IDChick1', 'IDChick2', 'clutch_count'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nest_and_breeding.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create the final aggregate table"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Start by getting the required `nest_and_breeding` fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Prepare the final master table: df_microclimate_effects\n",
    "This table becomes the master dataset for microclimate influences on breeding outcomes.\n",
    "1. Use df_nest_and_breeding as the base (aggregated breeding stats with static and seasonal nest data)\n",
    "2. Join to this the following\n",
    " 1. temp_annual (annual temperature stats per nest)\n",
    " 2. humidity_annual (annual humidity stats per nest)\n",
    " 3. temp_phase (temp stats per nest, year, clutch and phase)\n",
    " 4. humidity_phase (humidity stats per nest, year, clutch and phase)\n",
    " 5. temp_phase_bucket (hours at each bucketed temp range per nest, year, clutch and phase)\n",
    " 6. humidity_phase_bucket (hours at each bucketed humidity range per nest, year, clutch and phase)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\n",
    "df_microclimate_effects_annual = df_nest_and_breeding[['type', 'nest_id', 'year', 'clutch', 'date', 'season',\n",
    "                                                            'BoxCoverTotal', 'BoxCoverDead', 'BoxWood', 'BoxWoodDead', 'BoxVeg', 'BoxVegDead', \n",
    "                                                            'QuadCoverTotal', 'QuadCoverDead', 'QuadWood', 'QuadWoodDead', 'QuadVeg', 'QuadVegDead', 'comments',  \n",
    "                                                            'distance_to_boardwalk_m', 'distance_to_vegetation_m',\n",
    "                                                            'distance_to_landfall', 'entrance_bearing', 'box_height_mm',\n",
    "                                                            'box_length_mm', 'box_width_mm', 'box_wall_width_mm', 'box_lid_depth',\n",
    "                                                            'internal_height_mm', 'internal_width_mm', 'internal_length_mm',\n",
    "                                                            'entrance_height', 'entrance_width', 'entrance_length', 'vents',\n",
    "                                                            'box_vol_L', 'box_area_cm2', 'box_has_tunnel', 'shape', 'elevation',\n",
    "                                                            'easting', 'northing', 'aspect', 'slope', 'duration_of_insolation',\n",
    "                                                            'comment', 'egg_count', 'chick_count',\n",
    "                                                            'fledge_count', 'lay_date', 'age_at_fledging',\n",
    "                                                            'mass_at_fletching_chick1', 'mass_at_fletching_chick1', 'IDChick1',\n",
    "                                                            'IDChick2', 'clutch_count']].copy()\n",
    "df_microclimate_effects_annual.rename(columns={'comments':'comments_veg', 'comment':'comments_geo'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine `nest_and_breeding` with the sensor aggregate tables for the *annual stats*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nest_id</th>\n",
       "      <th>year</th>\n",
       "      <th>temp_annual_amin</th>\n",
       "      <th>temp_annual_amax</th>\n",
       "      <th>temp_annual_mean</th>\n",
       "      <th>temp_annual_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2013.0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>37.599998</td>\n",
       "      <td>18.406204</td>\n",
       "      <td>4.666923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>43.580002</td>\n",
       "      <td>21.536072</td>\n",
       "      <td>5.532999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10A</td>\n",
       "      <td>2014.0</td>\n",
       "      <td>7.60</td>\n",
       "      <td>42.110001</td>\n",
       "      <td>20.240257</td>\n",
       "      <td>5.329430</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nest_id    year  temp_annual_amin  temp_annual_amax  temp_annual_mean  \\\n",
       "0     101  2013.0              8.59         37.599998         18.406204   \n",
       "1     101  2014.0              8.59         43.580002         21.536072   \n",
       "2     10A  2014.0              7.60         42.110001         20.240257   \n",
       "\n",
       "   temp_annual_std  \n",
       "0         4.666923  \n",
       "1         5.532999  \n",
       "2         5.329430  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "temp_annual.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# join the sensor stats (annual and per-phase) onto the nest_and_breeding data\n",
    "df_microclimate_effects_annual = pd.merge(left=df_microclimate_effects_annual,\n",
    "                                   right=temp_annual,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'year'], # both have same keys\n",
    "                                   left_on=None, # same key names: don't need to specify R and L\n",
    "                                   right_on=None, # same key names: don't need to specify R and L\n",
    "                                   left_index=False, # dont' use left df index as key\n",
    "                                   right_index=False, # dont' use right df index as key\n",
    "                                   sort=True, # for efficiency do/not sort the df first\n",
    "                                   suffixes=['', '_temp_annual']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_microclimate_effects_annual = pd.merge(left=df_microclimate_effects_annual,\n",
    "                                   right=humidity_annual,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'year', 'clutch'], # both have same keys\n",
    "                                   left_on=None, # same key names: don't need to specify R and L\n",
    "                                   right_on=None, # same key names: don't need to specify R and L\n",
    "                                   left_index=False, # dont' use left df index as key\n",
    "                                   right_index=False, # dont' use right df index as key\n",
    "                                   sort=True, # for efficiency do/not sort the df first\n",
    "                                   suffixes=['', '_humidity_annual']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>nest_id</th>\n",
       "      <th>year</th>\n",
       "      <th>clutch</th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>BoxCoverTotal</th>\n",
       "      <th>BoxCoverDead</th>\n",
       "      <th>BoxWood</th>\n",
       "      <th>BoxWoodDead</th>\n",
       "      <th>...</th>\n",
       "      <th>mass_at_fletching_chick1</th>\n",
       "      <th>mass_at_fletching_chick1</th>\n",
       "      <th>mass_at_fletching_chick1</th>\n",
       "      <th>IDChick1</th>\n",
       "      <th>IDChick2</th>\n",
       "      <th>clutch_count</th>\n",
       "      <th>temp_annual_amin</th>\n",
       "      <th>temp_annual_amax</th>\n",
       "      <th>temp_annual_mean</th>\n",
       "      <th>temp_annual_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BOX</td>\n",
       "      <td>100</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>BOX</td>\n",
       "      <td>100</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>BOX</td>\n",
       "      <td>100</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>50.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>50.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>BOX</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>SUMMER</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>BOX</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>AUTUMN</td>\n",
       "      <td>2</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>BOX</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>4</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>BOX</td>\n",
       "      <td>100</td>\n",
       "      <td>2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>BOX</td>\n",
       "      <td>100</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-02-16</td>\n",
       "      <td>SUMMER</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>BOX</td>\n",
       "      <td>100</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-05-26</td>\n",
       "      <td>AUTUMN</td>\n",
       "      <td>5</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>BOX</td>\n",
       "      <td>100</td>\n",
       "      <td>2016</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2016-08-31</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>4</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>37.599998</td>\n",
       "      <td>18.406204</td>\n",
       "      <td>4.666923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>970.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>461260.0</td>\n",
       "      <td>625733.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>43.580002</td>\n",
       "      <td>21.536072</td>\n",
       "      <td>5.532999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-11-30</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>970.0</td>\n",
       "      <td>1010.0</td>\n",
       "      <td>970.0</td>\n",
       "      <td>461260.0</td>\n",
       "      <td>625733.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.59</td>\n",
       "      <td>43.580002</td>\n",
       "      <td>21.536072</td>\n",
       "      <td>5.532999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>SUMMER</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-02-25</td>\n",
       "      <td>SUMMER</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>690.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>546856.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>AUTUMN</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-05-13</td>\n",
       "      <td>AUTUMN</td>\n",
       "      <td>5</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>690.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>546856.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2015</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2015-08-25</td>\n",
       "      <td>WINTER</td>\n",
       "      <td>4</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>690.0</td>\n",
       "      <td>900.0</td>\n",
       "      <td>690.0</td>\n",
       "      <td>546856.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2015</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2015-11-23</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>2</td>\n",
       "      <td>5.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1380.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>20 rows × 62 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type nest_id  year  clutch       date  season BoxCoverTotal  BoxCoverDead  \\\n",
       "0   BOX     100  2013     1.0 2013-11-20  SPRING             4           NaN   \n",
       "1   BOX     100  2014     1.0 2014-10-07  SPRING             5           1.0   \n",
       "2   BOX     100  2014     1.0 2014-11-30  SPRING             5           1.0   \n",
       "3   BOX     100  2015     NaN 2015-02-25  SUMMER           NaN           NaN   \n",
       "4   BOX     100  2015     NaN 2015-05-13  AUTUMN             2           2.0   \n",
       "5   BOX     100  2015     NaN 2015-08-25  WINTER             4           1.0   \n",
       "6   BOX     100  2015     NaN 2015-11-23  SPRING             5           3.0   \n",
       "7   BOX     100  2016     NaN 2016-02-16  SUMMER             5           3.0   \n",
       "8   BOX     100  2016     NaN 2016-05-26  AUTUMN             5           2.0   \n",
       "9   BOX     100  2016     NaN 2016-08-31  WINTER             4           2.0   \n",
       "10  BOX     101  2013     1.0 2013-11-20  SPRING             4           NaN   \n",
       "11  BOX     101  2014     1.0 2014-10-07  SPRING             1           1.0   \n",
       "12  BOX     101  2014     1.0 2014-11-30  SPRING             2           5.0   \n",
       "13  BOX     101  2015     1.0 2015-02-25  SUMMER             2           5.0   \n",
       "14  BOX     101  2015     2.0 2015-02-25  SUMMER             2           5.0   \n",
       "15  BOX     101  2015     1.0 2015-05-13  AUTUMN             5           5.0   \n",
       "16  BOX     101  2015     2.0 2015-05-13  AUTUMN             5           5.0   \n",
       "17  BOX     101  2015     1.0 2015-08-25  WINTER             4           5.0   \n",
       "18  BOX     101  2015     2.0 2015-08-25  WINTER             4           5.0   \n",
       "19  BOX     101  2015     1.0 2015-11-23  SPRING             2           5.0   \n",
       "\n",
       "    BoxWood  BoxWoodDead       ...         mass_at_fletching_chick1  \\\n",
       "0       NaN          NaN       ...                              NaN   \n",
       "1       NaN          NaN       ...                             50.0   \n",
       "2       NaN          NaN       ...                             50.0   \n",
       "3       NaN          NaN       ...                              NaN   \n",
       "4       NaN          NaN       ...                              NaN   \n",
       "5       NaN          NaN       ...                              NaN   \n",
       "6       NaN          NaN       ...                              NaN   \n",
       "7       NaN          NaN       ...                              NaN   \n",
       "8       NaN          NaN       ...                              NaN   \n",
       "9       NaN          NaN       ...                              NaN   \n",
       "10      NaN          NaN       ...                              NaN   \n",
       "11      NaN          NaN       ...                            970.0   \n",
       "12      NaN          NaN       ...                            970.0   \n",
       "13      NaN          NaN       ...                              NaN   \n",
       "14      NaN          NaN       ...                            690.0   \n",
       "15      NaN          NaN       ...                              NaN   \n",
       "16      NaN          NaN       ...                            690.0   \n",
       "17      NaN          NaN       ...                              NaN   \n",
       "18      NaN          NaN       ...                            690.0   \n",
       "19      NaN          NaN       ...                              NaN   \n",
       "\n",
       "    mass_at_fletching_chick1  mass_at_fletching_chick1  IDChick1  IDChick2  \\\n",
       "0                        NaN                       NaN       NaN       NaN   \n",
       "1                       60.0                      50.0       NaN       NaN   \n",
       "2                       60.0                      50.0       NaN       NaN   \n",
       "3                        NaN                       NaN       NaN       NaN   \n",
       "4                        NaN                       NaN       NaN       NaN   \n",
       "5                        NaN                       NaN       NaN       NaN   \n",
       "6                        NaN                       NaN       NaN       NaN   \n",
       "7                        NaN                       NaN       NaN       NaN   \n",
       "8                        NaN                       NaN       NaN       NaN   \n",
       "9                        NaN                       NaN       NaN       NaN   \n",
       "10                       NaN                       NaN       NaN       NaN   \n",
       "11                    1010.0                     970.0  461260.0  625733.0   \n",
       "12                    1010.0                     970.0  461260.0  625733.0   \n",
       "13                    1380.0                       NaN       NaN       NaN   \n",
       "14                     900.0                     690.0  546856.0       NaN   \n",
       "15                    1380.0                       NaN       NaN       NaN   \n",
       "16                     900.0                     690.0  546856.0       NaN   \n",
       "17                    1380.0                       NaN       NaN       NaN   \n",
       "18                     900.0                     690.0  546856.0       NaN   \n",
       "19                    1380.0                       NaN       NaN       NaN   \n",
       "\n",
       "    clutch_count  temp_annual_amin temp_annual_amax temp_annual_mean  \\\n",
       "0            1.0               NaN              NaN              NaN   \n",
       "1            1.0               NaN              NaN              NaN   \n",
       "2            1.0               NaN              NaN              NaN   \n",
       "3            NaN               NaN              NaN              NaN   \n",
       "4            NaN               NaN              NaN              NaN   \n",
       "5            NaN               NaN              NaN              NaN   \n",
       "6            NaN               NaN              NaN              NaN   \n",
       "7            NaN               NaN              NaN              NaN   \n",
       "8            NaN               NaN              NaN              NaN   \n",
       "9            NaN               NaN              NaN              NaN   \n",
       "10           1.0              8.59        37.599998        18.406204   \n",
       "11           1.0              8.59        43.580002        21.536072   \n",
       "12           1.0              8.59        43.580002        21.536072   \n",
       "13           2.0               NaN              NaN              NaN   \n",
       "14           2.0               NaN              NaN              NaN   \n",
       "15           2.0               NaN              NaN              NaN   \n",
       "16           2.0               NaN              NaN              NaN   \n",
       "17           2.0               NaN              NaN              NaN   \n",
       "18           2.0               NaN              NaN              NaN   \n",
       "19           2.0               NaN              NaN              NaN   \n",
       "\n",
       "    temp_annual_std  \n",
       "0               NaN  \n",
       "1               NaN  \n",
       "2               NaN  \n",
       "3               NaN  \n",
       "4               NaN  \n",
       "5               NaN  \n",
       "6               NaN  \n",
       "7               NaN  \n",
       "8               NaN  \n",
       "9               NaN  \n",
       "10         4.666923  \n",
       "11         5.532999  \n",
       "12         5.532999  \n",
       "13              NaN  \n",
       "14              NaN  \n",
       "15              NaN  \n",
       "16              NaN  \n",
       "17              NaN  \n",
       "18              NaN  \n",
       "19              NaN  \n",
       "\n",
       "[20 rows x 62 columns]"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_microclimate_effects_annual.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine `nest_and_breeding` with the sensor aggregate tables for the *breeding_phase stats*\n",
    "Note that this will duplicate the annual stats rows for each breeding phase."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_microclimate_effects_phase = pd.merge(left=df_microclimate_effects_annual,\n",
    "                                   right=temp_phase,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'year', 'clutch'], # both have same keys\n",
    "                                   left_on=None, # same key names: don't need to specify R and L\n",
    "                                   right_on=None, # same key names: don't need to specify R and L\n",
    "                                   left_index=False, # dont' use left df index as key\n",
    "                                   right_index=False, # dont' use right df index as key\n",
    "                                   sort=True, # for efficiency do/not sort the df first\n",
    "                                   suffixes=['', '_temp_phase']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_microclimate_effects_phase = pd.merge(left=df_microclimate_effects_phase,\n",
    "                                   right=humidity_phase,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'year', 'clutch', 'breeding_phase'], # both have same keys\n",
    "                                   left_on=None, # same key names: don't need to specify R and L\n",
    "                                   right_on=None, # same key names: don't need to specify R and L\n",
    "                                   left_index=False, # dont' use left df index as key\n",
    "                                   right_index=False, # dont' use right df index as key\n",
    "                                   sort=True, # for efficiency do/not sort the df first\n",
    "                                   suffixes=['', '_humidity_phase']\n",
    "                                  )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>type</th>\n",
       "      <th>nest_id</th>\n",
       "      <th>year</th>\n",
       "      <th>clutch</th>\n",
       "      <th>date</th>\n",
       "      <th>season</th>\n",
       "      <th>BoxCoverTotal</th>\n",
       "      <th>BoxCoverDead</th>\n",
       "      <th>BoxWood</th>\n",
       "      <th>BoxWoodDead</th>\n",
       "      <th>...</th>\n",
       "      <th>temp_annual_std</th>\n",
       "      <th>humidity_annual_amin</th>\n",
       "      <th>humidity_annual_amax</th>\n",
       "      <th>humidity_annual_mean</th>\n",
       "      <th>humidity_annual_std</th>\n",
       "      <th>breeding_phase</th>\n",
       "      <th>temp_phase_amin</th>\n",
       "      <th>temp_phase_amax</th>\n",
       "      <th>temp_phase_mean</th>\n",
       "      <th>temp_phase_std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666923</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>85.430153</td>\n",
       "      <td>15.742786</td>\n",
       "      <td>incubating</td>\n",
       "      <td>8.59</td>\n",
       "      <td>24.610001</td>\n",
       "      <td>16.033649</td>\n",
       "      <td>2.331077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666923</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>85.430153</td>\n",
       "      <td>15.742786</td>\n",
       "      <td>unoccupied</td>\n",
       "      <td>10.09</td>\n",
       "      <td>37.599998</td>\n",
       "      <td>20.032824</td>\n",
       "      <td>5.146225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666923</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>85.430153</td>\n",
       "      <td>15.742786</td>\n",
       "      <td>incubating</td>\n",
       "      <td>8.59</td>\n",
       "      <td>24.610001</td>\n",
       "      <td>16.033649</td>\n",
       "      <td>2.331077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666923</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>85.430153</td>\n",
       "      <td>15.742786</td>\n",
       "      <td>unoccupied</td>\n",
       "      <td>10.09</td>\n",
       "      <td>37.599998</td>\n",
       "      <td>20.032824</td>\n",
       "      <td>5.146225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666923</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>85.430153</td>\n",
       "      <td>15.742786</td>\n",
       "      <td>incubating</td>\n",
       "      <td>8.59</td>\n",
       "      <td>24.610001</td>\n",
       "      <td>16.033649</td>\n",
       "      <td>2.331077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666923</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>85.430153</td>\n",
       "      <td>15.742786</td>\n",
       "      <td>unoccupied</td>\n",
       "      <td>10.09</td>\n",
       "      <td>37.599998</td>\n",
       "      <td>20.032824</td>\n",
       "      <td>5.146225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666923</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>85.430153</td>\n",
       "      <td>15.742786</td>\n",
       "      <td>incubating</td>\n",
       "      <td>8.59</td>\n",
       "      <td>24.610001</td>\n",
       "      <td>16.033649</td>\n",
       "      <td>2.331077</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666923</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>85.430153</td>\n",
       "      <td>15.742786</td>\n",
       "      <td>unoccupied</td>\n",
       "      <td>10.09</td>\n",
       "      <td>37.599998</td>\n",
       "      <td>20.032824</td>\n",
       "      <td>5.146225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.0</td>\n",
       "      <td>2013-11-20</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>4.666923</td>\n",
       "      <td>28.790001</td>\n",
       "      <td>107.029999</td>\n",
       "      <td>85.430153</td>\n",
       "      <td>15.742786</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>BOX</td>\n",
       "      <td>101</td>\n",
       "      <td>2014</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2014-10-07</td>\n",
       "      <td>SPRING</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>...</td>\n",
       "      <td>5.532999</td>\n",
       "      <td>26.030001</td>\n",
       "      <td>109.050003</td>\n",
       "      <td>75.252083</td>\n",
       "      <td>16.728451</td>\n",
       "      <td>rearing</td>\n",
       "      <td>8.59</td>\n",
       "      <td>43.580002</td>\n",
       "      <td>21.536072</td>\n",
       "      <td>5.532999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 71 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   type nest_id  year  clutch       date  season BoxCoverTotal  BoxCoverDead  \\\n",
       "20  BOX     101  2013     1.0 2013-11-20  SPRING             4           NaN   \n",
       "21  BOX     101  2013     1.0 2013-11-20  SPRING             4           NaN   \n",
       "22  BOX     101  2013     1.0 2013-11-20  SPRING             4           NaN   \n",
       "23  BOX     101  2013     1.0 2013-11-20  SPRING             4           NaN   \n",
       "24  BOX     101  2013     1.0 2013-11-20  SPRING             4           NaN   \n",
       "25  BOX     101  2013     1.0 2013-11-20  SPRING             4           NaN   \n",
       "26  BOX     101  2013     1.0 2013-11-20  SPRING             4           NaN   \n",
       "27  BOX     101  2013     1.0 2013-11-20  SPRING             4           NaN   \n",
       "28  BOX     101  2013     2.0 2013-11-20  SPRING             4           NaN   \n",
       "29  BOX     101  2014     1.0 2014-10-07  SPRING             1           1.0   \n",
       "\n",
       "    BoxWood  BoxWoodDead       ...        temp_annual_std  \\\n",
       "20      NaN          NaN       ...               4.666923   \n",
       "21      NaN          NaN       ...               4.666923   \n",
       "22      NaN          NaN       ...               4.666923   \n",
       "23      NaN          NaN       ...               4.666923   \n",
       "24      NaN          NaN       ...               4.666923   \n",
       "25      NaN          NaN       ...               4.666923   \n",
       "26      NaN          NaN       ...               4.666923   \n",
       "27      NaN          NaN       ...               4.666923   \n",
       "28      NaN          NaN       ...               4.666923   \n",
       "29      NaN          NaN       ...               5.532999   \n",
       "\n",
       "    humidity_annual_amin  humidity_annual_amax humidity_annual_mean  \\\n",
       "20             28.790001            107.029999            85.430153   \n",
       "21             28.790001            107.029999            85.430153   \n",
       "22             28.790001            107.029999            85.430153   \n",
       "23             28.790001            107.029999            85.430153   \n",
       "24             28.790001            107.029999            85.430153   \n",
       "25             28.790001            107.029999            85.430153   \n",
       "26             28.790001            107.029999            85.430153   \n",
       "27             28.790001            107.029999            85.430153   \n",
       "28             28.790001            107.029999            85.430153   \n",
       "29             26.030001            109.050003            75.252083   \n",
       "\n",
       "    humidity_annual_std  breeding_phase  temp_phase_amin temp_phase_amax  \\\n",
       "20            15.742786      incubating             8.59       24.610001   \n",
       "21            15.742786      unoccupied            10.09       37.599998   \n",
       "22            15.742786      incubating             8.59       24.610001   \n",
       "23            15.742786      unoccupied            10.09       37.599998   \n",
       "24            15.742786      incubating             8.59       24.610001   \n",
       "25            15.742786      unoccupied            10.09       37.599998   \n",
       "26            15.742786      incubating             8.59       24.610001   \n",
       "27            15.742786      unoccupied            10.09       37.599998   \n",
       "28            15.742786             NaN              NaN             NaN   \n",
       "29            16.728451         rearing             8.59       43.580002   \n",
       "\n",
       "   temp_phase_mean  temp_phase_std  \n",
       "20       16.033649        2.331077  \n",
       "21       20.032824        5.146225  \n",
       "22       16.033649        2.331077  \n",
       "23       20.032824        5.146225  \n",
       "24       16.033649        2.331077  \n",
       "25       20.032824        5.146225  \n",
       "26       16.033649        2.331077  \n",
       "27       20.032824        5.146225  \n",
       "28             NaN             NaN  \n",
       "29       21.536072        5.532999  \n",
       "\n",
       "[10 rows x 71 columns]"
      ]
     },
     "execution_count": 199,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_microclimate_effects_phase.query('nest_id in [\"101\"]').head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tempset = df_sensor_phase.query('nest_id in [\"E10\", \"E13\", \"E14\", \"E4\", \"T5\", \"W2\", \"W6\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING ONLY\n",
    "\n",
    "# temp = df_sensor_phase.query('nest_id in [\"E10\", \"E13\", \"E14\", \"E4\", \"T5\", \"W2\", \"W6\"]')\n",
    "# temp = tempset.query('nest_id in [\"E10\", \"E13\", \"E14\", \"E4\", \"T5\", \"W2\", \"W6\"]')\n",
    "# temp['date'] = temp['datetime'].apply(pd.datetools.normalize_date)\n",
    "# temp = temp[['nest_id', 'date', 'breeding_year','clutch_number', \n",
    "#        'egg_lay_date', 'courting_date', 'hatch_date', 'dead_or_fledge_date',\n",
    "#        'breeding_phase']]\n",
    "# temp = temp.drop_duplicates()\n",
    "\n",
    "# print(len(temp))\n",
    "# temp.to_csv('sensor_phase_test.csv')\n",
    "#E13 2014 egg never hatched:        works\n",
    "#E10 2014 normal single fledge:     works\n",
    "#W6 2014 chick ded:                 works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hold off making the dummy columns until we need to do the stats. This keeps the file size down and lets us save the csv with buckets rather than dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(str(time.ctime()), 'Creating temp and humidity bucket dummy columns.', end='', flush=True)\n",
    "df_joined = pd.get_dummies(data=df_joined, columns=['temp_bucket', 'humidity_bucket'])\n",
    "print(' Done.', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(str(time.ctime()), 'Aggregating data by nest and year.', flush=True)\n",
    "\n",
    "def percent_of_time(row):\n",
    "    return \n",
    "# group the data by nest_id and breeding year to get the temp and humidity stats per year\n",
    "temp_aggregations = {\n",
    "    'temp_c': {\n",
    "        'temp_count': 'count',\n",
    "        'temp_avg': 'mean',\n",
    "        'temp_min': 'min',\n",
    "        'temp_max': 'max',\n",
    "        'temp_std_dev': 'std'        \n",
    "    },\n",
    "    'humidity': {\n",
    "        'humidity_count': 'count',\n",
    "        'humidity_avg': 'mean',\n",
    "        'humidity_min': 'min',\n",
    "        'humidity_max': 'max',\n",
    "        'humidity_std_dev': 'std'  \n",
    "    },\n",
    "    'temp_<0': {'bucket_total': 'sum'},\n",
    "    'temp_0-5': {'bucket_total': 'sum'},\n",
    "    'temp_5-10': {'bucket_total': 'sum'},\n",
    "    'temp_10-15': {'bucket_total': 'sum'},\n",
    "    'temp_15-20': {'bucket_total': 'sum'},\n",
    "    'temp_20-25': {'bucket_total': 'sum'},\n",
    "    'temp_25-30': {'bucket_total': 'sum'},\n",
    "    'temp_30-35': {'bucket_total': 'sum'},\n",
    "    'temp_35-40': {'bucket_total': 'sum'},\n",
    "    'temp_40-45': {'bucket_total': 'sum'},\n",
    "    'temp_45-50': {'bucket_total': 'sum'},\n",
    "    'temp_50-55': {'bucket_total': 'sum'},\n",
    "    'temp_55-60': {'bucket_total': 'sum'},\n",
    "    'temp_60+': {'bucket_total': 'sum'}    \n",
    "}\n",
    "df_joined_gb = df_joined.groupby(['nest_id', 'breeding_year']).agg(temp_aggregations)\n",
    "print(str(time.ctime()), 'Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to add: \n",
    "* return the nest_ids and number and type of missing records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(str(time.ctime()), 'Checking for missing data.', flush=True)\n",
    "# check for missing temp or humidity readinga\n",
    "def missing_data(row):\n",
    "    if row['temp_c']['temp_count'] > row['humidity']['humidity_count']:\n",
    "        return 'missing_humidity_data'\n",
    "    elif row['temp_c']['temp_count'] < row['humidity']['humidity_count']:\n",
    "        return 'missing_temp_data'\n",
    "    else:\n",
    "        return None\n",
    "df_joined_gb['missing_data'] = df_joined_gb.apply(missing_data, axis=1)\n",
    "\n",
    "print(str(time.ctime()), 'Done.', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined_gb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_joined_gb['temp_25-30']['%time'] = df_joined_gb['temp_25-30']['bucket_total'] / df_joined_gb['temp_c']['temp_count']\n",
    "df_joined_gb['temp_25-30_total'] = df_joined_gb['temp_25-30']['bucket_total']\n",
    "df_joined_gb['temp_25-30_hours'] = df_joined_gb['temp_25-30_total'] / 4\n",
    "df_joined_gb['temp_25-30_%'] = df_joined_gb['temp_25-30_total'] / df_joined_gb['temp_c']['temp_count']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined_gb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined_gb.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below sends the data to the PostGres DB.\n",
    "\n",
    "Currently considering not using the DB at all. While the data maniopulation within the DB via SQL is far easier, keeping the whole project (data load, manipulate, graph) to a single platform and language is a priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #sending temperature dataframe to the postgres DB\n",
    "# print(\"Transferring temperature dataframe to DB..\")\n",
    "# df_temp.to_sql(con=engine, name='penguins_temperature', if_exists='replace')\n",
    "# print(\"Uploaded successfully\")\n",
    "\n",
    "# #sending humidity dataframe to the postgres DB\n",
    "# print(\"Transferring humidity dataframe to DB..\")\n",
    "# df_humd.to_sql(con=engine, name='penguins_humidity', if_exists='replace')\n",
    "# print(\"Uploaded successfully\")\n",
    "\n",
    "# #sending nests dataframe to the postgres DB\n",
    "# print(\"Transferring nests dataframe to DB..\")\n",
    "# nests_raw.to_sql(con=engine, name='penguins_nests', if_exists='replace')\n",
    "# print(\"Uploaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
