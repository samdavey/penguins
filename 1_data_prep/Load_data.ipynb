{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "The following need to be done:\n",
    "* Load the relevant data sets from file\n",
    "* Join them into a single data set\n",
    "* Add additional computed features to the data\n",
    "* Write the prepared data to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment\n",
    "We need a certain set of common libraries for the tasks to be performed. These are imported below. If an import statement errors, you will need to install the library in your environment using the command line command `pip install <library>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up environment and variables.\n"
     ]
    }
   ],
   "source": [
    "print('Setting up environment and variables.', flush=True)\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "df_joined = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the variables\n",
    "Change the values of the variables below to suit the files (names and directory location) to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## Currently in unix format as docker containers run on debian\n",
    "config_file = os.path.normpath('../config.yml')\n",
    "temperature_file = os.path.normpath('../0_data/TempData_2_10_2016.txt')\n",
    "humidity_file = os.path.normpath('../0_data/HumidData_2_10_2016.txt')\n",
    "joined_data_file = os.path.normpath('../0_data/TempHumdCombined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise the config.yml file\n",
    "# try:\n",
    "#     with open(config_file, 'r') as ymlfile:\n",
    "#         config = yaml.load(ymlfile)\n",
    "# except IOError:\n",
    "#     print('Config file can\\'t be found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the database connection parameters based on the config.ini file\n",
    "# if ymlfile is not None:\n",
    "#     host = config['PostgreSQL']['host']\n",
    "#     port = config['PostgreSQL']['port']\n",
    "#     dbname = config['PostgreSQL']['dbname']\n",
    "#     user  = config['PostgreSQL']['user']\n",
    "#     password = config['PostgreSQL']['password']\n",
    "    \n",
    "#     # establish connection to the postgres database using the generated connection string\n",
    "#     engine = create_engine(r\"postgresql://\"+user+\":\"+password+\"@\"+host+\"/\"+dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the temperature data\n",
    "Read the temperature data file into memory and report on success/failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 17 21:01:55 2016 Combined temp and humidity file found. Skipping the temp data load.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), 'Combined temp and humidity file found. Skipping the temp data load.', flush=True)\n",
    "else:\n",
    "    column_names = ['recnum', 'datetime', 'temp_c', 'nest_id']\n",
    "    data_types = {'recnum': np.int32, \n",
    "                  'datetime': str, \n",
    "                  'temp_c': np.float32, \n",
    "                  'nest_id': str}\n",
    "    file_size = os.path.getsize(temperature_file)\n",
    "    print('\\n{0} Temperature is {1:.1f} MB.'.format(str(time.ctime()), \n",
    "                                                                                     (file_size/1000000)))\n",
    "\n",
    "    if file_size > 5000000: # over 5mb\n",
    "        print(str(time.ctime()), 'Loading into memory. Please be patient. ', flush=True)\n",
    "    else:\n",
    "        print(str(time.ctime()), 'Loading into memory. ', flush=True)\n",
    "\n",
    "    df_temp = pd.read_csv(temperature_file,\n",
    "                         names=column_names,\n",
    "                         usecols=[0,1,2,3],\n",
    "                         dtype=data_types,\n",
    "#                          nrows=10000,               # for testing only\n",
    "                          parse_dates=['datetime'],\n",
    "                          dayfirst=True,\n",
    "                          encoding='utf-8',\n",
    "                          error_bad_lines=False,\n",
    "                          warn_bad_lines=True\n",
    "                         )\n",
    "\n",
    "    if df_temp is not None:\n",
    "        print(str(time.ctime()), 'Success: loaded {0:,} records.'.format(len(df_temp)))\n",
    "    else:\n",
    "        print(str(time.ctime()), '### FAILED! ###')\n",
    "    \n",
    "    # make sure the nest IDs are all caps\n",
    "    df_temp['nest_id'] = df_temp['nest_id'].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 17 21:01:55 2016 Combined temp and humidity file found. Skipping the humidity data load.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), 'Combined temp and humidity file found. Skipping the humidity data load.', flush=True)\n",
    "else:\n",
    "    column_names = ['recnum', 'datetime', 'humidity', 'nest_id']\n",
    "    data_types = {'recnum': np.int32, \n",
    "                  'datetime': str, \n",
    "                  'humidity': np.float32, \n",
    "                  'nest_id': str}\n",
    "    file_size = os.path.getsize(humidity_file)\n",
    "    print('\\n{0} Humidity file is {1:.1f} MB.'.format(str(time.ctime()),\n",
    "                                                      (file_size/1000000)), flush=True)\n",
    "\n",
    "    if file_size > 5000000: # over 5mb\n",
    "        print(str(time.ctime()), 'Loading into memory. Please be patient. ', flush=True)\n",
    "    else:\n",
    "        print(str(time.ctime()), 'Loading into memory. ', flush=True, end='')\n",
    "\n",
    "    df_humd = pd.read_csv(humidity_file,\n",
    "                         names=column_names,\n",
    "                         usecols=[0,1,2,3],\n",
    "                         dtype=data_types,\n",
    "#                          nrows=10000,               # for testing only\n",
    "                          parse_dates=['datetime'],\n",
    "                          dayfirst=True,\n",
    "                          encoding='utf-8',\n",
    "                          error_bad_lines=False,\n",
    "                          warn_bad_lines=True\n",
    "                         )\n",
    "\n",
    "    if df_humd is not None:\n",
    "        print(str(time.ctime()), 'Success: loaded {0:,} records.'.format(len(df_humd)))\n",
    "    else:\n",
    "        print(str(time.ctime()), '### FAILED! ###')\n",
    "    \n",
    "    # make sure the nest IDs are all caps\n",
    "    df_humd['nest_id'] = df_humd['nest_id'].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 17 21:01:55 2016 Combined temp and humidity file found. Skipping the temp and humidity data join.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), 'Combined temp and humidity file found. Skipping the temp and humidity data join.', flush=True)\n",
    "else:\n",
    "    print('\\n{0} Joining the temperature and humidity data sets.'.format(str(time.ctime())), flush=True)\n",
    "    df_joined = pd.merge(left=df_temp,\n",
    "                            right=df_humd,\n",
    "                            how='outer',\n",
    "                            on=['nest_id', 'datetime'], # both have same keys\n",
    "                            left_on=None, # same key names: don't need to specify R and L\n",
    "                            right_on=None, # same key names: don't need to specify R and L\n",
    "                            left_index=False, # dont' use left df index as key\n",
    "                            right_index=False, # dont' use right df index as key\n",
    "                            sort=True, # for efficiency do/not sort the df first\n",
    "                            suffixes=['_temp', '_humd']\n",
    "                            )[['nest_id', 'datetime', 'temp_c', 'humidity']] # take only these cols\n",
    "\n",
    "    print('{0} Join complete. Here are the stats:'.format(str(time.ctime())))\n",
    "    print('Records in temperature data: {0:>20,}'.format(len(df_temp)))\n",
    "    print('Records in humidity data:    {0:>20,}'.format(len(df_humd)))\n",
    "    print('                              -------------------')\n",
    "    print('Records in joined data:      {0:>20,}'.format(len(df_joined)))\n",
    "    print('\\nOverview:')\n",
    "    gb = df_joined.groupby(['nest_id'])\n",
    "    print('Number of nest_ids:          {0:>20,}'.format(len(gb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the joined temp and humidity csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mon Oct 17 21:01:56 2016 Combined temp and humidity file is 84.4 MB.\n",
      "Mon Oct 17 21:01:56 2016 Loading into memory. Please be patient. \n",
      "Mon Oct 17 21:02:08 2016 Success: loaded 2,173,738 records.\n"
     ]
    }
   ],
   "source": [
    "if df_joined is None and os.path.isfile(joined_data_file):\n",
    "    data_types = {'nest_id': str,\n",
    "    #               'recnum': np.int32, \n",
    "                  'datetime': str, \n",
    "                  'temp_c': np.float32,\n",
    "                  'humidity': np.float32, \n",
    "                  'breeding_year': np.int32}\n",
    "    file_size = os.path.getsize(joined_data_file)\n",
    "    print('\\n{0} Combined temp and humidity file is {1:.1f} MB.'.format(str(time.ctime()), (file_size/1000000)))\n",
    "\n",
    "    if file_size > 5000000: # over 5mb\n",
    "        print(str(time.ctime()), 'Loading into memory. Please be patient. ', flush=True)\n",
    "    else:\n",
    "        print(str(time.ctime()), 'Loading into memory. ', flush=True, end='')\n",
    "\n",
    "    df_joined = pd.read_csv(joined_data_file,\n",
    "    #                      names=column_names,\n",
    "    #                      usecols=[0,1,2,3],\n",
    "                         dtype=data_types,\n",
    "    #                      nrows=2048,               # for testing only\n",
    "                          parse_dates=['datetime'],\n",
    "                          dayfirst=True,\n",
    "                          encoding='utf-8',\n",
    "                          error_bad_lines=False,\n",
    "                          warn_bad_lines=True\n",
    "                         )\n",
    "\n",
    "    if df_joined is not None:\n",
    "        print(str(time.ctime()), 'Success: loaded {0:,} records.'.format(len(df_joined)))\n",
    "    else:\n",
    "        print(str(time.ctime()), '### FAILED! ###')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def temp_bucket(temp_c):\n",
    "    result = None\n",
    "    if temp_c < 0:\n",
    "        result = 'temp_<0'\n",
    "    elif temp_c >= 0 and temp_c < 5:\n",
    "        result = 'temp_0-5'\n",
    "    elif temp_c >= 5 and temp_c < 10:\n",
    "        result = 'temp_5-10'\n",
    "    elif temp_c >= 10 and temp_c < 15:\n",
    "        result = 'temp_10-15'\n",
    "    elif temp_c >= 15 and temp_c < 20:\n",
    "        result = 'temp_15-20'\n",
    "    elif temp_c >= 20 and temp_c < 25:\n",
    "        result = 'temp_20-25'\n",
    "    elif temp_c >= 25 and temp_c < 30:\n",
    "        result = 'temp_25-30'\n",
    "    elif temp_c >= 30 and temp_c < 35:\n",
    "        result = 'temp_30-35'\n",
    "    elif temp_c >= 35 and temp_c < 40:\n",
    "        result = 'temp_35-40'\n",
    "    elif temp_c >= 40 and temp_c < 45:\n",
    "        result = 'temp_40-45'\n",
    "    elif temp_c >= 45 and temp_c < 50:\n",
    "        result = 'temp_45-50'\n",
    "    elif temp_c >= 50 and temp_c < 55:\n",
    "        result = 'temp_50-55'\n",
    "    elif temp_c >= 55 and temp_c < 60:\n",
    "        result = 'temp_55-60'\n",
    "    elif temp_c >= 60:\n",
    "        result = 'temp_60+'\n",
    "    return result\n",
    "\n",
    "def humidity_bucket(humidity):\n",
    "    result = None\n",
    "    if humidity < 20: # lung & eye irritation in humans\n",
    "        result = 'RH%_<20'\n",
    "    elif humidity >= 20 and humidity < 30: # lung irritation in humans\n",
    "        result = 'RH%_20-30'\n",
    "    elif humidity >= 30 and humidity < 50: # low but not dangerous to humans\n",
    "        result = 'RH%_30-50'\n",
    "    elif humidity >= 50 and humidity < 60: # human ideal comfort zone \n",
    "        result = 'RH%_50-60'\n",
    "    elif humidity >= 60 and humidity < 80: # humid\n",
    "        result = 'RH%_60-80'\n",
    "    elif humidity >= 80 and humidity < 100: # v humid\n",
    "        result = 'RH%_80-100'\n",
    "    elif humidity >= 100: # dripping \n",
    "        result = 'RH%_100+'\n",
    "    return result\n",
    "\n",
    "def average_activity_phase(sensor_datetime):\n",
    "    '''\n",
    "    Returns the current phase of breeding based on per-nest observations. Phases are generally:\n",
    "    1 Jan - 31 Mar: moulting\n",
    "    1 Apr - 31 May: nest building\n",
    "    1 Jun - 30 Jun: laying\n",
    "    1 Jul - 7 Aug: incubating\n",
    "    8 Aug - 30 Sep: rearing\n",
    "    1 Oct - 30 Oct: fledging\n",
    "    1 Nov - 31 Dec: post-fledging\n",
    "    There can be two lays per season. The second lay is not considered in the average timeframes \n",
    "    above.\n",
    "    '''\n",
    "    if sensor_datetime is None:\n",
    "        return None\n",
    "    elif sensor_datetime.month >= 1 and sensor_datetime.month <= 3:\n",
    "        return 'moulting'\n",
    "    elif sensor_datetime.month >= 4 and sensor_datetime.month >= 5:\n",
    "        return 'nest building'\n",
    "    elif sensor_datetime.month == 6:\n",
    "        return 'laying'\n",
    "    elif sensor_datetime.month == 7:\n",
    "        return 'incubating'\n",
    "    elif sensor_datetime.month == 8 and date(sensor_datetime.year, sensor_datetime.month, sensor_datetime.day) <= date(sensor_datetime.year, 8, 7):\n",
    "        return 'incubating'\n",
    "    elif sensor_datetime.month == 8 and date(sensor_datetime.year, sensor_datetime.month, sensor_datetime.day) > date(sensor_datetime.year, 8, 7):\n",
    "        return 'rearing'\n",
    "    elif sensor_datetime.month >= 9:\n",
    "        return 'rearing'\n",
    "    elif sensor_datetime.month >= 10:\n",
    "        return 'fledging'\n",
    "    elif sensor_datetime.month in [11, 12]:\n",
    "        return 'post-fledging'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nest_id</th>\n",
       "      <th>datetime</th>\n",
       "      <th>temp_c</th>\n",
       "      <th>humidity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2013-07-11 21:49:00</td>\n",
       "      <td>15.10</td>\n",
       "      <td>91.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2013-07-11 22:04:00</td>\n",
       "      <td>15.10</td>\n",
       "      <td>91.949997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2013-07-11 22:19:00</td>\n",
       "      <td>15.61</td>\n",
       "      <td>91.519997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>101</td>\n",
       "      <td>2013-07-11 22:34:00</td>\n",
       "      <td>15.61</td>\n",
       "      <td>91.519997</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>101</td>\n",
       "      <td>2013-07-11 22:49:00</td>\n",
       "      <td>15.61</td>\n",
       "      <td>91.519997</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nest_id            datetime  temp_c   humidity\n",
       "0     101 2013-07-11 21:49:00   15.10  91.949997\n",
       "1     101 2013-07-11 22:04:00   15.10  91.949997\n",
       "2     101 2013-07-11 22:19:00   15.61  91.519997\n",
       "3     101 2013-07-11 22:34:00   15.61  91.519997\n",
       "4     101 2013-07-11 22:49:00   15.61  91.519997"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_joined.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations per-sensor reading\n",
    "The following calculations are added per sensor reading:\n",
    "* The `breeding_year`: same as the calendar year\n",
    "* `temp_bucket` is a category for each 5C temperature range: <0, 0-5, .., 60+\n",
    "* `humidity_bucket`: is a category for roughly 20% humidity ranges, based on human comfort zones\n",
    "* `average_activity_phase`: the average activity conducted at the time of the observation\n",
    "\n",
    "### To be added:\n",
    "* `actual_activity_phase`: Is the current phase of breeding based on per-nest observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mon Oct 17 21:46:54 2016 Combined temp and humidity file found. Skipping calculated fields.\n",
      "Mon Oct 17 21:46:54 2016 Calculating breeding year. Done.\n",
      "Mon Oct 17 21:48:22 2016 Calculating average activity periods. Done.\n",
      "Mon Oct 17 21:49:21 2016 Calculating temperature buckets. Done.\n",
      "Mon Oct 17 21:51:11 2016 Calculating humidity buckets. Done.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), 'Combined temp and humidity file found. Skipping calculated fields.', flush=True)\n",
    "# else:\n",
    "# add the breeding_year (same as financial year): \n",
    "print(str(time.ctime()), 'Calculating breeding year.', end='', flush=True)\n",
    "df_joined['breeding_year'] = df_joined['datetime'].apply(lambda x: x.year)\n",
    "print(' Done.', flush=True)\n",
    "\n",
    "# # add the average breeding phases \n",
    "print(str(time.ctime()), 'Calculating average activity periods.', end='', flush=True)\n",
    "df_joined['average_activity_period'] = df_joined['datetime'].apply(average_activity_phase)\n",
    "print(' Done.', flush=True)\n",
    "\n",
    "# Add flags for various temperature ranges. \n",
    "# These are summed to give the amount of time in the temp band\n",
    "print(str(time.ctime()), 'Calculating temperature buckets.', end='', flush=True)\n",
    "df_joined['temp_bucket'] = df_joined['temp_c'].apply(temp_bucket)\n",
    "print(' Done.', flush=True)\n",
    "\n",
    "# # Add flags for various humidity ranges. \n",
    "# # These are summed to give the amount of time in the humidity band\n",
    "print(str(time.ctime()), 'Calculating humidity buckets.', end='', flush=True)\n",
    "df_joined['humidity_bucket'] = df_joined['humidity'].apply(humidity_bucket)\n",
    "print(' Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the created data to file to use again in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Mon Oct 17 21:54:24 2016 Writing the joined dataset to csv.\n",
      "Mon Oct 17 21:57:28 2016 File written: ..\\0_data\\TempHumdCombined.csv (428.8MB)\n"
     ]
    }
   ],
   "source": [
    "# if os.path.isfile(joined_data_file):\n",
    "#     print(str(time.ctime()), 'Combined temp and humidity file found. Skipping writing the combined data to file.', flush=True)\n",
    "# else:\n",
    "print('\\n{0} Writing the joined dataset to csv.'.format(str(time.ctime())), flush=True)\n",
    "df_joined.to_csv(path_or_buf=joined_data_file,\n",
    "                 sep=',',\n",
    "                 na_rep='',\n",
    "                 float_format='%.3f',\n",
    "                 index=False,\n",
    "                 mode='w',\n",
    "                 encoding='utf-8')\n",
    "print('{0} File written: {1} ({2:.1f}MB)'.format(str(time.ctime()), str(joined_data_file), os.path.getsize(joined_data_file)/1000000), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Stop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hold off making the dummy columns until we need to do the stats. This keeps the file size down and lets us save the csv with buckets rather than dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(str(time.ctime()), 'Creating temp and humidity bucket dummy columns.', end='', flush=True)\n",
    "df_joined = pd.get_dummies(data=df_joined, columns=['temp_bucket', 'humidity_bucket'])\n",
    "print(' Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregation\n",
    "The nest sensor readings are aggregated to summarise the nest conditions by `nest`, `breeding_year` and `activity_phase`.\n",
    "\n",
    "### To be added\n",
    "* Bring in `activity_phase` by joining in the breeding data prior to aggregation\n",
    "* Aggregate separately and join back on to avoid ending up with a multi-dimensional table that is difficult to reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(str(time.ctime()), 'Aggregating data by nest and year.', flush=True)\n",
    "\n",
    "def percent_of_time(row):\n",
    "    return \n",
    "# group the data by nest_id and breeding year to get the temp and humidity stats per year\n",
    "temp_aggregations = {\n",
    "    'temp_c': {\n",
    "        'temp_count': 'count',\n",
    "        'temp_avg': 'mean',\n",
    "        'temp_min': 'min',\n",
    "        'temp_max': 'max',\n",
    "        'temp_std_dev': 'std'        \n",
    "    },\n",
    "    'humidity': {\n",
    "        'humidity_count': 'count',\n",
    "        'humidity_avg': 'mean',\n",
    "        'humidity_min': 'min',\n",
    "        'humidity_max': 'max',\n",
    "        'humidity_std_dev': 'std'  \n",
    "    },\n",
    "    'temp_<0': {'bucket_total': 'sum'},\n",
    "    'temp_0-5': {'bucket_total': 'sum'},\n",
    "    'temp_5-10': {'bucket_total': 'sum'},\n",
    "    'temp_10-15': {'bucket_total': 'sum'},\n",
    "    'temp_15-20': {'bucket_total': 'sum'},\n",
    "    'temp_20-25': {'bucket_total': 'sum'},\n",
    "    'temp_25-30': {'bucket_total': 'sum'},\n",
    "    'temp_30-35': {'bucket_total': 'sum'},\n",
    "    'temp_35-40': {'bucket_total': 'sum'},\n",
    "    'temp_40-45': {'bucket_total': 'sum'},\n",
    "    'temp_45-50': {'bucket_total': 'sum'},\n",
    "    'temp_50-55': {'bucket_total': 'sum'},\n",
    "    'temp_55-60': {'bucket_total': 'sum'},\n",
    "    'temp_60+': {'bucket_total': 'sum'}    \n",
    "}\n",
    "df_joined_gb = df_joined.groupby(['nest_id', 'breeding_year']).agg(temp_aggregations)\n",
    "print(str(time.ctime()), 'Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to add: \n",
    "* return the nest_ids and number and type of missing records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(str(time.ctime()), 'Checking for missing data.', flush=True)\n",
    "# check for missing temp or humidity readinga\n",
    "def missing_data(row):\n",
    "    if row['temp_c']['temp_count'] > row['humidity']['humidity_count']:\n",
    "        return 'missing_humidity_data'\n",
    "    elif row['temp_c']['temp_count'] < row['humidity']['humidity_count']:\n",
    "        return 'missing_temp_data'\n",
    "    else:\n",
    "        return None\n",
    "df_joined_gb['missing_data'] = df_joined_gb.apply(missing_data, axis=1)\n",
    "\n",
    "print(str(time.ctime()), 'Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------\n",
    "# Dev and Test\n",
    "### ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined_gb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_joined_gb['temp_25-30']['%time'] = df_joined_gb['temp_25-30']['bucket_total'] / df_joined_gb['temp_c']['temp_count']\n",
    "df_joined_gb['temp_25-30_total'] = df_joined_gb['temp_25-30']['bucket_total']\n",
    "df_joined_gb['temp_25-30_hours'] = df_joined_gb['temp_25-30_total'] / 4\n",
    "df_joined_gb['temp_25-30_%'] = df_joined_gb['temp_25-30_total'] / df_joined_gb['temp_c']['temp_count']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined_gb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined_gb.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below sends the data to the PostGres DB.\n",
    "\n",
    "Currently considering not using the DB at all. While the data maniopulation within the DB via SQL is far easier, keeping the whole project (data load, manipulate, graph) to a single platform and language is a priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#sending temperature dataframe to the postgres DB\n",
    "print(\"Transferring temperature dataframe to DB..\")\n",
    "df_temp.to_sql(con=engine, name='penguins_temperature', if_exists='replace')\n",
    "print(\"Uploaded successfully\")\n",
    "\n",
    "#sending humidity dataframe to the postgres DB\n",
    "print(\"Transferring humidity dataframe to DB..\")\n",
    "df_humd.to_sql(con=engine, name='penguins_humidity', if_exists='replace')\n",
    "print(\"Uploaded successfully\")\n",
    "\n",
    "#sending nests dataframe to the postgres DB\n",
    "print(\"Transferring nests dataframe to DB..\")\n",
    "nests_raw.to_sql(con=engine, name='penguins_nests', if_exists='replace')\n",
    "print(\"Uploaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
