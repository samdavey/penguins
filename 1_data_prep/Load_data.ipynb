{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Preparation\n",
    "The following need to be done:\n",
    "* Load the relevant data sets from file\n",
    "* Join them into a single data set\n",
    "* Add additional computed features to the data\n",
    "* Write the prepared data to file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the environment\n",
    "We need a certain set of common libraries for the tasks to be performed. These are imported below. If an import statement errors, you will need to install the library in your environment using the command line command `pip install <library>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up environment and variables.\n"
     ]
    }
   ],
   "source": [
    "print('Setting up environment and variables.', flush=True)\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "import yaml\n",
    "from sqlalchemy import create_engine\n",
    "\n",
    "df_sensor_data = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set up the variables\n",
    "Change the values of the variables below to suit the files (names and directory location) to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## Currently in unix format as docker containers run on debian\n",
    "config_file = os.path.normpath('../config.yml')\n",
    "temperature_file = os.path.normpath('../0_data/TempData_2_10_2016.txt')\n",
    "humidity_file = os.path.normpath('../0_data/HumidData_2_10_2016.txt')\n",
    "joined_data_file = os.path.normpath('../0_data/TempHumdCombined.csv')\n",
    "nest_static_file = os.path.normpath('../0_data/NestCharacteristic-Static.csv')\n",
    "nest_seasonal_file = os.path.normpath('../0_data/NestCharacteristic-Seasonal.csv')\n",
    "breeding_data_file = os.path.normpath('../0_data/BreedingDataCombined.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# initialise the config.yml file\n",
    "# try:\n",
    "#     with open(config_file, 'r') as ymlfile:\n",
    "#         config = yaml.load(ymlfile)\n",
    "# except IOError:\n",
    "#     print('Config file can\\'t be found.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# set the database connection parameters based on the config.ini file\n",
    "# if ymlfile is not None:\n",
    "#     host = config['PostgreSQL']['host']\n",
    "#     port = config['PostgreSQL']['port']\n",
    "#     dbname = config['PostgreSQL']['dbname']\n",
    "#     user  = config['PostgreSQL']['user']\n",
    "#     password = config['PostgreSQL']['password']\n",
    "    \n",
    "#     # establish connection to the postgres database using the generated connection string\n",
    "#     engine = create_engine(r\"postgresql://\"+user+\":\"+password+\"@\"+host+\"/\"+dbname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the NestCharacteristic-Static data\n",
    "This is the real nest master data to which everything else is joined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:23 2016 Loading the Nest Characteristic (Static) data.\n",
      "\n",
      "Sun Nov  6 21:04:23 2016 Nest Characteristic (Static) file is 0.0 MB.\n",
      "Sun Nov  6 21:04:23 2016 Loading into memory. \n",
      "Sun Nov  6 21:04:23 2016 Success: loaded 241 records.\n"
     ]
    }
   ],
   "source": [
    "print(str(time.ctime()), 'Loading the Nest Characteristic (Static) data.', flush=True)\n",
    "\n",
    "file_size = os.path.getsize(nest_static_file)\n",
    "print('\\n{0} Nest Characteristic (Static) file is {1:.1f} MB.'.format(str(time.ctime()), (file_size/1000000)))\n",
    "\n",
    "if file_size > 5000000: # over 5mb\n",
    "    print(str(time.ctime()), 'Loading into memory. Please be patient. ', flush=True)\n",
    "else:\n",
    "    print(str(time.ctime()), 'Loading into memory. ', flush=True)\n",
    "data_types = {'nest_id': str,\n",
    "              'nest_type': str,\n",
    "              'distance_to_boardwalk_m': np.int32,\n",
    "              'distance_to_vegetation_m': np.int32,\n",
    "              'distance_to_landfall': np.int32,\n",
    "              'entrance_bearing': np.int32,\n",
    "              'box_height_mm': np.int32,\n",
    "              'box_length_mm': np.int32,\n",
    "              'box_width_mm': np.int32,\n",
    "              'box_wall_width_mm': np.int32,\n",
    "              'box_lid_depth': np.int32,\n",
    "              'internal_height_mm': np.int32,\n",
    "              'internal_width_mm': np.int32,\n",
    "              'internal_length_mm': np.int32,\n",
    "              'entrance_height': np.int32,\n",
    "              'entrance_width': np.int32,\n",
    "              'entrance_length': np.int32,\n",
    "              'vents': np.int32,\n",
    "              'box_vol_L': np.int32,\n",
    "              'box_area_cm2': np.int32,\n",
    "              'box_has_tunnel': np.int32,\n",
    "              'shape': str,\n",
    "              'elevation': np.float32,\n",
    "              'easting': np.float32,\n",
    "              'northing': np.float32,\n",
    "              'aspect': np.float32,\n",
    "              'slope': np.float32,\n",
    "              'duration_of_insolation': np.float32,\n",
    "              'comment': str}\n",
    "df_nest_static = pd.read_csv(nest_static_file, \n",
    "                             header=0, \n",
    "                             encoding='utf-8',\n",
    "                             error_bad_lines=False,\n",
    "                             warn_bad_lines=True)\n",
    "\n",
    "if df_nest_static is not None:\n",
    "    print(str(time.ctime()), 'Success: loaded {0:,} records.'.format(len(df_nest_static)))\n",
    "else:\n",
    "    print(str(time.ctime()), '### FAILED! ###')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update and cleanse some fields\n",
    "* Make sure all the nest IDs are uppercase\n",
    "* Create `box_vol_L`\n",
    "* create `box_area_cm2`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure the nest IDs are all caps\n",
    "df_nest_static['nest_id'] = df_nest_static['nest_id'].apply(lambda x: x.upper())\n",
    "# calc the volume\n",
    "df_nest_static['box_vol_L'] = df_nest_static['internal_width_mm'] * df_nest_static['internal_height_mm'] * df_nest_static['internal_length_mm'] / 1000000\n",
    "# calc the floor area\n",
    "df_nest_static['box_area_cm2'] = df_nest_static['internal_width_mm'] * df_nest_static['internal_length_mm'] / 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the NestCharacteristic-Seasonal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:23 2016 Loading the Nest Characteristic (Seasonal) data.\n",
      "\n",
      "Sun Nov  6 21:04:23 2016 Nest Characteristic (Seasonal) file is 0.1 MB.\n",
      "Sun Nov  6 21:04:23 2016 Loading into memory. \n",
      "Sun Nov  6 21:04:24 2016 Success: loaded 1,711 records.\n"
     ]
    }
   ],
   "source": [
    "print(str(time.ctime()), 'Loading the Nest Characteristic (Seasonal) data.', flush=True)\n",
    "\n",
    "file_size = os.path.getsize(nest_seasonal_file)\n",
    "print('\\n{0} Nest Characteristic (Seasonal) file is {1:.1f} MB.'.format(str(time.ctime()), (file_size/1000000)))\n",
    "\n",
    "if file_size > 5000000: # over 5mb\n",
    "    print(str(time.ctime()), 'Loading into memory. Please be patient. ', flush=True)\n",
    "else:\n",
    "    print(str(time.ctime()), 'Loading into memory. ', flush=True)\n",
    "\n",
    "data_types = {'type': str,\n",
    "              'nest_id': str,\n",
    "              'BoxSeasYear': str,\n",
    "              'date': str,\n",
    "              'year': str,\n",
    "              'season': str,\n",
    "              'BoxCoverTotal': np.int32,\n",
    "              'BoxCoverDead': np.int32,\n",
    "              'BoxWood': np.int32,\n",
    "              'BoxWoodDead': np.int32,\n",
    "              'BoxVeg': np.int32,\n",
    "              'BoxVegDead': np.int32,\n",
    "              'QuadCoverTotal': np.int32,\n",
    "              'QuadCoverDead': np.int32,\n",
    "              'QuadWood': np.int32,\n",
    "              'QuadWoodDead': np.int32,\n",
    "              'QuadVeg': np.int32,\n",
    "              'QuadVegDead': np.int32,\n",
    "              'comments': str\n",
    "             }\n",
    "df_nest_seasonal = pd.read_csv(nest_seasonal_file, \n",
    "                             header=0, \n",
    "                             encoding='utf-8',\n",
    "                             parse_dates=['date'],\n",
    "                             error_bad_lines=False,\n",
    "                             warn_bad_lines=True)\n",
    "\n",
    "if df_nest_static is not None:\n",
    "    print(str(time.ctime()), 'Success: loaded {0:,} records.'.format(len(df_nest_seasonal)))\n",
    "else:\n",
    "    print(str(time.ctime()), '### FAILED! ###')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update and cleanse fields\n",
    "* Nest IDs to be all uppercase\n",
    "* recalculate the `year` and `season`\n",
    "* create the unique ID `BoxSeasYear`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure the nest IDs are all caps\n",
    "df_nest_seasonal['nest_id'] = df_nest_seasonal['nest_id'].apply(lambda x: x.upper())\n",
    "\n",
    "# recalculate year (because was manually created)\n",
    "df_nest_seasonal['year'] = df_nest_seasonal['date'].apply(lambda x: x.year)\n",
    "\n",
    "# recalculate season\n",
    "def season(date):\n",
    "    if date.month >= 3 and date.month <= 5:\n",
    "        return 'AUTUMN'\n",
    "    elif date.month >= 6 and date.month <= 8:\n",
    "        return 'WINTER'\n",
    "    elif date.month >= 9 and date.month <= 11:\n",
    "        return 'SPRING'\n",
    "    elif (date.month >= 1 and date.month <= 2) or date.month == 12:\n",
    "        return 'SUMMER'\n",
    "    else:\n",
    "        return None\n",
    "    \n",
    "df_nest_seasonal['season'] = df_nest_seasonal['date'].apply(lambda x: season(x))\n",
    "\n",
    "# calc the unique ID\n",
    "df_nest_seasonal['BoxSeasYear'] = df_nest_seasonal['nest_id'] + df_nest_seasonal['season'] + df_nest_seasonal['year'].apply(lambda x: str(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Read in the BreedingDataCombined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:24 2016 Loading the Breeding data.\n",
      "\n",
      "Sun Nov  6 21:04:24 2016 Breeding file is 0.1 MB.\n",
      "Sun Nov  6 21:04:24 2016 Loading into memory. \n",
      "Sun Nov  6 21:04:24 2016 Success: loaded 3,575 records.\n"
     ]
    }
   ],
   "source": [
    "print(str(time.ctime()), 'Loading the Breeding data.', flush=True)\n",
    "\n",
    "file_size = os.path.getsize(breeding_data_file)\n",
    "print('\\n{0} Breeding file is {1:.1f} MB.'.format(str(time.ctime()), (file_size/1000000)))\n",
    "\n",
    "if file_size > 5000000: # over 5mb\n",
    "    print(str(time.ctime()), 'Loading into memory. Please be patient. ', flush=True)\n",
    "else:\n",
    "    print(str(time.ctime()), 'Loading into memory. ', flush=True)\n",
    "\n",
    "data_types = {'nest_id': str,\n",
    "              'observation_date': str,\n",
    "              'ActivityStatus': np.int32,\n",
    "              'adult': np.int32,\n",
    "              'clutch': np.int32,\n",
    "              'eggs': np.int32,\n",
    "              'ChicksAlive': np.int32,\n",
    "              'ChicksDead': np.int32,\n",
    "              'ChicksAge': np.int32,\n",
    "              'ChicksFledge': np.int32,\n",
    "              'ChicksMissing': np.int32,\n",
    "              'ContentsNotVisible': np.int32,\n",
    "              'EggLayDate': str,\n",
    "              'IDChick1': np.int32,\n",
    "              'MassChick1': np.int32,\n",
    "              'IDChick2': np.int32,\n",
    "              'MassChick2': np.int32,\n",
    "              'comments': str\n",
    "             }\n",
    "df_breeding = pd.read_csv(breeding_data_file, \n",
    "                             header=0, \n",
    "                             encoding='utf-8',\n",
    "                             parse_dates=['observation_date', 'EggLayDate'],\n",
    "                             error_bad_lines=False,\n",
    "                             warn_bad_lines=True)\n",
    "\n",
    "if df_breeding is not None:\n",
    "    print(str(time.ctime()), 'Success: loaded {0:,} records.'.format(len(df_breeding)))\n",
    "else:\n",
    "    print(str(time.ctime()), '### FAILED! ###')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean and add columns\n",
    "* `year` is year of `observation_date`\n",
    "* make `nest_id` uppercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# make sure the nest IDs are all caps\n",
    "df_breeding['nest_id'] = df_breeding['nest_id'].apply(lambda x: x.upper())\n",
    "\n",
    "# create year field\n",
    "df_breeding['year'] = df_breeding['observation_date'].apply(lambda x: x.year)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Aggregate the Breeding data to get annual stats\n",
    "* _nest_id_\n",
    "* _year_\n",
    "* _clutch_\n",
    "* clutch_count\n",
    "* egg_count\n",
    "* chick_count\n",
    "* fletch_count\n",
    "* lay_date\n",
    "* age_at_fletching\n",
    "* mass_at_fletching_chick1\n",
    "* mass_at_fletching_chick2\n",
    "* chick_id1\n",
    "* chick_id2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:24 2016 Aggregating breeding data to get annual stats.\n"
     ]
    }
   ],
   "source": [
    "print(str(time.ctime()), 'Aggregating breeding data to get annual stats.', flush=True)\n",
    "\n",
    "# get the clutches per nest and year\n",
    "# [[chosen columns]] -> groupby -> apply max -> add suffix -> remove multi-index\n",
    "df_clutch_count = df_breeding[['nest_id', 'year', 'clutch']\n",
    "                             ].groupby(['nest_id', 'year']).max().add_suffix('_count').reset_index()\n",
    "\n",
    "# get the annual stats per nest, year and clutch\n",
    "temp = df_breeding[['nest_id', 'year', 'clutch', 'eggs', 'ChicksAlive', 'ChicksFledge', 'EggLayDate', 'ChicksAge', 'MassChick1', 'MassChick2', 'IDChick1', 'IDChick2']].copy()\n",
    "df_breeding_gb = temp.groupby(['nest_id', 'year', 'clutch']).max().reset_index()\n",
    "df_breeding_gb.rename(columns = {'eggs': 'egg_count', 'ChicksAlive': 'chick_count', 'ChicksFledge': 'fledge_count', \n",
    "                     'EggLayDate': 'lay_date', 'ChicksAge': 'age_at_fledging', 'MassChick1': 'mass_at_fletching_chick1', \n",
    "                     'MassChick2': 'mass_at_fletching_chick1'}\n",
    "          , inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the temperature data\n",
    "Read the temperature data file into memory and report on success/failure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:24 2016 Combined temp and humidity file found. Skipping the temp data load.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), 'Combined temp and humidity file found. Skipping the temp data load.', flush=True)\n",
    "else:\n",
    "    column_names = ['recnum', 'datetime', 'temp_c', 'nest_id']\n",
    "    data_types = {'recnum': np.int32, \n",
    "                  'datetime': str, \n",
    "                  'temp_c': np.float32, \n",
    "                  'nest_id': str}\n",
    "    file_size = os.path.getsize(temperature_file)\n",
    "    print('\\n{0} Temperature is {1:.1f} MB.'.format(str(time.ctime()), \n",
    "                                                                                     (file_size/1000000)))\n",
    "\n",
    "    if file_size > 5000000: # over 5mb\n",
    "        print(str(time.ctime()), 'Loading into memory. Please be patient. ', flush=True)\n",
    "    else:\n",
    "        print(str(time.ctime()), 'Loading into memory. ', flush=True)\n",
    "\n",
    "    df_temp = pd.read_csv(temperature_file,\n",
    "                         names=column_names,\n",
    "                         usecols=[0,1,2,3],\n",
    "                         dtype=data_types,\n",
    "#                          nrows=10000,               # for testing only\n",
    "                          parse_dates=['datetime'],\n",
    "                          dayfirst=True,\n",
    "                          encoding='utf-8',\n",
    "                          error_bad_lines=False,\n",
    "                          warn_bad_lines=True\n",
    "                         )\n",
    "\n",
    "    if df_temp is not None:\n",
    "        print(str(time.ctime()), 'Success: loaded {0:,} records.'.format(len(df_temp)))\n",
    "    else:\n",
    "        print(str(time.ctime()), '### FAILED! ###')\n",
    "    \n",
    "    # make sure the nest IDs are all caps\n",
    "    df_temp['nest_id'] = df_temp['nest_id'].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:24 2016 Combined temp and humidity file found. Skipping the humidity data load.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), 'Combined temp and humidity file found. Skipping the humidity data load.', flush=True)\n",
    "else:\n",
    "    column_names = ['recnum', 'datetime', 'humidity', 'nest_id']\n",
    "    data_types = {'recnum': np.int32, \n",
    "                  'datetime': str, \n",
    "                  'humidity': np.float32, \n",
    "                  'nest_id': str}\n",
    "    file_size = os.path.getsize(humidity_file)\n",
    "    print('\\n{0} Humidity file is {1:.1f} MB.'.format(str(time.ctime()),\n",
    "                                                      (file_size/1000000)), flush=True)\n",
    "\n",
    "    if file_size > 5000000: # over 5mb\n",
    "        print(str(time.ctime()), 'Loading into memory. Please be patient. ', flush=True)\n",
    "    else:\n",
    "        print(str(time.ctime()), 'Loading into memory. ', flush=True, end='')\n",
    "\n",
    "    df_humd = pd.read_csv(humidity_file,\n",
    "                         names=column_names,\n",
    "                         usecols=[0,1,2,3],\n",
    "                         dtype=data_types,\n",
    "#                          nrows=10000,               # for testing only\n",
    "                          parse_dates=['datetime'],\n",
    "                          dayfirst=True,\n",
    "                          encoding='utf-8',\n",
    "                          error_bad_lines=False,\n",
    "                          warn_bad_lines=True\n",
    "                         )\n",
    "\n",
    "    if df_humd is not None:\n",
    "        print(str(time.ctime()), 'Success: loaded {0:,} records.'.format(len(df_humd)))\n",
    "    else:\n",
    "        print(str(time.ctime()), '### FAILED! ###')\n",
    "    \n",
    "    # make sure the nest IDs are all caps\n",
    "    df_humd['nest_id'] = df_humd['nest_id'].apply(lambda x: x.upper())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:24 2016 Combined temp and humidity file found. Skipping the temp and humidity data join.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), 'Combined temp and humidity file found. Skipping the temp and humidity data join.', flush=True)\n",
    "else:\n",
    "    print('\\n{0} Joining the temperature and humidity data sets.'.format(str(time.ctime())), flush=True)\n",
    "    df_sensor_data = pd.merge(left=df_temp,\n",
    "                            right=df_humd,\n",
    "                            how='outer',\n",
    "                            on=['nest_id', 'datetime'], # both have same keys\n",
    "                            left_on=None, # same key names: don't need to specify R and L\n",
    "                            right_on=None, # same key names: don't need to specify R and L\n",
    "                            left_index=False, # dont' use left df index as key\n",
    "                            right_index=False, # dont' use right df index as key\n",
    "                            sort=True, # for efficiency do/not sort the df first\n",
    "                            suffixes=['_temp', '_humd']\n",
    "                            )[['nest_id', 'datetime', 'temp_c', 'humidity']] # take only these cols\n",
    "\n",
    "    print('{0} Join complete. Here are the stats:'.format(str(time.ctime())))\n",
    "    print('Records in temperature data: {0:>20,}'.format(len(df_temp)))\n",
    "    print('Records in humidity data:    {0:>20,}'.format(len(df_humd)))\n",
    "    print('                              -------------------')\n",
    "    print('Records in joined data:      {0:>20,}'.format(len(df_sensor_data)))\n",
    "    print('\\nOverview:')\n",
    "    gb = df_sensor_data.groupby(['nest_id'])\n",
    "    print('Number of nest_ids:          {0:>20,}'.format(len(gb)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the joined temp and humidity csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sun Nov  6 21:04:24 2016 Combined temp and humidity file is 167.9 MB.\n",
      "Sun Nov  6 21:04:24 2016 Loading into memory. Please be patient. \n",
      "Sun Nov  6 21:04:29 2016 Success: loaded 2,173,738 records.\n"
     ]
    }
   ],
   "source": [
    "if df_sensor_data is None and os.path.isfile(joined_data_file):\n",
    "    data_types = {'nest_id': str,\n",
    "    #               'recnum': np.int32, \n",
    "                  'datetime': str, \n",
    "                  'temp_c': np.float32,\n",
    "                  'humidity': np.float32, \n",
    "                  'breeding_year': np.int32}\n",
    "    file_size = os.path.getsize(joined_data_file)\n",
    "    print('\\n{0} Combined temp and humidity file is {1:.1f} MB.'.format(str(time.ctime()), (file_size/1000000)))\n",
    "\n",
    "    if file_size > 5000000: # over 5mb\n",
    "        print(str(time.ctime()), 'Loading into memory. Please be patient. ', flush=True)\n",
    "    else:\n",
    "        print(str(time.ctime()), 'Loading into memory. ', flush=True, end='')\n",
    "\n",
    "    df_sensor_data = pd.read_csv(joined_data_file,\n",
    "    #                      names=column_names,\n",
    "    #                      usecols=[0,1,2,3],\n",
    "                         dtype=data_types,\n",
    "    #                      nrows=2048,               # for testing only\n",
    "                          parse_dates=['datetime'],\n",
    "                          dayfirst=True,\n",
    "                          encoding='utf-8',\n",
    "                          error_bad_lines=False,\n",
    "                          warn_bad_lines=True\n",
    "                         )\n",
    "\n",
    "    if df_sensor_data is not None:\n",
    "        print(str(time.ctime()), 'Success: loaded {0:,} records.'.format(len(df_sensor_data)))\n",
    "    else:\n",
    "        print(str(time.ctime()), '### FAILED! ###')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculations per-sensor reading\n",
    "The following calculations are added per sensor reading:\n",
    "* The `breeding_year`: same as the calendar year\n",
    "* `temp_bucket` is a category for each 5C temperature range: <0, 0-5, .., 60+\n",
    "* `humidity_bucket`: is a category for roughly 20% humidity ranges, based on human comfort zones\n",
    "* `average_activity_phase`: the average activity conducted at the time of the observation\n",
    "\n",
    "### To be added:\n",
    "* `actual_activity_phase`: Is the current phase of breeding based on per-nest observations. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def temp_bucket(temp_c):\n",
    "    result = None\n",
    "    if temp_c < 0:\n",
    "        result = 'temp_<0'\n",
    "    elif temp_c >= 0 and temp_c < 5:\n",
    "        result = 'temp_0-5'\n",
    "    elif temp_c >= 5 and temp_c < 10:\n",
    "        result = 'temp_5-10'\n",
    "    elif temp_c >= 10 and temp_c < 15:\n",
    "        result = 'temp_10-15'\n",
    "    elif temp_c >= 15 and temp_c < 20:\n",
    "        result = 'temp_15-20'\n",
    "    elif temp_c >= 20 and temp_c < 25:\n",
    "        result = 'temp_20-25'\n",
    "    elif temp_c >= 25 and temp_c < 30:\n",
    "        result = 'temp_25-30'\n",
    "    elif temp_c >= 30 and temp_c < 35:\n",
    "        result = 'temp_30-35'\n",
    "    elif temp_c >= 35 and temp_c < 40:\n",
    "        result = 'temp_35-40'\n",
    "    elif temp_c >= 40 and temp_c < 45:\n",
    "        result = 'temp_40-45'\n",
    "    elif temp_c >= 45 and temp_c < 50:\n",
    "        result = 'temp_45-50'\n",
    "    elif temp_c >= 50 and temp_c < 55:\n",
    "        result = 'temp_50-55'\n",
    "    elif temp_c >= 55 and temp_c < 60:\n",
    "        result = 'temp_55-60'\n",
    "    elif temp_c >= 60:\n",
    "        result = 'temp_60+'\n",
    "    return result\n",
    "\n",
    "def humidity_bucket(humidity):\n",
    "    result = None\n",
    "    if humidity < 20: # lung & eye irritation in humans\n",
    "        result = 'RH%_<20'\n",
    "    elif humidity >= 20 and humidity < 30: # lung irritation in humans\n",
    "        result = 'RH%_20-30'\n",
    "    elif humidity >= 30 and humidity < 50: # low but not dangerous to humans\n",
    "        result = 'RH%_30-50'\n",
    "    elif humidity >= 50 and humidity < 60: # human ideal comfort zone \n",
    "        result = 'RH%_50-60'\n",
    "    elif humidity >= 60 and humidity < 80: # humid\n",
    "        result = 'RH%_60-80'\n",
    "    elif humidity >= 80 and humidity < 100: # v humid\n",
    "        result = 'RH%_80-100'\n",
    "    elif humidity >= 100: # dripping \n",
    "        result = 'RH%_100+'\n",
    "    return result\n",
    "\n",
    "def average_activity_phase(sensor_datetime):\n",
    "    '''\n",
    "    Returns the current phase of breeding based on per-nest observations. Phases are generally:\n",
    "    1 Jan - 31 Mar: moulting\n",
    "    1 Apr - 31 May: nest building\n",
    "    1 Jun - 30 Jun: laying\n",
    "    1 Jul - 7 Aug: incubating\n",
    "    8 Aug - 30 Sep: rearing\n",
    "    1 Oct - 30 Oct: fledging\n",
    "    1 Nov - 31 Dec: post-fledging\n",
    "    There can be two lays per season. The second lay is not considered in the average timeframes \n",
    "    above.\n",
    "    '''\n",
    "    if sensor_datetime is None:\n",
    "        return None\n",
    "    elif sensor_datetime.month >= 1 and sensor_datetime.month <= 3:\n",
    "        return 'moulting'\n",
    "    elif sensor_datetime.month >= 4 and sensor_datetime.month >= 5:\n",
    "        return 'nest building'\n",
    "    elif sensor_datetime.month == 6:\n",
    "        return 'laying'\n",
    "    elif sensor_datetime.month == 7:\n",
    "        return 'incubating'\n",
    "    elif sensor_datetime.month == 8 and date(sensor_datetime.year, sensor_datetime.month, sensor_datetime.day) <= date(sensor_datetime.year, 8, 7):\n",
    "        return 'incubating'\n",
    "    elif sensor_datetime.month == 8 and date(sensor_datetime.year, sensor_datetime.month, sensor_datetime.day) > date(sensor_datetime.year, 8, 7):\n",
    "        return 'rearing'\n",
    "    elif sensor_datetime.month >= 9:\n",
    "        return 'rearing'\n",
    "    elif sensor_datetime.month >= 10:\n",
    "        return 'fledging'\n",
    "    elif sensor_datetime.month in [11, 12]:\n",
    "        return 'post-fledging'\n",
    "    else:\n",
    "        return 'unknown'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:29 2016 Combined temp and humidity file found. Skipping calculated fields.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), 'Combined temp and humidity file found. Skipping calculated fields.', flush=True)\n",
    "else:\n",
    "    # add the breeding_year (same as financial year): \n",
    "    print(str(time.ctime()), 'Calculating breeding year.', end='', flush=True)\n",
    "    df_sensor_data['breeding_year'] = df_sensor_data['datetime'].apply(lambda x: x.year)\n",
    "    print(' Done.', flush=True)\n",
    "\n",
    "    # # add the average breeding phases \n",
    "    print(str(time.ctime()), 'Calculating average activity periods.', end='', flush=True)\n",
    "    df_sensor_data['average_activity_period'] = df_sensor_data['datetime'].apply(average_activity_phase)\n",
    "    print(' Done.', flush=True)\n",
    "\n",
    "    # Add flags for various temperature ranges. \n",
    "    # These are summed to give the amount of time in the temp band\n",
    "    print(str(time.ctime()), 'Calculating temperature buckets.', end='', flush=True)\n",
    "    df_sensor_data['temp_bucket'] = df_sensor_data['temp_c'].apply(temp_bucket)\n",
    "    print(' Done.', flush=True)\n",
    "\n",
    "    # # Add flags for various humidity ranges. \n",
    "    # # These are summed to give the amount of time in the humidity band\n",
    "    print(str(time.ctime()), 'Calculating humidity buckets.', end='', flush=True)\n",
    "    df_sensor_data['humidity_bucket'] = df_sensor_data['humidity'].apply(humidity_bucket)\n",
    "    print(' Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write the created data to file to use again in future."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:29 2016 Combined temp and humidity file found. Skipping writing the combined data to file.\n"
     ]
    }
   ],
   "source": [
    "if os.path.isfile(joined_data_file):\n",
    "    print(str(time.ctime()), 'Combined temp and humidity file found. Skipping writing the combined data to file.', flush=True)\n",
    "else:\n",
    "    print('\\n{0} Writing the joined dataset to csv.'.format(str(time.ctime())), flush=True)\n",
    "    df_sensor_data.to_csv(path_or_buf=joined_data_file,\n",
    "                     sep=',',\n",
    "                     na_rep='',\n",
    "                     float_format='%.3f',\n",
    "                     header=True,\n",
    "                     index=False,\n",
    "                     mode='w',\n",
    "                     encoding='utf-8')\n",
    "    print('{0} File written: {1} ({2:.1f}MB)'.format(str(time.ctime()), str(joined_data_file), os.path.getsize(joined_data_file)/1000000), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Join the data sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the NestCharacteristic Static and Seasonal data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:29 2016 Joining the Nest Characteristic (Seasonal and Static) data sets .\n",
      "Sun Nov  6 21:04:29 2016 Join complete. Here are the stats:\n",
      "Records in seasonal data:                   1,711\n",
      "Records in static data:                       241\n",
      "                              -------------------\n",
      "Records in joined data:                     1,711\n",
      "\n",
      "Overview:\n",
      "Number of nest_ids:                           193\n"
     ]
    }
   ],
   "source": [
    "print('{0} Joining the Nest Characteristic (Seasonal and Static) data sets .'.format(str(time.ctime())), flush=True)\n",
    "df_nest_joined = pd.merge(left=df_nest_seasonal,\n",
    "                            right=df_nest_static,\n",
    "                            how='left',\n",
    "                            on=['nest_id'], # both have same keys\n",
    "                            left_on=None, # same key names: don't need to specify R and L\n",
    "                            right_on=None, # same key names: don't need to specify R and L\n",
    "                            left_index=False, # dont' use left df index as key\n",
    "                            right_index=False, # dont' use right df index as key\n",
    "                            sort=True, # for efficiency do/not sort the df first\n",
    "                            suffixes=['_seasonal', '_static']\n",
    "                            )\n",
    "if df_nest_joined is not None:\n",
    "    print('{0} Join complete. Here are the stats:'.format(str(time.ctime())))\n",
    "    print('Records in seasonal data:    {0:>20,}'.format(len(df_nest_seasonal)))\n",
    "    print('Records in static data:      {0:>20,}'.format(len(df_nest_static)))\n",
    "    print('                              -------------------')\n",
    "    print('Records in joined data:      {0:>20,}'.format(len(df_nest_joined)))\n",
    "    print('\\nOverview:')\n",
    "    gb = df_nest_joined.groupby(['nest_id'])\n",
    "    print('Number of nest_ids:          {0:>20,}'.format(len(gb)))\n",
    "else:\n",
    "    print('{0} JOIN FAILED!!!.'.format(str(time.ctime())), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the breeding stats together\n",
    "Clutch counts per year and annual clutch survival stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sun Nov  6 21:04:29 2016 Merging the aggregated breeding stats.\n",
      "Sun Nov  6 21:04:29 2016 Join complete. Here are the stats:\n",
      "Records in annual stats data:                  267\n",
      "Records in clutch count data:                  302\n",
      "                              -------------------\n",
      "Records in joined data:                        267\n",
      "\n",
      "Overview:\n",
      "Number of nest_ids in clutch count:            129\n",
      "Number of nest_ids in breeding stats:          121\n",
      "Number of nest_ids in joined:                  121\n"
     ]
    }
   ],
   "source": [
    "# join the clutch count on to the annual stats\n",
    "print('\\n{0} Merging the aggregated breeding stats.'.format(str(time.ctime())), flush=True)\n",
    "df_breeding_annual_stats = pd.merge(left=df_breeding_gb,\n",
    "                        right=df_clutch_count,\n",
    "                        how='left',\n",
    "                        on=['nest_id', 'year'], # both have same keys\n",
    "#                             left_on=None, # same key names: don't need to specify R and L\n",
    "#                             right_on=None, # same key names: don't need to specify R and L\n",
    "#                             left_index=False, # dont' use left df index as key\n",
    "#                             right_index=False, # dont' use right df index as key\n",
    "                        sort=True # for efficiency do/not sort the df first\n",
    "#                             suffixes=['_temp', '_humd']\n",
    "                        )#[['nest_id', 'datetime', 'temp_c', 'humidity']] # take only these cols\n",
    "\n",
    "print('{0} Join complete. Here are the stats:'.format(str(time.ctime())))\n",
    "print('Records in annual stats data: {0:>20,}'.format(len(df_breeding_gb)))\n",
    "print('Records in clutch count data: {0:>20,}'.format(len(df_clutch_count)))\n",
    "print('                              -------------------')\n",
    "print('Records in joined data:       {0:>20,}'.format(len(df_breeding_annual_stats)))\n",
    "print('\\nOverview:')\n",
    "gb = df_breeding_annual_stats.groupby(['nest_id'])\n",
    "print('Number of nest_ids in clutch count:   {0:>12,}'.format(len(df_clutch_count.groupby(['nest_id']))))\n",
    "print('Number of nest_ids in breeding stats: {0:>12,}'.format(len(df_breeding_gb.groupby(['nest_id']))))\n",
    "print('Number of nest_ids in joined:         {0:>12,}'.format(len(df_breeding_annual_stats.groupby(['nest_id']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the Nest data (seasonal and static) to the Breeding stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Sun Nov  6 21:04:29 2016 Merging the aggregated breeding stats to the static and seasonal nest data.\n",
      "Sun Nov  6 21:04:29 2016 Join complete. Here are the stats:\n",
      "Records in nest data:                        1,711\n",
      "Records in breeding stats data:                267\n",
      "                                      ------------\n",
      "Records in joined data:                      2,927\n",
      "\n",
      "Overview:\n",
      "Number of nest_ids in nest data:               193\n",
      "Number of nest_ids in breeding stats:          121\n",
      "Number of nest_ids in joined:                  193\n"
     ]
    }
   ],
   "source": [
    "# join the annual clutch and breeding stats onto the full seasonal and static nest data\n",
    "print('\\n{0} Merging the aggregated breeding stats to the static and seasonal nest data.'.format(str(time.ctime())), flush=True)\n",
    "df_nest_and_breeding = pd.merge(left=df_nest_joined,\n",
    "                        right=df_breeding_annual_stats,\n",
    "                        how='left',\n",
    "                        on=['nest_id'], # both have same keys\n",
    "#                             left_on=None, # same key names: don't need to specify R and L\n",
    "#                             right_on=None, # same key names: don't need to specify R and L\n",
    "#                             left_index=False, # dont' use left df index as key\n",
    "#                             right_index=False, # dont' use right df index as key\n",
    "                        sort=True # for efficiency do/not sort the df first\n",
    "#                             suffixes=['_temp', '_humd']\n",
    "                        )#[['nest_id', 'datetime', 'temp_c', 'humidity']] # take only these cols\n",
    "\n",
    "print('{0} Join complete. Here are the stats:'.format(str(time.ctime())))\n",
    "print('Records in nest data:                 {0:>12,}'.format(len(df_nest_joined)))\n",
    "print('Records in breeding stats data:       {0:>12,}'.format(len(df_breeding_annual_stats)))\n",
    "print('                                      ------------')\n",
    "print('Records in joined data:               {0:>12,}'.format(len(df_nest_and_breeding)))\n",
    "print('\\nOverview:')\n",
    "gb = df_breeding_annual_stats.groupby(['nest_id'])\n",
    "print('Number of nest_ids in nest data:      {0:>12,}'.format(len(df_nest_joined.groupby(['nest_id']))))\n",
    "print('Number of nest_ids in breeding stats: {0:>12,}'.format(len(df_breeding_annual_stats.groupby(['nest_id']))))\n",
    "print('Number of nest_ids in joined:         {0:>12,}'.format(len(df_nest_and_breeding.groupby(['nest_id']))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Aggregate the sensor data into stats per breeding phase\n",
    "To understand the effect of nest conditions (from sensor data) in the choice of nest and breeding success of the nest, we need to break up the stats into:\n",
    "* *annual stats* which represent the averages, spikes etc for the entire year. These give an understanding of the nest itself.\n",
    "* *phase stats* which represent the conditions during specific phases of the breeding cycle. E.g. during nesting, during incubation, during rearing. To get these phase stats, we need to get the phase boundary dates from the breeding observation data.\n",
    "\n",
    "The nest sensor readings are aggregated to summarise the nest conditions by `nest`, `breeding_year` and `activity_phase`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "### Get the phase dates\n",
    "Summarise the breeding data to obtain the following:\n",
    "* list of all nests (regardless of breeding activity)\n",
    "* the `nesting_date` for each nest in each year\n",
    "* the `egg_lay_date` for each nest, year and clutch\n",
    "* the `hatch_date` for each nest, year and clutch\n",
    "* the `fledge_date` for each nest, year and clutch\n",
    "\n",
    "Join these all back together to get the phase dates all in one place, then join the combined result on to the sensor data table and calculate the phase in which each sensor reading occurred.\n",
    "This will take a while.\n",
    "\n",
    "**Issue: Nesting dates dont work: the second clutch will have first nesting date and the first obs for many nests is after the lay date, so nesting_date > lay_date**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:29 2016 Calculating the breeding phase dates for each nest and year.\n",
      "Sun Nov  6 21:04:30 2016 Merging the phase date tables.\n"
     ]
    }
   ],
   "source": [
    "# for each nest, year and clutch, get the following:\n",
    "# first activity_status date (nesting_date), EggLayDate, hatch_date, fledge_date\n",
    "# nesting_date, hatch_date, fledge_date are the min observation_date per nest, year, clutch where the value is not NaN\n",
    "\n",
    "print('{0} Calculating the breeding phase dates for each nest and year.'.format(str(time.ctime())), flush=True)\n",
    "# all observed nests\n",
    "df_all_nests = df_nest_static[['nest_id']].drop_duplicates()\n",
    "\n",
    "# egg_lay_date\n",
    "gb_lay_date = df_breeding[['nest_id', 'year', 'clutch', 'EggLayDate']\n",
    "                         ].groupby(['nest_id', 'year', 'clutch']).min().reset_index()\n",
    "gb_lay_date.rename(columns={'EggLayDate': 'egg_lay_date'}, inplace=True)\n",
    "\n",
    "# nesting date: 31 days before egg_lay_date\n",
    "gb_lay_date['courting_date'] = gb_lay_date['egg_lay_date'] - datetime.timedelta(days=31)\n",
    "\n",
    "# hatch_date\n",
    "def hatch_date(row):\n",
    "    return row['observation_date'] - datetime.timedelta(days=row['ChicksAge'])\n",
    "# get the observation date (select columns)                    where age is not blank (i.e. they're there)\n",
    "gb_hatch_date = df_breeding[['nest_id', 'year', 'clutch', 'observation_date', 'ChicksAge']].loc[df_breeding['ChicksAge'].notnull()]\n",
    "gb_hatch_date['hatch_date'] = gb_hatch_date.apply(hatch_date, axis=1)\n",
    "# get the min hatch_date \n",
    "gb_hatch_date = gb_hatch_date[['nest_id', 'year', 'clutch', 'hatch_date']].groupby(['nest_id', 'year', 'clutch']).min().reset_index()\n",
    "\n",
    "# fledge_date\n",
    "# is either the date that the chicks were of age and no longer observed in the nest, or were observed dead\n",
    "# get the observation date (select columns) where there is a fledge flag\n",
    "gb_fledge_date = df_breeding[['nest_id', 'year', 'clutch', 'observation_date', 'ChicksAlive', 'ChicksDead', 'ChicksFledge']].fillna(0)\n",
    "gb_fledge_date['dead_or_fledged'] = gb_fledge_date.apply(lambda row: row['ChicksFledge'] > 0 or (row['ChicksDead'] > 0 and row['ChicksAlive'] == 0), axis=1)\n",
    "gb_fledge_date = gb_fledge_date.query('dead_or_fledged')\n",
    "# get the min obs date, which is the earliest fledge recording (per clutch)\n",
    "gb_fledge_date = gb_fledge_date[['nest_id', 'year', 'clutch', 'observation_date']].groupby(['nest_id', 'year', 'clutch']).min().reset_index()\n",
    "# rename the obs date \n",
    "gb_fledge_date.rename(columns={'observation_date': 'dead_or_fledge_date'}, inplace=True)\n",
    "\n",
    "# join the key date tables together\n",
    "print('{0} Merging the phase date tables.'.format(str(time.ctime())), flush=True)\n",
    "df_phase_dates = pd.merge(left=df_all_nests, right=gb_lay_date, how='left', on=['nest_id'], sort=True)\n",
    "df_phase_dates = pd.merge(left=df_phase_dates, right=gb_hatch_date, how='left', on=['nest_id', 'year', 'clutch'], sort=True)\n",
    "df_phase_dates = pd.merge(left=df_phase_dates, right=gb_fledge_date, how='left', on=['nest_id', 'year', 'clutch'], sort=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `sensor_data` are lacking a `clutch` number, which will create duplicates if we attempt to join on the phase dates. Get the clutch dates and join them into the `sensor_data`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:04:30 2016 Pivot breeding data to get the clutch dates.\n",
      "Sun Nov  6 21:04:30 2016 Join the clutch dates to the sensor data.\n",
      "Sun Nov  6 21:04:30 2016 Done. Rows: 2,173,738\n",
      "Sun Nov  6 21:04:30 2016 Assigning a clutch number to each sensor record. Be patient.\n",
      "Sun Nov  6 21:08:29 2016 Done.\n"
     ]
    }
   ],
   "source": [
    "print('{0} Pivot breeding data to get the clutch dates.'.format(str(time.ctime())), flush=True)\n",
    "# to avoid making epic dupes, we need to first add the clutch number on to the sensor data table\n",
    "# get the required cols\n",
    "df_clutch_pivot = gb_lay_date[['nest_id', 'year', 'clutch', 'egg_lay_date']].copy()\n",
    "# we have to combine the index because pivot() does not like a multi-index\n",
    "df_clutch_pivot['nestyear'] = df_clutch_pivot['nest_id'] + '-' + df_clutch_pivot['year'].apply(lambda x: str(x))\n",
    "# drop the old index fields\n",
    "df_clutch_pivot = df_clutch_pivot = df_clutch_pivot[['nestyear', 'clutch', 'egg_lay_date']]\n",
    "# do the pivot to get the (up to three) clutch dates per nest and year\n",
    "df_clutch_pivot = df_clutch_pivot.pivot(index='nestyear', columns='clutch')['egg_lay_date'].reset_index()\n",
    "# rename and restore the indexes\n",
    "df_clutch_pivot.rename(columns={1.0: 'clutch_1', 2.0: 'clutch_2', 3.0: 'clutch_3'}, inplace=True)\n",
    "df_clutch_pivot['nest_id'] = df_clutch_pivot['nestyear'].apply(lambda x: x.split('-')[0])\n",
    "df_clutch_pivot['breeding_year'] = df_clutch_pivot['nestyear'].apply(lambda x: int(x.split('-')[1]))\n",
    "df_clutch_pivot = df_clutch_pivot[['nest_id', 'breeding_year', 'clutch_1', 'clutch_2', 'clutch_3']]\n",
    "\n",
    "print('{0} Join the clutch dates to the sensor data.'.format(str(time.ctime())), flush=True)\n",
    "# join on to teh sensor data\n",
    "df_sensor_clutch = pd.merge(left=df_sensor_data, right=df_clutch_pivot, how='left', on=['nest_id', 'breeding_year'], sort=True)\n",
    "print('{0} Done. Rows: {1:,}'.format(str(time.ctime()), len(df_sensor_clutch)), flush=True)\n",
    "\n",
    "print('{0} Assigning a clutch number to each sensor record. Be patient.'.format(str(time.ctime())), flush=True)\n",
    "# flag each reading with a clutch number\n",
    "def clutch_number(row):\n",
    "    if pd.isnull(row['clutch_1']):\n",
    "        # there are no breeding observations for this nest and year\n",
    "        return 0\n",
    "    else:\n",
    "        # there is at least 1 clutch\n",
    "        if pd.isnull(row['clutch_2']) or row['datetime'] < row['clutch_2']:\n",
    "            # there was only a single clutch, or there were >1 but this reading was before the 2nd clutch\n",
    "            return 1\n",
    "        elif pd.isnull(row['clutch_3']) or (not pd.isnull(row['clutch_3']) and row['datetime'] < row['clutch_3']):\n",
    "            # there is a 2nd clutch if we got this far. if there is no 3rd, or the reading is before the 3rd, then this is 2nd\n",
    "            return 2\n",
    "        else:\n",
    "            # there is a 3rd clutch and the sensor reading is after the 3rd\n",
    "            return 3\n",
    "\n",
    "df_sensor_clutch['clutch_number'] = df_sensor_clutch.apply(lambda row: clutch_number(row), axis=1)\n",
    "print('{0} Done.'.format(str(time.ctime())), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the breeding phase against each sensor reading\n",
    "1. Join the phase dates on to the sensor data\n",
    "2. Use the phase date to calculate the breeding_phase for each sensor reading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:08:29 2016 Join the phase dates on to the sensor data.\n",
      "Sun Nov  6 21:08:30 2016 Done. Rows: 2,173,738\n"
     ]
    }
   ],
   "source": [
    "print('{0} Join the phase dates on to the sensor data.'.format(str(time.ctime())), flush=True)\n",
    "df_sensor_phase = pd.merge(left=df_sensor_clutch,\n",
    "                        right=df_phase_dates,\n",
    "                        how='left',\n",
    "                        left_on=['nest_id', 'breeding_year', 'clutch_number'], # same key names: don't need to specify R and L\n",
    "                        right_on=['nest_id', 'year', 'clutch'], # same key names: don't need to specify R and L\n",
    "                        sort=True # for efficiency do/not sort the df first\n",
    "#                             suffixes=['_temp', '_humd']\n",
    "                        )\n",
    "print('{0} Done. Rows: {1:,}'.format(str(time.ctime()), len(df_sensor_phase)), flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun Nov  6 21:08:30 2016 Calculating the breeding_phase for each sensor reading. Be patient.\n",
      "Sun Nov  6 21:13:43 2016 Done.\n"
     ]
    }
   ],
   "source": [
    "print('{0} Calculating the breeding_phase for each sensor reading. Be patient.'.format(str(time.ctime())), flush=True)\n",
    "# for each sensor reading, determine the breeding_phase:\n",
    "# 'courting' iff date between nesting_date and egg_lay_date\n",
    "# 'incubating' iff date between egg_lay_date and hatch_date\n",
    "# 'rearing' iff date between hatch_date adn fledge_date\n",
    "# 'courting' iff clutch < clutch_count and date between fledge_date and egg_lay_date\n",
    "# else 'unoccupied' \n",
    "\n",
    "def breeding_phase(row):\n",
    "    if pd.isnull(row['egg_lay_date']) or row['clutch_number'] == 0: \n",
    "        # no activity this year\n",
    "        return 'unoccupied'\n",
    "    \n",
    "    elif pd.isnull(row['hatch_date']):\n",
    "        # laid but never hatched\n",
    "        if row['datetime'] <= row['egg_lay_date'] + datetime.timedelta(days=35):\n",
    "            # this egg never hatches, but the current sensor period is incubation\n",
    "            return 'incubating'\n",
    "        else:\n",
    "            # this egg never hatches, and the current sensor period is past the 35 day incubation period\n",
    "            return 'unoccupied'\n",
    "    \n",
    "    elif pd.isnull(row['dead_or_fledge_date']): \n",
    "        # hatched but never fledged\n",
    "        if row['datetime'] <= row['hatch_date'] + datetime.timedelta(days=80):\n",
    "            # oldest chick at fledge was 77 days, so assume up to 80\n",
    "            return 'rearing'\n",
    "        else:\n",
    "            # the chicks must be missing\n",
    "            return 'unoccupied' \n",
    "    \n",
    "    elif row['datetime'] < row['courting_date']:\n",
    "        # no one has moved in yet\n",
    "        return 'unoccupied'\n",
    "    \n",
    "    elif row['clutch_number'] == 1 and row['courting_date'] <= row['datetime'] <= row['egg_lay_date']:\n",
    "        # for the first clutch, courting is 31 days prior to lay\n",
    "        return 'courting'\n",
    "    \n",
    "    elif row['clutch_number'] > 1 and row['datetime'] <= row['egg_lay_date']:\n",
    "        # consider it courting again between fledging and second clutch\n",
    "        return 'courting'\n",
    "    \n",
    "    elif row['egg_lay_date'] <= row['datetime'] <= row['hatch_date']:\n",
    "        return 'incubating'\n",
    "    \n",
    "    elif row['hatch_date'] <= row['datetime'] <= row['dead_or_fledge_date']:\n",
    "        return 'rearing'\n",
    "    \n",
    "    elif row['datetime'] > row['dead_or_fledge_date']:\n",
    "        return 'unoccupied'\n",
    "    \n",
    "    else:\n",
    "        return 'undefined'\n",
    "\n",
    "df_sensor_phase['breeding_phase'] = df_sensor_phase.apply(lambda row: breeding_phase(row), axis=1)\n",
    "# tempset['breeding_phase'] = tempset.apply(lambda row: breeding_phase(row), axis=1)\n",
    "print('{0} Done.'.format(str(time.ctime())), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ----------------------------------------------------------------\n",
    "# Dev and Test\n",
    "### ----------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df_sensor_phase.to_csv('df_sensor_phase')\n",
    "df_sensor_phase.to_pickle('df_sensor_phase.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sensor_phase = read_pickle('df_sensor_phase.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "test = df_sensor_phase[['nest_id', 'year', 'temp_c']].groupby(['nest_id', 'year']).describe(include='all')\n",
    "test.rename(columns={'temp_c':name}).squeeze() for name, group in test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the annual microclimate stats for each nest\n",
    "This is used to understand the annual nest output absed on it's characteristics in the breeding year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# get the YEARLY temp and humidity mean, min, max, stddev for each nest and year\n",
    "\n",
    "\n",
    "# get the PHASE temp and humidity mean, min, max, stddev for each nest, year, clutch and phase\n",
    "\n",
    "# get the temp and humidity buckets for each nest, year, clutch, phase\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculate the microclimate stats for each nest, year and clutch as well as per-phase \n",
    "This is used to understand how the microclimate affects the outcome of each clutch and nest selection during courting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# join the sensor stats (annual and per-phase) onto the nest_and_breeding data\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# -------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# tempset = df_sensor_phase.query('nest_id in [\"E10\", \"E13\", \"E14\", \"E4\", \"T5\", \"W2\", \"W6\"]')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# TESTING ONLY\n",
    "\n",
    "# temp = df_sensor_phase.query('nest_id in [\"E10\", \"E13\", \"E14\", \"E4\", \"T5\", \"W2\", \"W6\"]')\n",
    "# temp = tempset.query('nest_id in [\"E10\", \"E13\", \"E14\", \"E4\", \"T5\", \"W2\", \"W6\"]')\n",
    "# temp['date'] = temp['datetime'].apply(pd.datetools.normalize_date)\n",
    "# temp = temp[['nest_id', 'date', 'breeding_year','clutch_number', \n",
    "#        'egg_lay_date', 'courting_date', 'hatch_date', 'dead_or_fledge_date',\n",
    "#        'breeding_phase']]\n",
    "# temp = temp.drop_duplicates()\n",
    "\n",
    "# print(len(temp))\n",
    "# temp.to_csv('sensor_phase_test.csv')\n",
    "#E13 2014 egg never hatched:        works\n",
    "#E10 2014 normal single fledge:     works\n",
    "#W6 2014 chick ded:                 works"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Hold off making the dummy columns until we need to do the stats. This keeps the file size down and lets us save the csv with buckets rather than dummies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(str(time.ctime()), 'Creating temp and humidity bucket dummy columns.', end='', flush=True)\n",
    "df_joined = pd.get_dummies(data=df_joined, columns=['temp_bucket', 'humidity_bucket'])\n",
    "print(' Done.', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(str(time.ctime()), 'Aggregating data by nest and year.', flush=True)\n",
    "\n",
    "def percent_of_time(row):\n",
    "    return \n",
    "# group the data by nest_id and breeding year to get the temp and humidity stats per year\n",
    "temp_aggregations = {\n",
    "    'temp_c': {\n",
    "        'temp_count': 'count',\n",
    "        'temp_avg': 'mean',\n",
    "        'temp_min': 'min',\n",
    "        'temp_max': 'max',\n",
    "        'temp_std_dev': 'std'        \n",
    "    },\n",
    "    'humidity': {\n",
    "        'humidity_count': 'count',\n",
    "        'humidity_avg': 'mean',\n",
    "        'humidity_min': 'min',\n",
    "        'humidity_max': 'max',\n",
    "        'humidity_std_dev': 'std'  \n",
    "    },\n",
    "    'temp_<0': {'bucket_total': 'sum'},\n",
    "    'temp_0-5': {'bucket_total': 'sum'},\n",
    "    'temp_5-10': {'bucket_total': 'sum'},\n",
    "    'temp_10-15': {'bucket_total': 'sum'},\n",
    "    'temp_15-20': {'bucket_total': 'sum'},\n",
    "    'temp_20-25': {'bucket_total': 'sum'},\n",
    "    'temp_25-30': {'bucket_total': 'sum'},\n",
    "    'temp_30-35': {'bucket_total': 'sum'},\n",
    "    'temp_35-40': {'bucket_total': 'sum'},\n",
    "    'temp_40-45': {'bucket_total': 'sum'},\n",
    "    'temp_45-50': {'bucket_total': 'sum'},\n",
    "    'temp_50-55': {'bucket_total': 'sum'},\n",
    "    'temp_55-60': {'bucket_total': 'sum'},\n",
    "    'temp_60+': {'bucket_total': 'sum'}    \n",
    "}\n",
    "df_joined_gb = df_joined.groupby(['nest_id', 'breeding_year']).agg(temp_aggregations)\n",
    "print(str(time.ctime()), 'Done.', flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### to add: \n",
    "* return the nest_ids and number and type of missing records"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print(str(time.ctime()), 'Checking for missing data.', flush=True)\n",
    "# check for missing temp or humidity readinga\n",
    "def missing_data(row):\n",
    "    if row['temp_c']['temp_count'] > row['humidity']['humidity_count']:\n",
    "        return 'missing_humidity_data'\n",
    "    elif row['temp_c']['temp_count'] < row['humidity']['humidity_count']:\n",
    "        return 'missing_temp_data'\n",
    "    else:\n",
    "        return None\n",
    "df_joined_gb['missing_data'] = df_joined_gb.apply(missing_data, axis=1)\n",
    "\n",
    "print(str(time.ctime()), 'Done.', flush=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined_gb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_joined_gb['temp_25-30']['%time'] = df_joined_gb['temp_25-30']['bucket_total'] / df_joined_gb['temp_c']['temp_count']\n",
    "df_joined_gb['temp_25-30_total'] = df_joined_gb['temp_25-30']['bucket_total']\n",
    "df_joined_gb['temp_25-30_hours'] = df_joined_gb['temp_25-30_total'] / 4\n",
    "df_joined_gb['temp_25-30_%'] = df_joined_gb['temp_25-30_total'] / df_joined_gb['temp_c']['temp_count']\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined_gb.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_joined_gb.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The below sends the data to the PostGres DB.\n",
    "\n",
    "Currently considering not using the DB at all. While the data maniopulation within the DB via SQL is far easier, keeping the whole project (data load, manipulate, graph) to a single platform and language is a priority."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# #sending temperature dataframe to the postgres DB\n",
    "# print(\"Transferring temperature dataframe to DB..\")\n",
    "# df_temp.to_sql(con=engine, name='penguins_temperature', if_exists='replace')\n",
    "# print(\"Uploaded successfully\")\n",
    "\n",
    "# #sending humidity dataframe to the postgres DB\n",
    "# print(\"Transferring humidity dataframe to DB..\")\n",
    "# df_humd.to_sql(con=engine, name='penguins_humidity', if_exists='replace')\n",
    "# print(\"Uploaded successfully\")\n",
    "\n",
    "# #sending nests dataframe to the postgres DB\n",
    "# print(\"Transferring nests dataframe to DB..\")\n",
    "# nests_raw.to_sql(con=engine, name='penguins_nests', if_exists='replace')\n",
    "# print(\"Uploaded successfully\")"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
