{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Sensor Stats\n",
    "In script A_load_and_combine_data we created a table called df_sensor_phase which contianed the full temperature and humidity sensor readings, together with the breeding_year, season_year and breeding_phase.\n",
    "\n",
    "This script creates a set of aggregates from this data to understand the nest microclimates. The aggregates include:\n",
    "* `Annual stats             -> df_sensor_stats_annual`\n",
    "* `Seasonal stats           -> df_sensor_stats_seasonal`\n",
    "* `Monthly stats            -> df_sensor_stats_monthly`\n",
    "* `Daily stats              -> df_sensor_stats_daily`\n",
    "* `Stats by breeding phase  -> df_sensor_stats_breeding_phase`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the environment\n",
    "### 1.1 Import the required libraries\n",
    "We need a certain set of common libraries for the tasks to be performed. These are imported below. If an import statement errors, you will need to install the library in your environment using the command line command `pip install <library>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up environment and variables...\n"
     ]
    }
   ],
   "source": [
    "print('Setting up environment and variables...', flush=True)\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# all the useful and reuseable functions are defined in helper_functions.py\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set up the variables\n",
    "You will need to change the values of the variables below to suit the names and directory location of your files to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:16 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "# update these with your file paths\n",
    "sensor_phase = os.path.normpath('./output/A_load_and_combine_data/df_sensor_phase.pkl')\n",
    "\n",
    "# write intermediate tables to disk for debugging purposes\n",
    "write_temps = True\n",
    "output_path = os.path.normpath('./output/B_Aggregate_Sensor_Stats')\n",
    "df_sensor_data = None\n",
    "\n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_temp_file(df, filepath, df_name):\n",
    "    '''\n",
    "    If write_temps is true, this function will write the specified Pandas dataframe (df) to csv at the specified location (filepath).\n",
    "    Variables:\n",
    "        df: a Pandas dataframe to be written to csv.\n",
    "        filepath: a string in Unix path format (using / not \\) for the csv destination.\n",
    "        df_name: human readable name or description of the dataframe for logging purposes.\n",
    "    '''\n",
    "    if write_temps:\n",
    "        print('{0} - Writing intermediate table {1} to disk.'.format(str(time.ctime()), df_name, filepath), flush=True)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        df.to_csv(os.path.normpath(filepath))\n",
    "        if os.path.getsize(filepath) > 0:\n",
    "            print('{0} - Written {1}: {2:.3f} MB'.format(str(time.ctime()), filepath, os.path.getsize(filepath)/1000000), flush=True)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Import the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sensor_phase = pd.read_pickle(sensor_phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the aggregate temperature and humidity calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Number of days per month with a temp >= 35C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:19 2017 -    1. Days per month >= 35C...\n",
      "Sun May  7 08:42:19 2017 -    1. Done\n"
     ]
    }
   ],
   "source": [
    "log('   1. Days per month >= 35C...')\n",
    "# get the records > 35\n",
    "# Convert the datetime to a month and day (in addition to the existing breeding_year)\n",
    "# Count the distinct dates per nest per year per month\n",
    "df_temp_above_35C = df_sensor_phase.loc[df_sensor_phase['temp_c'] >= 35].reset_index()\n",
    "gb_monthly_days_above_35C = df_temp_above_35C.groupby(['nest_id', 'breeding_year', 'month']).size()\n",
    "# convert from Series to Dataframe (which has multi-level index)\n",
    "gb_monthly_days_above_35C = gb_monthly_days_above_35C.to_frame()\n",
    "# rename axis 1 to remove the multi-index\n",
    "gb_monthly_days_above_35C = gb_monthly_days_above_35C.rename_axis(None, axis=1).reset_index()\n",
    "gb_monthly_days_above_35C.rename(columns={0: 'days_above_35C'}, inplace=True)\n",
    "log('   1. Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Number of days per season with a temp >= 35C**\n",
    "\n",
    "**Note**: Assumes that Summer 2013 is Jan-Feb13 and Dec13; i.e. all the summer months in the year 2013 rather than the Summer season that starts in 2013 (which would be Dec13-Feb14)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:19 2017 -    2. Days per season >= 35C...\n",
      "Sun May  7 08:42:19 2017 -    2. Done\n"
     ]
    }
   ],
   "source": [
    "log('   2. Days per season >= 35C...')\n",
    "# use the >35C table from #1, sum for each season\n",
    "gb_seasonal_days_above_35C = df_temp_above_35C.groupby(['nest_id', 'season_year', 'season']).size().reset_index()\n",
    "gb_seasonal_days_above_35C.rename(columns={0: 'days_above_35C'}, inplace=True)\n",
    "log('   2. Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Number of days per year with a temp >= 35C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:19 2017 -    3. Days per year >= 35C...\n",
      "Sun May  7 08:42:20 2017 -    3. Done\n"
     ]
    }
   ],
   "source": [
    "log('   3. Days per year >= 35C...')\n",
    "# use the >35C table from #1, sum for each year\n",
    "gb_annual_days_above_35C = df_temp_above_35C.groupby(['nest_id', 'breeding_year']).size()\n",
    "# convert from Series to Dataframe (which has multi-level index)\n",
    "gb_annual_days_above_35C = gb_annual_days_above_35C.to_frame()\n",
    "# rename axis 1 to remove the multi-index\n",
    "gb_annual_days_above_35C = gb_annual_days_above_35C.rename_axis(None, axis=1).reset_index()\n",
    "gb_annual_days_above_35C.rename(columns={0: 'days_above_35C'}, inplace=True)\n",
    "log('   3. Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Number of days per month with a temp >= 40C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:20 2017 -    4. Days per month >= 40C...\n",
      "Sun May  7 08:42:20 2017 -    4. Done\n"
     ]
    }
   ],
   "source": [
    "log('   4. Days per month >= 40C...')\n",
    "# get the records > 40\n",
    "# Convert the datetime to a month and day (in addition to the existing breeding_year)\n",
    "# Count the distinct dates per nest per year per month\n",
    "df_temp_above_40C = df_sensor_phase.loc[df_sensor_phase['temp_c'] >= 40].reset_index()\n",
    "gb_monthly_days_above_40C = df_temp_above_40C.groupby(['nest_id', 'breeding_year', 'month']).size()\n",
    "# convert from Series to Dataframe (which has multi-level index)\n",
    "gb_monthly_days_above_40C = gb_monthly_days_above_40C.to_frame()\n",
    "# rename axis 1 to remove the multi-index\n",
    "gb_monthly_days_above_40C = gb_monthly_days_above_40C.rename_axis(None, axis=1).reset_index()\n",
    "gb_monthly_days_above_40C.rename(columns={0: 'days_above_40C'}, inplace=True)\n",
    "log('   4. Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Number of days per season with a temp >= 40C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:20 2017 -    5. Days per season >= 40C...\n",
      "Sun May  7 08:42:20 2017 -    5. Done\n"
     ]
    }
   ],
   "source": [
    "log('   5. Days per season >= 40C...')\n",
    "# use the >40C table from #4, sum for each season\n",
    "gb_seasonal_days_above_40C = df_temp_above_40C.groupby(['nest_id', 'season_year', 'season']).size()\n",
    "# convert from Series to Dataframe (which has multi-level index)\n",
    "gb_seasonal_days_above_40C = gb_seasonal_days_above_40C.to_frame()\n",
    "# rename axis 1 to remove the multi-index\n",
    "gb_seasonal_days_above_40C = gb_seasonal_days_above_40C.rename_axis(None, axis=1).reset_index()\n",
    "gb_seasonal_days_above_40C.rename(columns={0: 'days_above_40C'}, inplace=True)\n",
    "log('   5. Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Number of days per year with a temp >= 40C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:20 2017 -    6. Days per year >= 40C...\n",
      "Sun May  7 08:42:20 2017 -    6. Done\n"
     ]
    }
   ],
   "source": [
    "log('   6. Days per year >= 40C...')\n",
    "# use the >35C table from #1, sum for each year\n",
    "gb_annual_days_above_40C = df_temp_above_40C.groupby(['nest_id', 'breeding_year']).size()\n",
    "# convert from Series to Dataframe (which has multi-level index)\n",
    "gb_annual_days_above_40C = gb_annual_days_above_40C.to_frame()\n",
    "# rename axis 1 to remove the multi-index\n",
    "gb_annual_days_above_40C = gb_annual_days_above_40C.rename_axis(None, axis=1).reset_index()\n",
    "gb_annual_days_above_40C.rename(columns={0: 'days_above_40C'}, inplace=True)\n",
    "log('   6. Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Daily temperature and humidity stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:20 2017 -    7. Daily temp and humidity stats...\n",
      "Sun May  7 08:42:21 2017 -    7. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   7. Daily temp and humidity stats...')\n",
    "agg = {\n",
    "    'humidity': {\n",
    "        'max': 'max',\n",
    "        'min': 'min',\n",
    "        'mean': 'mean',\n",
    "        'median': 'median',\n",
    "        'stddev': 'std'\n",
    "    },\n",
    "    'temp_c': {\n",
    "        'max': 'max',\n",
    "        'min': 'min',\n",
    "        'mean': 'mean',\n",
    "        'median': 'median',\n",
    "        'stddev': 'std'\n",
    "    }\n",
    "}\n",
    "gb_daily_sensor_stats = df_sensor_phase.groupby(['nest_id', 'breeding_year', 'season_year', 'calendar_year', 'breeding_phase', 'season', 'month', 'day', 'clutch']).agg(agg).reset_index()\n",
    "gb_daily_sensor_stats.columns = [' '.join(col).strip() for col in gb_daily_sensor_stats.columns.values]\n",
    "# daily range = max-min\n",
    "gb_daily_sensor_stats['humidity range'] = gb_daily_sensor_stats['humidity max'] - gb_daily_sensor_stats['humidity min']\n",
    "gb_daily_sensor_stats['temp_c range'] = gb_daily_sensor_stats['temp_c max'] - gb_daily_sensor_stats['temp_c min']\n",
    "log('   7. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Monthly temperature and humidity stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:21 2017 -    8. Monthly temp and humidity stats...\n",
      "Sun May  7 08:42:22 2017 -    8. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   8. Monthly temp and humidity stats...')\n",
    "gb_monthly_sensor_stats = df_sensor_phase.groupby(['nest_id', 'breeding_year', 'month']).agg(agg).reset_index()\n",
    "gb_monthly_sensor_stats.columns = [' '.join(col).strip() for col in gb_monthly_sensor_stats.columns.values]\n",
    "# monthly range = max-min\n",
    "# gb_monthly_sensor_stats['humidity range'] = gb_monthly_sensor_stats['humidity max'] - gb_monthly_sensor_stats['humidity min']\n",
    "# gb_monthly_sensor_stats['temp_c range'] = gb_monthly_sensor_stats['temp_c max'] - gb_monthly_sensor_stats['temp_c min']\n",
    "log('   8. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Seasonal temperature and humidity stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:22 2017 -    9. Seasonal temp and humidity stats...\n",
      "Sun May  7 08:42:23 2017 -    9. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   9. Seasonal temp and humidity stats...')\n",
    "gb_seasonal_sensor_stats = df_sensor_phase.groupby(['nest_id', 'season_year', 'season']).agg(agg).reset_index()\n",
    "gb_seasonal_sensor_stats.columns = [' '.join(col).strip() for col in gb_seasonal_sensor_stats.columns.values]\n",
    "# seasonal range = max-min\n",
    "gb_seasonal_sensor_stats['humidity range'] = gb_seasonal_sensor_stats['humidity max'] - gb_seasonal_sensor_stats['humidity min']\n",
    "gb_seasonal_sensor_stats['temp_c range'] = gb_seasonal_sensor_stats['temp_c max'] - gb_seasonal_sensor_stats['temp_c min']\n",
    "log('   9. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Annual temperature and humidity stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:23 2017 -    10. Annual temp and humidity stats...\n",
      "Sun May  7 08:42:24 2017 -    10. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   10. Annual temp and humidity stats...')\n",
    "gb_annual_sensor_stats = df_sensor_phase.groupby(['nest_id', 'breeding_year']).agg(agg).reset_index()\n",
    "gb_annual_sensor_stats.columns = [' '.join(col).strip() for col in gb_annual_sensor_stats.columns.values]\n",
    "# annual range = max-min\n",
    "gb_annual_sensor_stats['humidity range'] = gb_annual_sensor_stats['humidity max'] - gb_annual_sensor_stats['humidity min']\n",
    "gb_annual_sensor_stats['temp_c range'] = gb_annual_sensor_stats['temp_c max'] - gb_annual_sensor_stats['temp_c min']\n",
    "log('   10. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Mean min temp and humidity by month, season, year, phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:24 2017 -    11. Mean min temp and humidity by month, season, year, phase...\n",
      "Sun May  7 08:42:24 2017 -    11. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   11. Mean min temp and humidity by month, season, year, phase...')\n",
    "agg = {\n",
    "    'humidity range': {'mean_range': 'mean'},\n",
    "    'temp_c range': {'mean_range': 'mean'}\n",
    "}\n",
    "gb_monthly_range = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'month']).agg(agg).reset_index()\n",
    "gb_monthly_range.columns = [' '.join(col).strip() for col in gb_monthly_range.columns.values]\n",
    "\n",
    "gb_seasonal_range = gb_daily_sensor_stats.groupby(['nest_id', 'season_year', 'season']).agg(agg).reset_index()\n",
    "gb_seasonal_range.columns = [' '.join(col).strip() for col in gb_seasonal_range.columns.values]\n",
    "\n",
    "gb_annual_range = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year']).agg(agg).reset_index()\n",
    "gb_annual_range.columns = [' '.join(col).strip() for col in gb_annual_range.columns.values]\n",
    "\n",
    "gb_phase_range = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'clutch', 'breeding_phase']).agg(agg).reset_index()\n",
    "gb_phase_range.columns = [' '.join(col).strip() for col in gb_phase_range.columns.values]\n",
    "log('   11. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Mean max temp and humidity by month, season, year, phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:25 2017 -    8. Mean max temp and humidity by month, season, year, phase...\n",
      "Sun May  7 08:42:25 2017 -    8. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   8. Mean max temp and humidity by month, season, year, phase...')\n",
    "agg = {\n",
    "    'humidity max': {'mean_max': 'mean'},\n",
    "    'temp_c max': {'mean_max': 'mean'}\n",
    "}\n",
    "gb_monthly_max = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'month']).agg(agg).reset_index()\n",
    "gb_monthly_max.columns = [' '.join(col).strip() for col in gb_monthly_max.columns.values]\n",
    "\n",
    "gb_seasonal_max = gb_daily_sensor_stats.groupby(['nest_id', 'season_year', 'season']).agg(agg).reset_index()\n",
    "gb_seasonal_max.columns = [' '.join(col).strip() for col in gb_seasonal_max.columns.values]\n",
    "\n",
    "gb_annual_max = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year']).agg(agg).reset_index()\n",
    "gb_annual_max.columns = [' '.join(col).strip() for col in gb_annual_max.columns.values]\n",
    "\n",
    "gb_phase_max = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'clutch', 'breeding_phase']).agg(agg).reset_index()\n",
    "gb_phase_max.columns = [' '.join(col).strip() for col in gb_phase_max.columns.values]\n",
    "log('   8. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Mean temp and humidity range by month, season, year, phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:25 2017 -    9. Mean temp and humidity range by month, season, year, phase...\n",
      "Sun May  7 08:42:25 2017 -    9. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   9. Mean temp and humidity range by month, season, year, phase...')\n",
    "agg = {\n",
    "    'humidity range': {'mean_range': 'mean'},\n",
    "    'temp_c range': {'mean_range': 'mean'}\n",
    "}\n",
    "gb_monthly_range = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'month']).agg(agg).reset_index()\n",
    "gb_monthly_range.columns = [' '.join(col).strip() for col in gb_monthly_range.columns.values]\n",
    "\n",
    "gb_seasonal_range = gb_daily_sensor_stats.groupby(['nest_id', 'season_year', 'season']).agg(agg).reset_index()\n",
    "gb_seasonal_range.columns = [' '.join(col).strip() for col in gb_seasonal_range.columns.values]\n",
    "\n",
    "gb_annual_range = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year']).agg(agg).reset_index()\n",
    "gb_annual_range.columns = [' '.join(col).strip() for col in gb_annual_range.columns.values]\n",
    "\n",
    "gb_phase_range = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'clutch', 'breeding_phase']).agg(agg).reset_index()\n",
    "gb_phase_range.columns = [' '.join(col).strip() for col in gb_phase_range.columns.values]\n",
    "log('   9. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Hours exceeding 35C by year, season, month and phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:25 2017 -    11. Hours exceeding 35C...\n",
      "Sun May  7 08:42:29 2017 -    11. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   11. Hours exceeding 35C...')\n",
    "# Get a version of df_sensor_phase that is sorted correctly\n",
    "temp = df_sensor_phase.sort_values(by=['nest_id', 'datetime']).copy().reset_index()\n",
    "temp['recnum'] = temp['index']\n",
    "\n",
    "# Get all records with a temp_c >= 35 C\n",
    "df_hours_above_35C = temp[df_sensor_phase['temp_c'] >= 35].copy()\n",
    "df_hours_above_35C['next_rec'] = df_hours_above_35C['recnum'] + 1\n",
    "\n",
    "# Get all records with recnum+1 using a merge\n",
    "df_hours_above_35C = pd.merge(\n",
    "    left=df_hours_above_35C,\n",
    "    right=temp,\n",
    "    how='left',\n",
    "    left_on='next_rec',\n",
    "    right_on='recnum',\n",
    "    sort=True,\n",
    "    suffixes=('_orig', '_next')\n",
    ")[['recnum_orig', 'datetime_orig', 'nest_id_orig', 'humidity_orig',\n",
    "       'temp_c_orig', 'breeding_year_orig', 'temp_bucket_orig',\n",
    "       'humidity_bucket_orig', 'clutch_1_orig', 'clutch_2_orig',\n",
    "       'clutch_3_orig', 'clutch_orig', 'egg_lay_date_orig',\n",
    "       'courting_date_orig', 'hatch_date_orig', 'dead_or_fledge_date_orig',\n",
    "       'clutch_count_orig', 'calendar_year_orig', 'month_orig', 'day_orig',\n",
    "       'hour_orig', 'minute_orig', 'season_orig', 'season_year_orig',\n",
    "       'breeding_phase_orig', 'datetime_next']]\n",
    "\n",
    "del temp\n",
    "\n",
    "# Get the Timedelta between recnum-datestamp and next_rec-datestamp\n",
    "df_hours_above_35C['time_at_temp'] = df_hours_above_35C['datetime_next'] - df_hours_above_35C['datetime_orig']\n",
    "df_hours_above_35C['hours_above_35C'] = df_hours_above_35C['time_at_temp'].apply(lambda x: x.seconds / 3600)\n",
    "\n",
    "# Sum the Timedeltas per nest per year, season, month\n",
    "# monthly\n",
    "gb_monthly_hours_above_35C = df_hours_above_35C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'month_orig', 'hours_above_35C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'month_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "# annual\n",
    "gb_annual_hours_above_35C = df_hours_above_35C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'hours_above_35C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "# seasonal\n",
    "gb_seasonal_hours_above_35C = df_hours_above_35C[\n",
    "    ['nest_id_orig', 'season_year_orig', 'season_orig', 'hours_above_35C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'season_year_orig', 'season_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "# breeding phase\n",
    "gb_seasonal_hours_above_35C = df_hours_above_35C[\n",
    "    ['nest_id_orig', 'season_year_orig', 'season_orig', 'hours_above_35C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'season_year_orig', 'season_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "log('   11. Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['recnum_orig', 'datetime_orig', 'nest_id_orig', 'humidity_orig',\n",
       "       'temp_c_orig', 'breeding_year_orig', 'temp_bucket_orig',\n",
       "       'humidity_bucket_orig', 'clutch_1_orig', 'clutch_2_orig',\n",
       "       'clutch_3_orig', 'clutch_orig', 'egg_lay_date_orig',\n",
       "       'courting_date_orig', 'hatch_date_orig', 'dead_or_fledge_date_orig',\n",
       "       'clutch_count_orig', 'calendar_year_orig', 'month_orig', 'day_orig',\n",
       "       'hour_orig', 'minute_orig', 'season_orig', 'season_year_orig',\n",
       "       'breeding_phase_orig', 'datetime_next', 'time_at_temp',\n",
       "       'hours_above_35C'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hours_above_35C.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>recnum_orig</th>\n",
       "      <th>datetime_orig</th>\n",
       "      <th>nest_id_orig</th>\n",
       "      <th>humidity_orig</th>\n",
       "      <th>temp_c_orig</th>\n",
       "      <th>breeding_year_orig</th>\n",
       "      <th>temp_bucket_orig</th>\n",
       "      <th>humidity_bucket_orig</th>\n",
       "      <th>clutch_1_orig</th>\n",
       "      <th>clutch_2_orig</th>\n",
       "      <th>...</th>\n",
       "      <th>month_orig</th>\n",
       "      <th>day_orig</th>\n",
       "      <th>hour_orig</th>\n",
       "      <th>minute_orig</th>\n",
       "      <th>season_orig</th>\n",
       "      <th>season_year_orig</th>\n",
       "      <th>breeding_phase_orig</th>\n",
       "      <th>datetime_next</th>\n",
       "      <th>time_at_temp</th>\n",
       "      <th>hours_above_35C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7885</td>\n",
       "      <td>2013-11-10 11:45:00</td>\n",
       "      <td>101</td>\n",
       "      <td>32.200001</td>\n",
       "      <td>35.09</td>\n",
       "      <td>2013</td>\n",
       "      <td>temp_30-40</td>\n",
       "      <td>RH%_20-40</td>\n",
       "      <td>2013-07-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>11</td>\n",
       "      <td>45</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2013</td>\n",
       "      <td>Not in use</td>\n",
       "      <td>2013-11-10 12:15:00</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7886</td>\n",
       "      <td>2013-11-10 12:15:00</td>\n",
       "      <td>101</td>\n",
       "      <td>32.860001</td>\n",
       "      <td>35.59</td>\n",
       "      <td>2013</td>\n",
       "      <td>temp_30-40</td>\n",
       "      <td>RH%_20-40</td>\n",
       "      <td>2013-07-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>15</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2013</td>\n",
       "      <td>Not in use</td>\n",
       "      <td>2013-11-10 12:45:00</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7887</td>\n",
       "      <td>2013-11-10 12:45:00</td>\n",
       "      <td>101</td>\n",
       "      <td>34.220001</td>\n",
       "      <td>35.59</td>\n",
       "      <td>2013</td>\n",
       "      <td>temp_30-40</td>\n",
       "      <td>RH%_20-40</td>\n",
       "      <td>2013-07-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>12</td>\n",
       "      <td>45</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2013</td>\n",
       "      <td>Not in use</td>\n",
       "      <td>2013-11-10 13:15:00</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7888</td>\n",
       "      <td>2013-11-10 13:15:00</td>\n",
       "      <td>101</td>\n",
       "      <td>34.220001</td>\n",
       "      <td>36.09</td>\n",
       "      <td>2013</td>\n",
       "      <td>temp_30-40</td>\n",
       "      <td>RH%_20-40</td>\n",
       "      <td>2013-07-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>15</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2013</td>\n",
       "      <td>Not in use</td>\n",
       "      <td>2013-11-10 13:45:00</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7889</td>\n",
       "      <td>2013-11-10 13:45:00</td>\n",
       "      <td>101</td>\n",
       "      <td>37.520000</td>\n",
       "      <td>35.59</td>\n",
       "      <td>2013</td>\n",
       "      <td>temp_30-40</td>\n",
       "      <td>RH%_20-40</td>\n",
       "      <td>2013-07-22</td>\n",
       "      <td>NaT</td>\n",
       "      <td>...</td>\n",
       "      <td>11</td>\n",
       "      <td>10</td>\n",
       "      <td>13</td>\n",
       "      <td>45</td>\n",
       "      <td>Spring</td>\n",
       "      <td>2013</td>\n",
       "      <td>Not in use</td>\n",
       "      <td>2013-11-10 14:15:00</td>\n",
       "      <td>00:30:00</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 28 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   recnum_orig       datetime_orig nest_id_orig  humidity_orig  temp_c_orig  \\\n",
       "0         7885 2013-11-10 11:45:00          101      32.200001        35.09   \n",
       "1         7886 2013-11-10 12:15:00          101      32.860001        35.59   \n",
       "2         7887 2013-11-10 12:45:00          101      34.220001        35.59   \n",
       "3         7888 2013-11-10 13:15:00          101      34.220001        36.09   \n",
       "4         7889 2013-11-10 13:45:00          101      37.520000        35.59   \n",
       "\n",
       "   breeding_year_orig temp_bucket_orig humidity_bucket_orig clutch_1_orig  \\\n",
       "0                2013       temp_30-40            RH%_20-40    2013-07-22   \n",
       "1                2013       temp_30-40            RH%_20-40    2013-07-22   \n",
       "2                2013       temp_30-40            RH%_20-40    2013-07-22   \n",
       "3                2013       temp_30-40            RH%_20-40    2013-07-22   \n",
       "4                2013       temp_30-40            RH%_20-40    2013-07-22   \n",
       "\n",
       "  clutch_2_orig       ...        month_orig  day_orig hour_orig minute_orig  \\\n",
       "0           NaT       ...                11        10        11          45   \n",
       "1           NaT       ...                11        10        12          15   \n",
       "2           NaT       ...                11        10        12          45   \n",
       "3           NaT       ...                11        10        13          15   \n",
       "4           NaT       ...                11        10        13          45   \n",
       "\n",
       "  season_orig season_year_orig  breeding_phase_orig       datetime_next  \\\n",
       "0      Spring             2013           Not in use 2013-11-10 12:15:00   \n",
       "1      Spring             2013           Not in use 2013-11-10 12:45:00   \n",
       "2      Spring             2013           Not in use 2013-11-10 13:15:00   \n",
       "3      Spring             2013           Not in use 2013-11-10 13:45:00   \n",
       "4      Spring             2013           Not in use 2013-11-10 14:15:00   \n",
       "\n",
       "   time_at_temp  hours_above_35C  \n",
       "0      00:30:00              0.5  \n",
       "1      00:30:00              0.5  \n",
       "2      00:30:00              0.5  \n",
       "3      00:30:00              0.5  \n",
       "4      00:30:00              0.5  \n",
       "\n",
       "[5 rows x 28 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_hours_above_35C.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Hours exceeding 40C by year, season, month and phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:29 2017 -    12. Hours exceeding 40C...\n",
      "Sun May  7 08:42:33 2017 -    12. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   12. Hours exceeding 40C...')\n",
    "# Get a version of df_sensor_phase that is sorted correctly\n",
    "temp = df_sensor_phase.sort_values(by=['nest_id', 'datetime']).copy().reset_index()\n",
    "temp['recnum'] = temp['index']\n",
    "\n",
    "# Get all records with a temp_c >= 40 C\n",
    "df_hours_above_40C = temp[df_sensor_phase['temp_c'] >= 40].copy()\n",
    "df_hours_above_40C['next_rec'] = df_hours_above_40C['recnum'] + 1\n",
    "\n",
    "# Get all records with recnum+1 using a merge\n",
    "df_hours_above_40C = pd.merge(\n",
    "    left=df_hours_above_40C,\n",
    "    right=temp,\n",
    "    how='left',\n",
    "    left_on='next_rec',\n",
    "    right_on='recnum',\n",
    "    sort=True,\n",
    "    suffixes=('_orig', '_next')\n",
    ")[['recnum_orig', 'datetime_orig', 'nest_id_orig', 'humidity_orig',\n",
    "       'temp_c_orig', 'breeding_year_orig', 'temp_bucket_orig',\n",
    "       'humidity_bucket_orig', 'clutch_1_orig', 'clutch_2_orig',\n",
    "       'clutch_3_orig', 'clutch_orig', 'egg_lay_date_orig',\n",
    "       'courting_date_orig', 'hatch_date_orig', 'dead_or_fledge_date_orig',\n",
    "       'clutch_count_orig', 'calendar_year_orig', 'month_orig', 'day_orig',\n",
    "       'hour_orig', 'minute_orig', 'season_orig', 'season_year_orig',\n",
    "       'breeding_phase_orig', 'datetime_next']]\n",
    "\n",
    "del temp\n",
    "\n",
    "# Get the Timedelta between recnum-datestamp and next_rec-datestamp\n",
    "df_hours_above_40C['time_at_temp'] = df_hours_above_40C['datetime_next'] - df_hours_above_40C['datetime_orig']\n",
    "df_hours_above_40C['hours_above_40C'] = df_hours_above_40C['time_at_temp'].apply(lambda x: x.seconds / 3600)\n",
    "\n",
    "# Sum the Timedeltas per nest per year, season, month\n",
    "gb_monthly_hours_above_40C = df_hours_above_40C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'month_orig', 'hours_above_40C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'month_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "gb_annual_hours_above_40C = df_hours_above_40C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'hours_above_40C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "gb_seasonal_hours_above_40C = df_hours_above_40C[\n",
    "    ['nest_id_orig', 'season_year_orig', 'season_orig', 'hours_above_40C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'season_year_orig', 'season_orig']\n",
    ").sum().reset_index()\n",
    "log('   12. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder - need BOM data\n",
    "Calculation: **Mean variance from ambient max temperature by year, season, month, phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:33 2017 -    13. Mean monthly humidity...\n",
      "Sun May  7 08:42:33 2017 -    13. Done.\n"
     ]
    }
   ],
   "source": [
    "# log('   13. Mean monthly humidity...')\n",
    "\n",
    "# log('   13. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder - need BOM data\n",
    "Calculation: **Mean variance from ambient min temperature by year, season, month, phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:33 2017 -    14. Mean monthly humidity...\n",
      "Sun May  7 08:42:33 2017 -    14. Done.\n"
     ]
    }
   ],
   "source": [
    "# log('   14. Mean monthly humidity...')\n",
    "\n",
    "# log('   14. Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:42:33 2017 - Calculating the sensor stats: Done.\n"
     ]
    }
   ],
   "source": [
    "log('Calculating the sensor stats: Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the aggregates by their time period (all annual, all monthly etc) and join the breeding success data to the aggregates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 09:06:45 2017 - Joining monthly tables...\n",
      "Sun May  7 09:06:45 2017 - Writing intermediate table df_monthly_microclimate to disk.\n",
      "Sun May  7 09:06:45 2017 - Written output\\B_Aggregate_Sensor_Stats/df_monthly_microclimate.csv: 0.429 MB\n",
      "Sun May  7 09:06:45 2017 - Done.\n",
      "Sun May  7 09:06:45 2017 - Joining breeding success to monthly microclimate data -> df_monthly_microclimate_vs_breeding...\n",
      "Sun May  7 09:06:45 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "log('Joining monthly tables...')\n",
    "df_monthly_microclimate = pd.merge(left=gb_monthly_sensor_stats, \n",
    "                                   right=gb_monthly_range, \n",
    "                                   how='left', \n",
    "                                   on=['nest_id', 'breeding_year', 'month'], \n",
    "                                   sort=True)\n",
    "\n",
    "df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "                                   right=gb_monthly_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'month'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "                                   right=gb_monthly_days_above_40C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'month'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "                                   right=gb_monthly_hours_above_35C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year', 'month'],\n",
    "                                   right_on=['nest_id_orig', 'breeding_year_orig', 'month_orig'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "                                   right=gb_monthly_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year', 'month'],\n",
    "                                   right_on=['nest_id', 'breeding_year', 'month'],\n",
    "                                   sort=True)\n",
    "df_monthly_microclimate.sort_values(by=['nest_id', 'breeding_year', 'month'], inplace=True)\n",
    "write_temp_file(df_monthly_microclimate, '{0}/df_monthly_microclimate.csv'.format(output_path), 'df_monthly_microclimate')\n",
    "log('Done.')\n",
    "\n",
    "log('Joining breeding success to monthly microclimate data -> df_monthly_microclimate_vs_breeding...')\n",
    "# PLACEHOLDER\n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 08:43:29 2017 - Joining annual tables...\n",
      "Sun May  7 08:43:29 2017 - Writing intermediate table df_annual_microclimate to disk.\n",
      "Sun May  7 08:43:29 2017 - Written output\\B_Aggregate_Sensor_Stats/df_annual_microclimate.csv: 0.078 MB\n",
      "Sun May  7 08:43:29 2017 - Done.\n",
      "Sun May  7 08:43:29 2017 - Joining breeding success to annual microclimate data -> df_annual_microclimate_vs_breeding...\n",
      "Sun May  7 08:43:29 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "log('Joining annual tables...')\n",
    "df_annual_microclimate = pd.merge(left=gb_annual_sensor_stats, \n",
    "                                   right=gb_annual_range, \n",
    "                                   how='left', \n",
    "                                   on=['nest_id', 'breeding_year'], \n",
    "                                   sort=True)\n",
    "\n",
    "df_annual_microclimate = pd.merge(left=df_annual_microclimate,\n",
    "                                   right=gb_annual_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_annual_microclimate = pd.merge(left=df_annual_microclimate,\n",
    "                                   right=gb_annual_days_above_40C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_annual_microclimate = pd.merge(left=df_annual_microclimate,\n",
    "                                   right=gb_annual_hours_above_35C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year'],\n",
    "                                   right_on=['nest_id_orig', 'breeding_year_orig'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_annual_microclimate = pd.merge(left=df_annual_microclimate,\n",
    "                                   right=gb_annual_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year'],\n",
    "                                   sort=True)\n",
    "df_annual_microclimate.sort_values(by=['nest_id', 'breeding_year'], inplace=True)\n",
    "write_temp_file(df_annual_microclimate, '{0}/df_annual_microclimate.csv'.format(output_path), 'df_annual_microclimate')\n",
    "log('Done.')\n",
    "\n",
    "log('Joining breeding success to annual microclimate data -> df_annual_microclimate_vs_breeding...')\n",
    "# PLACEHOLDER\n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 09:05:51 2017 - Joining seasonal tables...\n",
      "Sun May  7 09:05:51 2017 - Writing intermediate table df_seasonal_microclimate to disk.\n",
      "Sun May  7 09:05:51 2017 - Written output\\B_Aggregate_Sensor_Stats/df_seasonal_microclimate.csv: 0.203 MB\n",
      "Sun May  7 09:05:51 2017 - Done.\n",
      "Sun May  7 09:05:51 2017 - Joining breeding success to seasonal microclimate data -> df_seasonal_microclimate_vs_breeding...\n",
      "Sun May  7 09:05:51 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "log('Joining seasonal tables...')\n",
    "df_seasonal_microclimate = pd.merge(left=gb_seasonal_sensor_stats, \n",
    "                                   right=gb_seasonal_range, \n",
    "                                   how='left', \n",
    "                                   on=['nest_id', 'season_year', 'season'], \n",
    "                                   sort=True)\n",
    "\n",
    "df_seasonal_microclimate = pd.merge(left=df_seasonal_microclimate,\n",
    "                                   right=gb_seasonal_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'season_year', 'season'], \n",
    "                                   sort=True)\n",
    "\n",
    "df_seasonal_microclimate = pd.merge(left=df_seasonal_microclimate,\n",
    "                                   right=gb_seasonal_days_above_40C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'season_year', 'season'], \n",
    "                                   sort=True)\n",
    "\n",
    "df_seasonal_microclimate = pd.merge(left=df_seasonal_microclimate,\n",
    "                                   right=gb_seasonal_hours_above_35C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'season_year', 'season'], \n",
    "                                   right_on=['nest_id_orig', 'season_year_orig', 'season_orig'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_seasonal_microclimate = pd.merge(left=df_seasonal_microclimate,\n",
    "                                   right=gb_seasonal_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'season_year', 'season'],\n",
    "                                   sort=True)\n",
    "df_seasonal_microclimate.sort_values(by=['nest_id', 'season_year', 'season'], inplace=True)\n",
    "write_temp_file(df_seasonal_microclimate, '{0}/df_seasonal_microclimate.csv'.format(output_path), 'df_seasonal_microclimate')\n",
    "log('Done.')\n",
    "\n",
    "log('Joining breeding success to seasonal microclimate data -> df_seasonal_microclimate_vs_breeding...')\n",
    "# PLACEHOLDER\n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ------\n",
    "# UP TO HERE - do script A first\n",
    "# ------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nest_id</th>\n",
       "      <th>season_year</th>\n",
       "      <th>season</th>\n",
       "      <th>days_above_35C</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>Spring</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>101</td>\n",
       "      <td>2013</td>\n",
       "      <td>Summer</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>101</td>\n",
       "      <td>2014</td>\n",
       "      <td>Autumn</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>102</td>\n",
       "      <td>2013</td>\n",
       "      <td>Spring</td>\n",
       "      <td>126</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>102</td>\n",
       "      <td>2013</td>\n",
       "      <td>Summer</td>\n",
       "      <td>584</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  nest_id  season_year  season  days_above_35C\n",
       "0     101         2013  Spring              16\n",
       "1     101         2013  Summer             164\n",
       "2     101         2014  Autumn              43\n",
       "3     102         2013  Spring             126\n",
       "4     102         2013  Summer             584"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gb_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breeding phase aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "log('Joining breeding phase tables...')\n",
    "df_breeding_microclimate = pd.merge(left=gb_monthly_sensor_stats, \n",
    "                                   right=gb_monthly_range, \n",
    "                                   how='left', \n",
    "                                   on=['nest_id', 'breeding_year', 'month'], \n",
    "                                   sort=True)\n",
    "\n",
    "# df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "#                                    right=gb_monthly_days_above_35C,\n",
    "#                                    how='left',\n",
    "#                                    on=['nest_id', 'breeding_year', 'month'],\n",
    "#                                    sort=True)\n",
    "\n",
    "# df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "#                                    right=gb_monthly_days_above_40C,\n",
    "#                                    how='left',\n",
    "#                                    on=['nest_id', 'breeding_year', 'month'],\n",
    "#                                    sort=True)\n",
    "\n",
    "# df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "#                                    right=gb_monthly_hours_above_35C,\n",
    "#                                    how='left',\n",
    "#                                    left_on=['nest_id', 'breeding_year', 'month'],\n",
    "#                                    right_on=['nest_id_orig', 'breeding_year_orig', 'month_orig'],\n",
    "#                                    sort=True)\n",
    "\n",
    "# df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "#                                    right=gb_monthly_days_above_35C,\n",
    "#                                    how='left',\n",
    "#                                    left_on=['nest_id', 'breeding_year', 'month'],\n",
    "#                                    right_on=['nest_id', 'breeding_year', 'month'],\n",
    "#                                    sort=True)\n",
    "# df_monthly_microclimate.sort_values(by=['nest_id', 'breeding_year', 'month'], inplace=True)\n",
    "# write_temp_file(df_monthly_microclimate, '{0}/df_monthly_microclimate.csv'.format(output_path), 'df_monthly_microclimate')\n",
    "# log('Done.')\n",
    "\n",
    "# log('Joining breeding success to monthly microclimate data -> df_monthly_microclimate_vs_breeding...')\n",
    "# # PLACEHOLDER\n",
    "# log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickle the two key data files for use in later scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sun May  7 09:20:12 2017 - Writing the final tables to pickle for future use...\n",
      "Sun May  7 09:20:12 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "log('Writing the final tables to pickle for future use...')\n",
    "df_monthly_microclimate.to_pickle('{0}/df_monthly_microlimate.pkl'.format(output_path))\n",
    "df_annual_microclimate.to_pickle('{0}/df_annual_microlimate.pkl'.format(output_path))\n",
    "df_seasonal_microclimate.to_pickle('{0}/df_seasonal_microlimate.pkl'.format(output_path))\n",
    "log('Done.')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
