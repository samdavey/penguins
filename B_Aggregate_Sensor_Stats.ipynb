{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Aggregate Sensor Stats\n",
    "In script A_load_and_combine_data we created a table called df_sensor_phase which contianed the full temperature and humidity sensor readings, together with the breeding_year, season_year and breeding_phase.\n",
    "\n",
    "This script creates a set of aggregates from this data to understand the nest microclimates. The aggregates include:\n",
    "* `Annual stats             -> df_sensor_stats_annual`\n",
    "* `Seasonal stats           -> df_sensor_stats_seasonal`\n",
    "* `Monthly stats            -> df_sensor_stats_monthly`\n",
    "* `Daily stats              -> df_sensor_stats_daily`\n",
    "* `Stats by breeding phase  -> df_sensor_stats_breeding_phase`\n",
    "* `Stats by clutch          -> df_sensor_stats_clutch`\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Set up the environment\n",
    "### 1.1 Import the required libraries\n",
    "We need a certain set of common libraries for the tasks to be performed. These are imported below. If an import statement errors, you will need to install the library in your environment using the command line command `pip install <library>`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up environment and variables...\n"
     ]
    }
   ],
   "source": [
    "print('Setting up environment and variables...', flush=True)\n",
    "import pandas as pd\n",
    "import os\n",
    "import numpy as np\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "# all the useful and reuseable functions are defined in helper_functions.py\n",
    "from helper_functions import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Set up the variables\n",
    "You will need to change the values of the variables below to suit the names and directory location of your files to be loaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:46:29 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "# update these with your file paths\n",
    "sensor_phase = os.path.normpath('./output/A_load_and_combine_data/df_sensor_phase.pkl')\n",
    "\n",
    "# write intermediate tables to disk for debugging purposes\n",
    "write_temps = True\n",
    "output_path = os.path.normpath('./output/B_Aggregate_Sensor_Stats')\n",
    "df_sensor_data = None\n",
    "\n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def write_temp_file(df, filepath, df_name):\n",
    "    '''\n",
    "    If write_temps is true, this function will write the specified Pandas dataframe (df) to csv at the specified location (filepath).\n",
    "    Variables:\n",
    "        df: a Pandas dataframe to be written to csv.\n",
    "        filepath: a string in Unix path format (using / not \\) for the csv destination.\n",
    "        df_name: human readable name or description of the dataframe for logging purposes.\n",
    "    '''\n",
    "    if write_temps:\n",
    "        print('{0} - Writing intermediate table {1} to disk.'.format(str(time.ctime()), df_name, filepath), flush=True)\n",
    "        if not os.path.exists(output_path):\n",
    "            os.makedirs(output_path)\n",
    "        df.to_csv(os.path.normpath(filepath))\n",
    "        if os.path.getsize(filepath) > 0:\n",
    "            print('{0} - Written {1}: {2:.3f} MB'.format(str(time.ctime()), filepath, os.path.getsize(filepath)/1000000), flush=True)\n",
    "           "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Import the data file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sensor_phase = pd.read_pickle(sensor_phase)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the aggregate temperature and humidity calculations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Number of days per year, month, season, breeding phase and clutch with a temp >= 35C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:47:12 2017 -    1. Days >= 35C...\n",
      "Thu Aug 31 19:47:12 2017 -    1. Done\n"
     ]
    }
   ],
   "source": [
    "log('   1. Days >= 35C...')\n",
    "# get the records > 35c\n",
    "df_temp_above_35C = df_sensor_phase.loc[df_sensor_phase['temp_c'] >= 35].reset_index()\n",
    "\n",
    "# get the count of records per day over 35C. One record per day, to be summarised and counted again in each larger unit.\n",
    "df_days_above_35C = pd.DataFrame({'count': df_temp_above_35C.groupby(['nest_id', 'breeding_year', 'season_year', 'clutch', 'breeding_phase', 'season', 'month', 'day']).size()}).reset_index()\n",
    "\n",
    "# Summarise the daily version into larger units, counting the resords (one per day) in the dailty version to get days>35\n",
    "df_monthly_days_above_35C = pd.DataFrame({'days_above_35C': df_days_above_35C.groupby(['nest_id', 'breeding_year', 'month']).size()}).reset_index()\n",
    "df_seasonal_days_above_35C = pd.DataFrame({'days_above_35C': df_days_above_35C.groupby(['nest_id', 'season_year', 'season']).size()}).reset_index()\n",
    "df_annual_days_above_35C = pd.DataFrame({'days_above_35C': df_days_above_35C.groupby(['nest_id', 'breeding_year']).size()}).reset_index()\n",
    "df_phase_days_above_35C = pd.DataFrame({'days_above_35C': df_days_above_35C.groupby(['nest_id', 'breeding_year', 'clutch', 'breeding_phase']).size()}).reset_index()\n",
    "df_clutch_days_above_35C = pd.DataFrame({'days_above_35C': df_days_above_35C.groupby(['nest_id', 'breeding_year', 'clutch']).size()}).reset_index()\n",
    "log('   1. Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Number of days per month with a temp >= 40C**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:47:33 2017 -    2. Days >= 40C...\n",
      "Thu Aug 31 19:47:33 2017 -    2. Done\n"
     ]
    }
   ],
   "source": [
    "log('   2. Days >= 40C...')\n",
    "# get the records > 40c\n",
    "df_temp_above_40C = df_sensor_phase.loc[df_sensor_phase['temp_c'] >= 40].reset_index()\n",
    "\n",
    "# get the count of records per day over 35C. One record per day, to be summarised and counted again in each larger unit.\n",
    "df_days_above_40C = pd.DataFrame({'count': df_temp_above_40C.groupby(['nest_id', 'breeding_year', 'season_year', 'clutch', 'breeding_phase', 'season', 'month', 'day']).size()}).reset_index()\n",
    "\n",
    "# Summarise the daily version into larger units, counting the resords (one per day) in the dailty version to get days>35\n",
    "df_monthly_days_above_40C = pd.DataFrame({'days_above_40C': df_days_above_40C.groupby(['nest_id', 'breeding_year', 'month']).size()}).reset_index()\n",
    "df_seasonal_days_above_40C = pd.DataFrame({'days_above_40C': df_days_above_40C.groupby(['nest_id', 'season_year', 'season']).size()}).reset_index()\n",
    "df_annual_days_above_40C = pd.DataFrame({'days_above_40C': df_days_above_40C.groupby(['nest_id', 'breeding_year']).size()}).reset_index()\n",
    "df_phase_days_above_40C = pd.DataFrame({'days_above_40C': df_days_above_40C.groupby(['nest_id', 'breeding_year', 'clutch', 'breeding_phase']).size()}).reset_index()\n",
    "df_clutch_days_above_40C = pd.DataFrame({'days_above_40C': df_days_above_40C.groupby(['nest_id', 'breeding_year', 'clutch']).size()}).reset_index()\n",
    "log('   2. Done')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Daily temperature and humidity stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:47:58 2017 -    7. Daily temp and humidity stats...\n",
      "Thu Aug 31 19:47:59 2017 -    7. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   7. Daily temp and humidity stats...')\n",
    "agg = {\n",
    "    'humidity': {\n",
    "        'max': 'max',\n",
    "        'min': 'min',\n",
    "        'mean': 'mean',\n",
    "        'median': 'median',\n",
    "        'stddev': 'std'\n",
    "    },\n",
    "    'temp_c': {\n",
    "        'max': 'max',\n",
    "        'min': 'min',\n",
    "        'mean': 'mean',\n",
    "        'median': 'median',\n",
    "        'stddev': 'std'\n",
    "    }\n",
    "}\n",
    "gb_daily_sensor_stats = df_sensor_phase.groupby(['nest_id', 'breeding_year', 'season_year', 'calendar_year', 'breeding_phase', 'season', 'month', 'day', 'clutch']).agg(agg).reset_index()\n",
    "gb_daily_sensor_stats.columns = [' '.join(col).strip() for col in gb_daily_sensor_stats.columns.values]\n",
    "# daily range = max-min\n",
    "gb_daily_sensor_stats['humidity range'] = gb_daily_sensor_stats['humidity max'] - gb_daily_sensor_stats['humidity min']\n",
    "gb_daily_sensor_stats['temp_c range'] = gb_daily_sensor_stats['temp_c max'] - gb_daily_sensor_stats['temp_c min']\n",
    "log('   7. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "gb_daily_sensor_stats[['nest_id', 'breeding_year', 'season_year', 'calendar_year',\n",
    "       'breeding_phase', 'season', 'month', 'day', 'clutch', 'humidity max',\n",
    "       'humidity min', 'humidity mean', 'humidity median', 'humidity stddev',\n",
    "       'temp_c max', 'temp_c min', 'temp_c mean', 'temp_c median',\n",
    "       'temp_c stddev', 'humidity range', 'temp_c range']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Monthly temperature and humidity stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:48:16 2017 -    8. Monthly temp and humidity stats...\n",
      "Thu Aug 31 19:48:16 2017 -    8. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   8. Monthly temp and humidity stats...')\n",
    "gb_monthly_sensor_stats = df_sensor_phase.groupby(['nest_id', 'breeding_year', 'month']).agg(agg).reset_index()\n",
    "gb_monthly_sensor_stats.columns = [' '.join(col).strip() for col in gb_monthly_sensor_stats.columns.values]\n",
    "# monthly range = max-min\n",
    "gb_monthly_sensor_stats['humidity range'] = gb_monthly_sensor_stats['humidity max'] - gb_monthly_sensor_stats['humidity min']\n",
    "gb_monthly_sensor_stats['temp_c range'] = gb_monthly_sensor_stats['temp_c max'] - gb_monthly_sensor_stats['temp_c min']\n",
    "log('   8. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Seasonal temperature and humidity stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:48:18 2017 -    9. Seasonal temp and humidity stats...\n",
      "Thu Aug 31 19:48:19 2017 -    9. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   9. Seasonal temp and humidity stats...')\n",
    "gb_seasonal_sensor_stats = df_sensor_phase.groupby(['nest_id', 'season_year', 'season']).agg(agg).reset_index()\n",
    "gb_seasonal_sensor_stats.columns = [' '.join(col).strip() for col in gb_seasonal_sensor_stats.columns.values]\n",
    "# seasonal range = max-min\n",
    "gb_seasonal_sensor_stats['humidity range'] = gb_seasonal_sensor_stats['humidity max'] - gb_seasonal_sensor_stats['humidity min']\n",
    "gb_seasonal_sensor_stats['temp_c range'] = gb_seasonal_sensor_stats['temp_c max'] - gb_seasonal_sensor_stats['temp_c min']\n",
    "log('   9. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Annual temperature and humidity stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:48:26 2017 -    10. Annual temp and humidity stats...\n",
      "Thu Aug 31 19:48:26 2017 -    10. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   10. Annual temp and humidity stats...')\n",
    "gb_annual_sensor_stats = df_sensor_phase.groupby(['nest_id', 'breeding_year']).agg(agg).reset_index()\n",
    "gb_annual_sensor_stats.columns = [' '.join(col).strip() for col in gb_annual_sensor_stats.columns.values]\n",
    "# annual range = max-min\n",
    "gb_annual_sensor_stats['humidity range'] = gb_annual_sensor_stats['humidity max'] - gb_annual_sensor_stats['humidity min']\n",
    "gb_annual_sensor_stats['temp_c range'] = gb_annual_sensor_stats['temp_c max'] - gb_annual_sensor_stats['temp_c min']\n",
    "log('   10. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Breeding phase temperature and humidity stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:48:32 2017 -    11. Seasonal temp and humidity stats...\n",
      "Thu Aug 31 19:48:33 2017 -    11. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   11. Seasonal temp and humidity stats...')\n",
    "gb_phase_sensor_stats = df_sensor_phase.groupby(['nest_id', 'breeding_year', 'clutch', 'breeding_phase']).agg(agg).reset_index()\n",
    "gb_phase_sensor_stats.columns = [' '.join(col).strip() for col in gb_phase_sensor_stats.columns.values]\n",
    "# range = max-min\n",
    "gb_phase_sensor_stats['humidity range'] = gb_phase_sensor_stats['humidity max'] - gb_phase_sensor_stats['humidity min']\n",
    "gb_phase_sensor_stats['temp_c range'] = gb_phase_sensor_stats['temp_c max'] - gb_phase_sensor_stats['temp_c min']\n",
    "log('   11. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Clutch temperature and humidity stats**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:52:15 2017 -    10.5 Seasonal temp and humidity stats...\n",
      "Thu Aug 31 19:52:16 2017 -    10.5 Done.\n"
     ]
    }
   ],
   "source": [
    "log('   10.5 Seasonal temp and humidity stats...')\n",
    "gb_clutch_sensor_stats = df_sensor_phase.groupby(['nest_id', 'breeding_year', 'clutch']).agg(agg).reset_index()\n",
    "gb_clutch_sensor_stats.columns = [' '.join(col).strip() for col in gb_clutch_sensor_stats.columns.values]\n",
    "# range = max-min\n",
    "gb_clutch_sensor_stats['humidity range'] = gb_clutch_sensor_stats['humidity max'] - gb_clutch_sensor_stats['humidity min']\n",
    "gb_clutch_sensor_stats['temp_c range'] = gb_clutch_sensor_stats['temp_c max'] - gb_clutch_sensor_stats['temp_c min']\n",
    "log('   10.5 Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Mean min temp and humidity by month, season, year, phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:53:37 2017 -    11. Mean min temp and humidity range by month, season, year, phase...\n",
      "Thu Aug 31 19:53:37 2017 -    11. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   11. Mean min temp and humidity range by month, season, year, phase...')\n",
    "agg = {\n",
    "    'humidity min': {'mean_min': 'mean'},\n",
    "    'temp_c min': {'mean_min': 'mean'}\n",
    "}\n",
    "gb_monthly_min = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'month']).agg(agg).reset_index()\n",
    "gb_monthly_min.columns = [' '.join(col).strip() for col in gb_monthly_min.columns.values]\n",
    "\n",
    "gb_seasonal_min = gb_daily_sensor_stats.groupby(['nest_id', 'season_year', 'season']).agg(agg).reset_index()\n",
    "gb_seasonal_min.columns = [' '.join(col).strip() for col in gb_seasonal_min.columns.values]\n",
    "\n",
    "gb_annual_min = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year']).agg(agg).reset_index()\n",
    "gb_annual_min.columns = [' '.join(col).strip() for col in gb_annual_min.columns.values]\n",
    "\n",
    "gb_phase_min = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'clutch', 'breeding_phase']).agg(agg).reset_index()\n",
    "gb_phase_min.columns = [' '.join(col).strip() for col in gb_phase_min.columns.values]\n",
    "\n",
    "gb_clutch_min = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'clutch']).agg(agg).reset_index()\n",
    "gb_clutch_min.columns = [' '.join(col).strip() for col in gb_clutch_min.columns.values]\n",
    "log('   11. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Mean max temp and humidity by month, season, year, phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:54:34 2017 -    8. Mean max temp and humidity by month, season, year, phase...\n",
      "Thu Aug 31 19:54:34 2017 -    8. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   8. Mean max temp and humidity by month, season, year, phase...')\n",
    "agg = {\n",
    "    'humidity max': {'mean_max': 'mean'},\n",
    "    'temp_c max': {'mean_max': 'mean'}\n",
    "}\n",
    "gb_monthly_max = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'month']).agg(agg).reset_index()\n",
    "gb_monthly_max.columns = [' '.join(col).strip() for col in gb_monthly_max.columns.values]\n",
    "\n",
    "gb_seasonal_max = gb_daily_sensor_stats.groupby(['nest_id', 'season_year', 'season']).agg(agg).reset_index()\n",
    "gb_seasonal_max.columns = [' '.join(col).strip() for col in gb_seasonal_max.columns.values]\n",
    "\n",
    "gb_annual_max = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year']).agg(agg).reset_index()\n",
    "gb_annual_max.columns = [' '.join(col).strip() for col in gb_annual_max.columns.values]\n",
    "\n",
    "gb_phase_max = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'clutch', 'breeding_phase']).agg(agg).reset_index()\n",
    "gb_phase_max.columns = [' '.join(col).strip() for col in gb_phase_max.columns.values]\n",
    "\n",
    "gb_clutch_max = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'clutch']).agg(agg).reset_index()\n",
    "gb_clutch_max.columns = [' '.join(col).strip() for col in gb_clutch_max.columns.values]\n",
    "log('   8. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Mean temp and humidity range by month, season, year, phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:55:23 2017 -    9. Mean temp and humidity range by month, season, year, phase...\n",
      "Thu Aug 31 19:55:23 2017 -    9. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   9. Mean temp and humidity range by month, season, year, phase...')\n",
    "agg = {\n",
    "    'humidity range': {'mean_range': 'mean'},\n",
    "    'temp_c range': {'mean_range': 'mean'}\n",
    "}\n",
    "gb_monthly_range = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'month']).agg(agg).reset_index()\n",
    "gb_monthly_range.columns = [' '.join(col).strip() for col in gb_monthly_range.columns.values]\n",
    "\n",
    "gb_seasonal_range = gb_daily_sensor_stats.groupby(['nest_id', 'season_year', 'season']).agg(agg).reset_index()\n",
    "gb_seasonal_range.columns = [' '.join(col).strip() for col in gb_seasonal_range.columns.values]\n",
    "\n",
    "gb_annual_range = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year']).agg(agg).reset_index()\n",
    "gb_annual_range.columns = [' '.join(col).strip() for col in gb_annual_range.columns.values]\n",
    "\n",
    "gb_phase_range = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'clutch', 'breeding_phase']).agg(agg).reset_index()\n",
    "gb_phase_range.columns = [' '.join(col).strip() for col in gb_phase_range.columns.values]\n",
    "\n",
    "gb_clutch_range = gb_daily_sensor_stats.groupby(['nest_id', 'breeding_year', 'clutch']).agg(agg).reset_index()\n",
    "gb_clutch_range.columns = [' '.join(col).strip() for col in gb_clutch_range.columns.values]\n",
    "log('   9. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Hours exceeding 35C by year, season, month and phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:56:22 2017 -    11. Hours exceeding 35C...\n",
      "Thu Aug 31 19:56:26 2017 -    11. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   11. Hours exceeding 35C...')\n",
    "# Get a version of df_sensor_phase that is sorted correctly\n",
    "temp = df_sensor_phase.sort_values(by=['nest_id', 'datetime']).copy().reset_index()\n",
    "temp['recnum'] = temp['index']\n",
    "\n",
    "# Get all records with a temp_c >= 35 C\n",
    "df_hours_above_35C = temp[df_sensor_phase['temp_c'] >= 35].copy()\n",
    "df_hours_above_35C['next_rec'] = df_hours_above_35C['recnum'] + 1\n",
    "\n",
    "# Get all records with recnum+1 using a merge\n",
    "df_hours_above_35C = pd.merge(\n",
    "    left=df_hours_above_35C,\n",
    "    right=temp,\n",
    "    how='left',\n",
    "    left_on='next_rec',\n",
    "    right_on='recnum',\n",
    "    sort=True,\n",
    "    suffixes=('_orig', '_next')\n",
    ")[['recnum_orig', 'datetime_orig', 'nest_id_orig', 'humidity_orig',\n",
    "       'temp_c_orig', 'breeding_year_orig', 'temp_bucket_orig',\n",
    "       'humidity_bucket_orig', 'clutch_1_orig', 'clutch_2_orig',\n",
    "       'clutch_3_orig', 'clutch_orig', 'egg_lay_date_orig',\n",
    "       'courting_date_orig', 'hatch_date_orig', 'dead_or_fledge_date_orig',\n",
    "       'clutch_count_orig', 'calendar_year_orig', 'month_orig', 'day_orig',\n",
    "       'hour_orig', 'minute_orig', 'season_orig', 'season_year_orig',\n",
    "       'breeding_phase_orig', 'datetime_next']]\n",
    "\n",
    "del temp\n",
    "\n",
    "# Get the Timedelta between recnum-datestamp and next_rec-datestamp\n",
    "df_hours_above_35C['time_at_temp'] = df_hours_above_35C['datetime_next'] - df_hours_above_35C['datetime_orig']\n",
    "df_hours_above_35C['hours_above_35C'] = df_hours_above_35C['time_at_temp'].apply(lambda x: x.seconds / 3600)\n",
    "\n",
    "# Sum the Timedeltas per nest per year, season, month\n",
    "# monthly\n",
    "gb_monthly_hours_above_35C = df_hours_above_35C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'month_orig', 'hours_above_35C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'month_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "# annual\n",
    "gb_annual_hours_above_35C = df_hours_above_35C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'hours_above_35C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "# seasonal\n",
    "gb_seasonal_hours_above_35C = df_hours_above_35C[\n",
    "    ['nest_id_orig', 'season_year_orig', 'season_orig', 'hours_above_35C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'season_year_orig', 'season_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "# breeding phase\n",
    "gb_phase_hours_above_35C = df_hours_above_35C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'clutch_orig', 'breeding_phase_orig', 'hours_above_35C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'clutch_orig', 'breeding_phase_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "# clutch\n",
    "gb_clutch_hours_above_35C = df_hours_above_35C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'clutch_orig', 'hours_above_35C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'clutch_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "log('   11. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculation: **Hours exceeding 40C by year, season, month and phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 19:57:31 2017 -    12. Hours exceeding 40C...\n",
      "Thu Aug 31 19:57:35 2017 -    12. Done.\n"
     ]
    }
   ],
   "source": [
    "log('   12. Hours exceeding 40C...')\n",
    "# Get a version of df_sensor_phase that is sorted correctly\n",
    "temp = df_sensor_phase.sort_values(by=['nest_id', 'datetime']).copy().reset_index()\n",
    "temp['recnum'] = temp['index']\n",
    "\n",
    "# Get all records with a temp_c >= 40 C\n",
    "df_hours_above_40C = temp[df_sensor_phase['temp_c'] >= 40].copy()\n",
    "df_hours_above_40C['next_rec'] = df_hours_above_40C['recnum'] + 1\n",
    "\n",
    "# Get all records with recnum+1 using a merge\n",
    "df_hours_above_40C = pd.merge(\n",
    "    left=df_hours_above_40C,\n",
    "    right=temp,\n",
    "    how='left',\n",
    "    left_on='next_rec',\n",
    "    right_on='recnum',\n",
    "    sort=True,\n",
    "    suffixes=('_orig', '_next')\n",
    ")[['recnum_orig', 'datetime_orig', 'nest_id_orig', 'humidity_orig',\n",
    "       'temp_c_orig', 'breeding_year_orig', 'temp_bucket_orig',\n",
    "       'humidity_bucket_orig', 'clutch_1_orig', 'clutch_2_orig',\n",
    "       'clutch_3_orig', 'clutch_orig', 'egg_lay_date_orig',\n",
    "       'courting_date_orig', 'hatch_date_orig', 'dead_or_fledge_date_orig',\n",
    "       'clutch_count_orig', 'calendar_year_orig', 'month_orig', 'day_orig',\n",
    "       'hour_orig', 'minute_orig', 'season_orig', 'season_year_orig',\n",
    "       'breeding_phase_orig', 'datetime_next']]\n",
    "\n",
    "del temp\n",
    "\n",
    "# Get the Timedelta between recnum-datestamp and next_rec-datestamp\n",
    "df_hours_above_40C['time_at_temp'] = df_hours_above_40C['datetime_next'] - df_hours_above_40C['datetime_orig']\n",
    "df_hours_above_40C['hours_above_40C'] = df_hours_above_40C['time_at_temp'].apply(lambda x: x.seconds / 3600)\n",
    "\n",
    "# Sum the Timedeltas per nest per year, season, month\n",
    "gb_monthly_hours_above_40C = df_hours_above_40C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'month_orig', 'hours_above_40C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'month_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "gb_annual_hours_above_40C = df_hours_above_40C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'hours_above_40C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "gb_seasonal_hours_above_40C = df_hours_above_40C[\n",
    "    ['nest_id_orig', 'season_year_orig', 'season_orig', 'hours_above_40C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'season_year_orig', 'season_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "gb_phase_hours_above_40C = df_hours_above_40C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'clutch_orig', 'breeding_phase_orig', 'hours_above_40C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'clutch_orig', 'breeding_phase_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "gb_clutch_hours_above_40C = df_hours_above_40C[\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'clutch_orig', 'hours_above_40C']\n",
    "].groupby(\n",
    "    ['nest_id_orig', 'breeding_year_orig', 'clutch_orig']\n",
    ").sum().reset_index()\n",
    "\n",
    "log('   12. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder - need BOM data\n",
    "Calculation: **Mean variance from ambient max temperature by year, season, month, phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log('   13. Mean monthly humidity...')\n",
    "\n",
    "# log('   13. Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Placeholder - need BOM data\n",
    "Calculation: **Mean variance from ambient min temperature by year, season, month, phase**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# log('   14. Mean monthly humidity...')\n",
    "\n",
    "# log('   14. Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sat Jul  8 20:44:59 2017 - Calculating the sensor stats: Done.\n"
     ]
    }
   ],
   "source": [
    "log('Calculating the sensor stats: Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Join the aggregates by their time period (all annual, all monthly etc) and join the breeding success data to the aggregates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Monthly aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 20:21:20 2017 - Joining monthly tables...\n",
      "Thu Aug 31 20:21:20 2017 - Writing intermediate table df_monthly_microclimate to disk.\n",
      "Thu Aug 31 20:21:20 2017 - Written output\\B_Aggregate_Sensor_Stats/df_monthly_microclimate.csv: 0.501 MB\n",
      "Thu Aug 31 20:21:20 2017 - Done.\n",
      "Thu Aug 31 20:21:20 2017 - Placeholder: Joining breeding success to monthly microclimate data -> df_monthly_microclimate_vs_breeding...\n",
      "Thu Aug 31 20:21:20 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "log('Joining monthly tables...')\n",
    "df_monthly_microclimate = pd.merge(left=gb_monthly_sensor_stats, \n",
    "                                   right=gb_monthly_range, \n",
    "                                   how='left', \n",
    "                                   on=['nest_id', 'breeding_year', 'month'], \n",
    "                                   sort=True)\n",
    "\n",
    "df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "                                   right=df_monthly_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'month'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "                                   right=df_monthly_days_above_40C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'month'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "                                   right=gb_monthly_hours_above_35C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year', 'month'],\n",
    "                                   right_on=['nest_id_orig', 'breeding_year_orig', 'month_orig'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_monthly_microclimate = pd.merge(left=df_monthly_microclimate,\n",
    "                                   right=gb_monthly_hours_above_40C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year', 'month'],\n",
    "                                   right_on=['nest_id_orig', 'breeding_year_orig', 'month_orig'],\n",
    "                                   sort=True)\n",
    "df_monthly_microclimate.sort_values(by=['nest_id', 'breeding_year', 'month'], inplace=True)\n",
    "write_temp_file(df_monthly_microclimate, '{0}/df_monthly_microclimate.csv'.format(output_path), 'df_monthly_microclimate')\n",
    "log('Done.')\n",
    "\n",
    "log('Placeholder: Joining breeding success to monthly microclimate data -> df_monthly_microclimate_vs_breeding...')\n",
    "# PLACEHOLDER\n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Annual aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 20:21:24 2017 - Joining annual tables...\n",
      "Thu Aug 31 20:21:24 2017 - Writing intermediate table df_annual_microclimate to disk.\n",
      "Thu Aug 31 20:21:24 2017 - Written output\\B_Aggregate_Sensor_Stats/df_annual_microclimate.csv: 0.079 MB\n",
      "Thu Aug 31 20:21:24 2017 - Done.\n",
      "Thu Aug 31 20:21:24 2017 - Placeholder: Joining breeding success to annual microclimate data -> df_annual_microclimate_vs_breeding...\n",
      "Thu Aug 31 20:21:24 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "log('Joining annual tables...')\n",
    "df_annual_microclimate = pd.merge(left=gb_annual_sensor_stats, \n",
    "                                   right=gb_annual_range, \n",
    "                                   how='left', \n",
    "                                   on=['nest_id', 'breeding_year'], \n",
    "                                   sort=True)\n",
    "\n",
    "df_annual_microclimate = pd.merge(left=df_annual_microclimate,\n",
    "                                   right=df_annual_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_annual_microclimate = pd.merge(left=df_annual_microclimate,\n",
    "                                   right=df_annual_days_above_40C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_annual_microclimate = pd.merge(left=df_annual_microclimate,\n",
    "                                   right=gb_annual_hours_above_35C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year'],\n",
    "                                   right_on=['nest_id_orig', 'breeding_year_orig'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_annual_microclimate = pd.merge(left=df_annual_microclimate,\n",
    "                                   right=gb_annual_hours_above_40C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year'],\n",
    "                                   right_on=['nest_id_orig', 'breeding_year_orig'],\n",
    "                                   sort=True)\n",
    "df_annual_microclimate.sort_values(by=['nest_id', 'breeding_year'], inplace=True)\n",
    "write_temp_file(df_annual_microclimate, '{0}/df_annual_microclimate.csv'.format(output_path), 'df_annual_microclimate')\n",
    "log('Done.')\n",
    "\n",
    "log('Placeholder: Joining breeding success to annual microclimate data -> df_annual_microclimate_vs_breeding...')\n",
    "# PLACEHOLDER\n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seasonal aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 20:21:26 2017 - Joining seasonal tables...\n",
      "Thu Aug 31 20:21:26 2017 - Writing intermediate table df_seasonal_microclimate to disk.\n",
      "Thu Aug 31 20:21:26 2017 - Written output\\B_Aggregate_Sensor_Stats/df_seasonal_microclimate.csv: 0.207 MB\n",
      "Thu Aug 31 20:21:26 2017 - Done.\n",
      "Thu Aug 31 20:21:26 2017 - Placeholder: Joining breeding success to seasonal microclimate data -> df_seasonal_microclimate_vs_breeding...\n",
      "Thu Aug 31 20:21:26 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "log('Joining seasonal tables...')\n",
    "df_seasonal_microclimate = pd.merge(left=gb_seasonal_sensor_stats, \n",
    "                                   right=gb_seasonal_range, \n",
    "                                   how='left', \n",
    "                                   on=['nest_id', 'season_year', 'season'], \n",
    "                                   sort=True)\n",
    "\n",
    "df_seasonal_microclimate = pd.merge(left=df_seasonal_microclimate,\n",
    "                                   right=df_seasonal_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'season_year', 'season'], \n",
    "                                   sort=True)\n",
    "\n",
    "df_seasonal_microclimate = pd.merge(left=df_seasonal_microclimate,\n",
    "                                   right=df_seasonal_days_above_40C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'season_year', 'season'], \n",
    "                                   sort=True)\n",
    "\n",
    "df_seasonal_microclimate = pd.merge(left=df_seasonal_microclimate,\n",
    "                                   right=gb_seasonal_hours_above_35C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'season_year', 'season'], \n",
    "                                   right_on=['nest_id_orig', 'season_year_orig', 'season_orig'],\n",
    "                                   sort=True)\n",
    "\n",
    "df_seasonal_microclimate = pd.merge(left=df_seasonal_microclimate,\n",
    "                                   right=gb_seasonal_hours_above_40C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'season_year', 'season'], \n",
    "                                   right_on=['nest_id_orig', 'season_year_orig', 'season_orig'],\n",
    "                                   sort=True)\n",
    "df_seasonal_microclimate.sort_values(by=['nest_id', 'season_year', 'season'], inplace=True)\n",
    "write_temp_file(df_seasonal_microclimate, '{0}/df_seasonal_microclimate.csv'.format(output_path), 'df_seasonal_microclimate')\n",
    "log('Done.')\n",
    "\n",
    "log('Placeholder: Joining breeding success to seasonal microclimate data -> df_seasonal_microclimate_vs_breeding...')\n",
    "# PLACEHOLDER\n",
    "log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breeding phase aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 20:21:29 2017 - Joining breeding phase tables...\n",
      "\n",
      "Join breeding phase stats to average temp/humidity range\n",
      "   gb_phase_sensor_stats: 275\n",
      "   gb_phase_range: 275\n",
      "   Result: df_breeding_microclimate: 275\n",
      "\n",
      "Add average minimum\n",
      "   df_breeding_microclimate: 275\n",
      "   gb_phase_min: 275\n",
      "   Result: df_breeding_microclimate: 275\n",
      "\n",
      "Add average maximum\n",
      "   df_breeding_microclimate: 275\n",
      "   gb_phase_max: 275\n",
      "   Result: df_breeding_microclimate: 275\n",
      "\n",
      "Add days >35C\n",
      "   df_breeding_microclimate: 275\n",
      "   df_phase_days_above_35C: 102\n",
      "   Result: df_breeding_microclimate: 275\n",
      "\n",
      "Add days >40C\n",
      "   df_breeding_microclimate: 275\n",
      "   df_phase_days_above_40C: 72\n",
      "   Result: df_breeding_microclimate: 275\n",
      "\n",
      "Add hours >35C\n",
      "   df_breeding_microclimate: 275\n",
      "   gb_phase_hours_above_35C: 102\n",
      "   Result: df_breeding_microclimate: 275\n",
      "\n",
      "Add hours >40C\n",
      "   df_breeding_microclimate: 275\n",
      "   gb_phase_hours_above_40C: 72\n",
      "   Result: df_breeding_microclimate: 275\n",
      "Thu Aug 31 20:21:29 2017 - Writing intermediate table df_breeding_phase_microclimate to disk.\n",
      "Thu Aug 31 20:21:29 2017 - Written output\\B_Aggregate_Sensor_Stats/df_breeding_phase_microclimate.csv: 0.106 MB\n",
      "Thu Aug 31 20:21:29 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "log('Joining breeding phase tables...')\n",
    "\n",
    "print('\\nJoin breeding phase stats to average temp/humidity range')\n",
    "print('   gb_phase_sensor_stats:', len(gb_phase_sensor_stats))\n",
    "print('   gb_phase_range:', len(gb_phase_range))\n",
    "df_breeding_microclimate = pd.merge(left=gb_phase_sensor_stats, # 275\n",
    "                                   right=gb_phase_range, # 275\n",
    "                                   how='left', \n",
    "                                   on=['nest_id', 'breeding_year', 'clutch', 'breeding_phase'], \n",
    "                                   sort=False)\n",
    "print('   Result: df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "\n",
    "print('\\nAdd average minimum')\n",
    "print('   df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "print('   gb_phase_min:', len(gb_phase_min))\n",
    "df_breeding_microclimate = pd.merge(left=df_breeding_microclimate,\n",
    "                                   right=gb_phase_min,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'clutch', 'breeding_phase'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "\n",
    "print('\\nAdd average maximum')\n",
    "print('   df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "print('   gb_phase_max:', len(gb_phase_max))\n",
    "df_breeding_microclimate = pd.merge(left=df_breeding_microclimate,\n",
    "                                   right=gb_phase_max,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'clutch', 'breeding_phase'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "\n",
    "print('\\nAdd days >35C')\n",
    "print('   df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "print('   df_phase_days_above_35C:', len(df_phase_days_above_35C))\n",
    "df_breeding_microclimate = pd.merge(left=df_breeding_microclimate,\n",
    "                                   right=df_phase_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'clutch', 'breeding_phase'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "\n",
    "print('\\nAdd days >40C')\n",
    "print('   df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "print('   df_phase_days_above_40C:', len(df_phase_days_above_40C))\n",
    "df_breeding_microclimate = pd.merge(left=df_breeding_microclimate,\n",
    "                                   right=df_phase_days_above_40C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'clutch', 'breeding_phase'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "\n",
    "print('\\nAdd hours >35C')\n",
    "print('   df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "print('   gb_phase_hours_above_35C:', len(gb_phase_hours_above_35C))\n",
    "df_breeding_microclimate = pd.merge(left=df_breeding_microclimate,\n",
    "                                   right=gb_phase_hours_above_35C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year', 'clutch', 'breeding_phase'],\n",
    "                                   right_on=['nest_id_orig', 'breeding_year_orig', 'clutch_orig', 'breeding_phase_orig'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "\n",
    "print('\\nAdd hours >40C')\n",
    "print('   df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "print('   gb_phase_hours_above_40C:', len(gb_phase_hours_above_40C))\n",
    "df_breeding_microclimate = pd.merge(left=df_breeding_microclimate,\n",
    "                                   right=gb_phase_hours_above_40C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year', 'clutch', 'breeding_phase'],\n",
    "                                   right_on=['nest_id_orig', 'breeding_year_orig', 'clutch_orig', 'breeding_phase_orig'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_breeding_microclimate:', len(df_breeding_microclimate))\n",
    "\n",
    "write_temp_file(df_breeding_microclimate, '{0}/df_breeding_phase_microclimate.csv'.format(output_path), 'df_breeding_phase_microclimate')\n",
    "log('Done.')\n",
    "\n",
    "# log('Placeholder: Joining breeding success to monthly microclimate data -> df_monthly_microclimate_vs_breeding...')\n",
    "# # PLACEHOLDER\n",
    "# log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clutch aggregate data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 20:21:33 2017 - Joining breeding clutch tables...\n",
      "\n",
      "Join breeding clutch stats to average temp/humidity range\n",
      "   gb_clutch_sensor_stats: 102\n",
      "   gb_clutch_range: 102\n",
      "   Result: df_clutch_microclimate: 102\n",
      "\n",
      "Add average minimum\n",
      "   df_clutch_microclimate: 102\n",
      "   gb_clutch_min: 102\n",
      "   Result: df_clutch_microclimate: 102\n",
      "\n",
      "Add average maximum\n",
      "   df_clutch_microclimate: 102\n",
      "   gb_clutch_max: 102\n",
      "   Result: df_clutch_microclimate: 102\n",
      "\n",
      "Add days >35C\n",
      "   df_clutch_microclimate: 102\n",
      "   df_clutch_days_above_35C: 86\n",
      "   Result: df_clutch_microclimate: 102\n",
      "\n",
      "Add days >40C\n",
      "   df_clutch_microclimate: 102\n",
      "   df_clutch_days_above_40C: 66\n",
      "   Result: df_clutch_microclimate: 102\n",
      "\n",
      "Add hours >35C\n",
      "   df_clutch_microclimate: 102\n",
      "   gb_clutch_hours_above_35C: 86\n",
      "   Result: df_clutch_microclimate: 102\n",
      "\n",
      "Add hours >40C\n",
      "   df_clutch_microclimate: 102\n",
      "   gb_clutch_hours_above_40C: 66\n",
      "   Result: df_clutch_microclimate: 102\n",
      "Thu Aug 31 20:21:33 2017 - Writing intermediate table df_breeding_clutch_microclimate to disk.\n",
      "Thu Aug 31 20:21:33 2017 - Written output\\B_Aggregate_Sensor_Stats/df_breeding_clutch_microclimate.csv: 0.039 MB\n",
      "Thu Aug 31 20:21:33 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "log('Joining breeding clutch tables...')\n",
    "\n",
    "print('\\nJoin breeding clutch stats to average temp/humidity range')\n",
    "print('   gb_clutch_sensor_stats:', len(gb_clutch_sensor_stats))\n",
    "print('   gb_clutch_range:', len(gb_clutch_range))\n",
    "df_clutch_microclimate = pd.merge(left=gb_clutch_sensor_stats, # 275\n",
    "                                   right=gb_clutch_range, # 275\n",
    "                                   how='left', \n",
    "                                   on=['nest_id', 'breeding_year', 'clutch'], \n",
    "                                   sort=False)\n",
    "print('   Result: df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "\n",
    "print('\\nAdd average minimum')\n",
    "print('   df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "print('   gb_clutch_min:', len(gb_clutch_min))\n",
    "df_clutch_microclimate = pd.merge(left=df_clutch_microclimate,\n",
    "                                   right=gb_clutch_min,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'clutch'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "\n",
    "print('\\nAdd average maximum')\n",
    "print('   df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "print('   gb_clutch_max:', len(gb_clutch_max))\n",
    "df_clutch_microclimate = pd.merge(left=df_clutch_microclimate,\n",
    "                                   right=gb_clutch_max,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'clutch'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "\n",
    "print('\\nAdd days >35C')\n",
    "print('   df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "print('   df_clutch_days_above_35C:', len(df_clutch_days_above_35C))\n",
    "df_clutch_microclimate = pd.merge(left=df_clutch_microclimate,\n",
    "                                   right=df_clutch_days_above_35C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'clutch'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "\n",
    "print('\\nAdd days >40C')\n",
    "print('   df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "print('   df_clutch_days_above_40C:', len(df_clutch_days_above_40C))\n",
    "df_clutch_microclimate = pd.merge(left=df_clutch_microclimate,\n",
    "                                   right=df_clutch_days_above_40C,\n",
    "                                   how='left',\n",
    "                                   on=['nest_id', 'breeding_year', 'clutch'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "\n",
    "print('\\nAdd hours >35C')\n",
    "print('   df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "print('   gb_clutch_hours_above_35C:', len(gb_clutch_hours_above_35C))\n",
    "df_clutch_microclimate = pd.merge(left=df_clutch_microclimate,\n",
    "                                   right=gb_clutch_hours_above_35C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year', 'clutch'],\n",
    "                                   right_on=['nest_id_orig', 'breeding_year_orig', 'clutch_orig'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "\n",
    "print('\\nAdd hours >40C')\n",
    "print('   df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "print('   gb_clutch_hours_above_40C:', len(gb_clutch_hours_above_40C))\n",
    "df_clutch_microclimate = pd.merge(left=df_clutch_microclimate,\n",
    "                                   right=gb_clutch_hours_above_40C,\n",
    "                                   how='left',\n",
    "                                   left_on=['nest_id', 'breeding_year', 'clutch'],\n",
    "                                   right_on=['nest_id_orig', 'breeding_year_orig', 'clutch_orig'],\n",
    "                                   sort=True)\n",
    "print('   Result: df_clutch_microclimate:', len(df_clutch_microclimate))\n",
    "\n",
    "write_temp_file(df_clutch_microclimate, '{0}/df_breeding_clutch_microclimate.csv'.format(output_path), 'df_breeding_clutch_microclimate')\n",
    "log('Done.')\n",
    "\n",
    "# log('Placeholder: Joining breeding success to monthly microclimate data -> df_monthly_microclimate_vs_breeding...')\n",
    "# # PLACEHOLDER\n",
    "# log('Done.')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pickle the two key data files for use in later scripts**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Thu Aug 31 20:21:36 2017 - Writing the final tables to pickle for future use...\n",
      "Thu Aug 31 20:21:36 2017 - Writing intermediate table Microclimate_Annual to disk.\n",
      "Thu Aug 31 20:21:36 2017 - Written output\\B_Aggregate_Sensor_Stats/Microclimate_Annual.csv: 0.079 MB\n",
      "Thu Aug 31 20:21:36 2017 - Writing intermediate table Microclimate_Monthly to disk.\n",
      "Thu Aug 31 20:21:36 2017 - Written output\\B_Aggregate_Sensor_Stats/Microclimate_Monthly.csv: 0.501 MB\n",
      "Thu Aug 31 20:21:36 2017 - Writing intermediate table Microclimate_Seasonal to disk.\n",
      "Thu Aug 31 20:21:36 2017 - Written output\\B_Aggregate_Sensor_Stats/Microclimate_Seasonal.csv: 0.207 MB\n",
      "Thu Aug 31 20:21:36 2017 - Writing intermediate table Microclimate_BreedingPhase to disk.\n",
      "Thu Aug 31 20:21:36 2017 - Written output\\B_Aggregate_Sensor_Stats/Microclimate_BreedingPhase.csv: 0.106 MB\n",
      "Thu Aug 31 20:21:36 2017 - Writing intermediate table Microclimate_Clutch to disk.\n",
      "Thu Aug 31 20:21:36 2017 - Written output\\B_Aggregate_Sensor_Stats/Microclimate_Clutch.csv: 0.039 MB\n",
      "Thu Aug 31 20:21:36 2017 - Done.\n"
     ]
    }
   ],
   "source": [
    "log('Writing the final tables to pickle for future use...')\n",
    "df_monthly_microclimate.to_pickle('{0}/df_monthly_microlimate.pkl'.format(output_path))\n",
    "df_annual_microclimate.to_pickle('{0}/df_annual_microlimate.pkl'.format(output_path))\n",
    "df_seasonal_microclimate.to_pickle('{0}/df_seasonal_microlimate.pkl'.format(output_path))\n",
    "df_breeding_microclimate.to_pickle('{0}/df_breeding_microclimate.pkl'.format(output_path))\n",
    "df_clutch_microclimate.to_pickle('{0}/df_clutch_microlimate.pkl'.format(output_path))\n",
    "\n",
    "write_temp_file(df_annual_microclimate, '{0}/Microclimate_Annual.csv'.format(output_path), 'Microclimate_Annual')\n",
    "write_temp_file(df_monthly_microclimate, '{0}/Microclimate_Monthly.csv'.format(output_path), 'Microclimate_Monthly')\n",
    "write_temp_file(df_seasonal_microclimate, '{0}/Microclimate_Seasonal.csv'.format(output_path), 'Microclimate_Seasonal')\n",
    "write_temp_file(df_breeding_microclimate, '{0}/Microclimate_BreedingPhase.csv'.format(output_path), 'Microclimate_BreedingPhase')\n",
    "write_temp_file(df_clutch_microclimate, '{0}/Microclimate_Clutch.csv'.format(output_path), 'Microclimate_Clutch')\n",
    "\n",
    "log('Done.')"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
